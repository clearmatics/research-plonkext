% !TEX root = main.tex
% !TEX spellcheck = en-US

\section{Concrete SNARKs Preliminaries}

\ourpar{Bilinear groups.}
A bilinear group generator $\pgen (\secparam)$ returns public parameters $ \pp =
(p, \GRP_1, \GRP_2, \GRP_T, \pair, \gone{1}, \gtwo{1})$, where $\GRP_1$,
$\GRP_2$, and $\GRP_T$ are additive cyclic groups of prime order $p = 2^{\Omega
  (\secpar)}$, $\gone{1}, \gtwo{1}$ are generators of $\GRP_1$, $\GRP_2$, resp.,
and $\pair: \GRP_1 \times \GRP_2 \to \GRP_T$ is a non-degenerate
$\ppt$-computable bilinear pairing. We assume the bilinear pairing to be Type-3,
i.e., that there is no efficient isomorphism from $\GRP_1$ to $\GRP_2$ or from
$\GRP_2$ to $\GRP_1$. We use the by now standard bracket notation, i.e., we
write $\bmap{a}{\gi}$ to denote $a g_{\gi}$ where $g_{\gi}$ is a fixed generator
of $\GRP_{\gi}$. We denote $\pair (\gone{a}, \gtwo{b})$ as $\gone{a} \bullet
\gtwo{b}$. Thus, $\gone{a} \bullet \gtwo{b} = \gtar{a b}$. We freely use the
bracket notation with matrices, e.g., if $\vec{A} \vec{B} = \vec{C}$ then
$\vec{A} \grpgi{\vec{B}} = \grpgi{\vec{C}}$ and $\gone{\vec{A}}\bullet
\gtwo{\vec{B}} = \gtar{\vec{C}}$. Since every algorithm $\adv$ takes as input
the public parameters we skip them when describing $\adv$'s input. Similarly, we
do not explicitly state that each protocol starts with generating these
parameters by $\pgen$.

\subsection{Algebraic Group Model}
The algebraic group model (AGM) introduced in \cite{C:FucKilLos18} lies between the
standard model and generic bilinear group model. In the AGM it is assumed that an
adversary $\adv$ can output a group element $\gnone{y} \in \GRP$ if $\gnone{y}$ has
been computed by applying group operations to group elements given to $\adv$ as
input. It is further assumed, that $\adv$ knows how to ``build'' $\gnone{y}$ from
that elements. More precisely, the AGM requires that whenever $\adv(\gnone{\vec{x}})$
outputs a group element $\gnone{y}$ then it also outputs $\vec{c}$ such that
$\gnone{y} = \vec{c}^\top \cdot \gnone{\vec{x}}$. $\plonk$, $\sonic$ and $\marlin$
have been shown secure using the AGM. An adversary that works in the AGM is called
\emph{algebraic}.

\oursubsub{Idealised Verifier and Verification Equations.} Let
$(\kgen, \prover, \verifier, \simulator)$ be a proof system.
% or a polynomial commitment
% scheme\hamid{might be unclear as we are defining polynomial commitments as
%   $(\kgen, \com, \open, \verify)$.}.
Observe that the $\kgen$ algorithm provides an SRS which can be interpreted as a set
of group representation of polynomials evaluated at trapdoor elements. That is, for a
trapdoor $\chi$ the SRS contains $\gone{\p{p_1}(\chi), \ldots, \p{p_k}(\chi)}$, for
some polynomials $\p{p_1}(X), \ldots, \p{p_k}(X) \in \FF_p[X]$. The verifier
$\verifier$ accepts a proof $\zkproof$ for instance $\inp$ if (a set of) verification
equation $\vereq_{\inp, \zkproof}$ (which can also be interpreted as a polynomial in
$\FF_p[X]$ whose coefficients depend on messages sent by the prover) zeroes at
$\chi$. Following \cite{EPRINT:GabWilCio19} we call verifiers who check that
$\vereq_{\inp, \zkproof}(\chi) = 0$ \emph{real verifiers} as opposed to \emph{ideal
  verifiers} who accept only when $\vereq_{\inp, \zkproof}(X) = 0$. That is, while a
real verifier accepts when a polynomial \emph{evaluates} to zero, an ideal verifier
accepts only when the polynomial \emph{is} zero.

Although ideal verifiers are impractical, they are very useful in our
proofs. More precisely, we show that
\begin{compactenum}
\item the idealised verifier accepts an incorrect proof (what ``incorrect''
  means depends on the situation) with at most negligible probability (and in many
  cases---never);
\item when the real verifier accepts, but not the idealised one, then a malicious
  prover can be used to break the underlying security assumption (in our case---a
  variant of $\dlog$.)
\end{compactenum}

Analogously, idealised verifier can be defined for polynomial commitment schemes.

\subsection{Dlog assumptions}
  \markulf{22.04}{Move it to Section 5.}
\label{sec:dlog_assumptions}
\begin{definition}[$(q_1, q_2)\mhyph\dlog$ assumption]\label{def:dlog}
	Let $\adv$ be a $\ppt$ adversary that gets as input
  $\gone{1, \chi, \ldots, \chi^{q_1}}, \gtwo{1, \chi, \ldots, \chi^{q_2}}$, for
  some randomly picked $\chi \in \FF_p$, the assumption requires that $\adv$ cannot compute $\chi$. That is
	\[
		\condprob{\chi = \adv(\gone{1, \chi, \ldots, \chi^{q_1}}, \gtwo{1, \chi,
        \ldots, \chi^{q_2} })}{\chi \sample \FF_p} \leq \negl.
	\]
\end{definition}

\markulf{22.04}{I prefer the notation $Pr[\chi \gets \FF_q; \chi' \gets \adv( ...): \chi=\chi']$ as one can start reading at the left. But I will let that one go and will admit that it's a question of taste and it might be an aquired taste. }

\begin{definition}[$(q_1, q_2)\mhyph\ldlog$ assumption]\label{def:ldlog}
  Let $\adv$ be a $\ppt$ adversary that gets as input
  $\gone{\chi^{-q_1}, \ldots, 1, \ldots, \chi^{q_1}}, \gtwo{\chi^{-q_2},
    \ldots, 1, \ldots, \chi^{q_2}}$, for some randomly picked
  $\chi \in \FF_p$, the assumption requires that $\adv$ cannot compute $\chi$. That is
	\[
    \condprob{\chi = \adv(\gone{\chi^{-q_1}, \ldots, 1, \ldots,
        \chi^{q_1}}, \gtwo{\chi^{-q_2}, \ldots, 1, \ldots, \chi^{q_2}
      })}{\chi \sample \FF_p} \leq \negl.
	\]
\end{definition}


\chb{\paragraph{Dlog assumptions in the updatable setting.}\label{dlog-upd} Since all our protocols and security notions are in the updatable setting, we may require to rely on Dlog assumptions that are defined in the updatable setting. That is, the adversary $\adv$ is not given as input a Dlog challenge, but access to an update oracle as defined in~\cref{fig:upd}, wherein an honestly generated SRS is defined as a Dlog challenge and the update algorithm $\upd$ works similarly as in the updatable schemes by re-randomizing the challenge. Here we define these assumptions and then show a reduction between the assumptions and their variant in the updatable setting. \textcolor{blue}{Note that for ease of clarity, with a slight abuse of notation, we here denote the SRS by $\Ch$. Further, to avoid cluttering notation, we do not make the proofs of correctly generating or updating the Dlog challenges explicit as they can be generated in a similar manner to the proofs in~\cref{fig:upd-scheme}.}
	
%The reduction $\reduction$ proceeds as follows: given the input dlog instance, $\reduction$ answers adversary's queries for the dlog updates and sets the honest update to be the input dlog instance. Once the dlog challenge in the updatable setting is finalized, it runs the adversary and obtains the answer $\chi'$. Let $\chi_1, \ldots, \chi_\ell$ be the partial discrete logarithms of dlog instances corresponding to the adversary's dlog updates. These values can be computed by $\reduction$ by extracting from the update proofs given by the adversary. $\reduction$ now returns  $\chi = \chi' (\chi_1 \chi_2 \ldots \chi_\ell)^{-1}$. The same argument holds for the $(q_1, q_2)\mhyph\ldlog$ assumption, ~\cref{def:ldlog}.

\subsection{Dlog assumptions in the updatable setting}
\label{sec:udlog_assumptions}

\begin{definition}[$(q_1, q_2)\mhyph\udlog$ assumption]\label{def:udlog}
	Let $\adv$ be a $\ppt$ adversary that gets oracle access to $\initU$ with internal algorithms $(\kgen_{\dlog}, \upd_{\dlog}, \verifyCRS)$, where $\kgen_{\dlog}$ and $\upd_{\dlog}$ are defined as follows:
	\begin{itemize}
	\item $\kgen_\dlog(\secpar)$ samples $\chi \sample \FF_p$ and defines 
		$\Ch:=(\gone{1, \chi, \ldots,
			\chi^{q_1}}, \gtwo{1, \chi, \ldots, \chi^{q_2}
		})$.
	\item $\upd_\dlog(\Ch, \{\rho_j \}_{j=1}^n)$ 
	parses $\Ch$ as $\left( \gone{\smallset{A_i}_{i = 0}^{q_1}},
	\gtwo{\smallset{B_i}_{i = 0}^{q_2}} \right)$, samples
	$\widetilde{\chi} \sample \FF_p$, and defines
	$\widetilde{\Ch} := 
	\left( \gone{\smallset{\widetilde{\chi}^i A_i}_{i = 0}^{q_1}},
	\gtwo{\smallset{\widetilde{\chi}^i B_i}_{i = 0}^{q_2}} \right)$.
	\end{itemize}
	Then
	\[
	\prob{\bar{\chi} \gets \adv^{\initU}(\secpar)} \leq \negl,
	\]
	where $\left( \gone{\smallset{\bar{\chi}^i}_{i = 0}^{q_1}},
	\gtwo{\smallset{\bar{\chi}^i}_{i = 0}^{q_2}} \right)$ is the finalized challenge.
\end{definition}

\begin{definition}[$(q_1, q_2)\mhyph\uldlog$ assumption]\label{def:uldlog}
	Let $\adv$ be a $\ppt$ adversary that gets oracle access to $\initU$ with internal algorithms $(\kgen_{\ldlog}, \upd_{\ldlog}, \verifyCRS)$, where $\kgen_{\ldlog}$ and $\upd_{\ldlog}$ are defined as follows:
	\begin{itemize}
		\item $\kgen_\ldlog(\secpar)$ samples $\chi \sample \FF_p$ and defines 
		$\Ch:=(\gone{\chi^{-q_1}, \ldots, 1, \chi, \ldots,
			\chi^{q_1}}, \gtwo{\chi^{-q_2}, \ldots, 1, \chi, \ldots, \chi^{q_2}
		})$.
		\item $\upd_\ldlog(\Ch, \{\rho_j \}_{j=1}^n)$ 
		parses $\Ch$ as $\left( \gone{\smallset{A_i}_{i = -q_1}^{q_1}},
		\gtwo{\smallset{B_i}_{i = -q_2}^{q_2}} \right)$, samples
		$\widetilde{\chi} \sample \FF_p$, and defines
		$\widetilde{\Ch} := 
		\left( \gone{\smallset{\widetilde{\chi}^i A_i}_{i = -q_1}^{q_1}},
		\gtwo{\smallset{\widetilde{\chi}^i B_i}_{i = -q_2}^{q_2}} \right)$.
	\end{itemize}
	Then
	\[
	\prob{\bar{\chi} \gets \adv^{\initU}(\secpar)} \leq \negl,
	\]
	where $\left( \gone{\smallset{\bar{\chi}^i}_{i = -q_1}^{q_1}},
	\gtwo{\smallset{\bar{\chi}^i}_{i = -q_2}^{q_2}} \right)$ is the finalized challenge.
\end{definition}

\chb{\begin{remark}[Single adversarial updates after an honest setup.]\label{rem:upd}
	One can consider a slightly different model of setup, where the adversary is given an initial honestly-generated SRS and is then allowed to perform a malicious update in one-shot fashion.
	As shown by Groth
	et al. in~\cite{C:GKMMM18}, the two definitions are equivalent for the class of SNARKs in this work and thus we use this simpler definition to show our security proofs in the updatable setting.
\end{remark}} \markulf{25.04}{Move this to where we use it in the proof.}

We show a reduction from $(q_1, q_2)\mhyph\dlog$ assumption to its variant in the updatable setting according to the update model in~\cref{rem:upd}. We omit showing the reduction $(q_1, q_2)\mhyph\ldlog \Rightarrow (q_1, q_2)\mhyph\uldlog$ as it can be done similarly in a straightforward manner.
\begin{lemma}
	$(q_1, q_2)\mhyph\dlog \Rightarrow (q_1, q_2)\mhyph\udlog$.
	\end{lemma}
\begin{proof}
	We construct a reduction algorithm $\reduction$ which uses an adversary $\adv$ on the $(q_1, q_2)\mhyph\udlog$ and construct an adversary on the $(q_1, q_2)\mhyph\dlog$. Specifically, $\reduction$ proceeds as follows: given a dlog instance $\Ch$ as input, it sets $\Ch$ as the initial (honestly generated) challenge \sout{and answers adversary's queries for the dlog updates by internally running $\upd_{\dlog}$ in Definition 5.} Once the dlog challenge in the updatable setting is finalized, it runs $\adv$ and obtains the answer $\chi'$. Let \sout{$\chi_1, \ldots, \chi_\ell$} $\chi_\adv$ be the (possibly) partial discrete logarithm of the dlog instance corresponding to the adversary's update. This value can be computed by $\reduction$ by extracting from the update proof given by $\adv$. $\reduction$ now returns  
	\sout{$\chi = \chi' (\chi_1 \chi_2 \ldots \chi_\ell)^{-1}$} $\chi = \chi' \chi_\adv^{-1}$ as the discrete logarithm of $\Ch$. %The same argument holds for the $(q_1, q_2)\mhyph\ldlog$ assumption, ~\cref{def:ldlog}.
	\end{proof}
}
  %\michals{24.03}{I think we should write a formal proof for the reduction}


  \begin{lemma}[Generalized forking lemma~\cite{EPRINT:AttFehKlo21}]\label{lem:attema}
	Let $N = n_1 \cdots n_\mu$. \markulf{26.04}{are the $n_i$ the same as the $k_i$ in the algoithm of Fig.3?} Let $\proofsystem$ be a proof system that is knowledge sound \markulf{22.04}{Requiring knowledge soundness here seems circular.} \chaya{25.04}{do we want to say that $\proofsystem$ is knowledge sound with knowledge error $\epsk$ if there exists a tree buildin algorithm $\tdv$ such that a tree of accepting transcripts is produced with the following probability?}
	with knowledge error $\epsk$. Assume adversary $\adv$ that makes up to $q$ random
	oracle queries and outputs an acceptable proof with probability at least
	$\accProb$. There exists a tree building algorithm $\tdv$ for $(n_1, \ldots, n_\mu)$-trees that utilizes the extractor $\zdv_1$ in~\cref{fig:Attema-ext} and succeeds in building a
	tree of accepting transcripts in expected
	running time $N + q (N - 1)$ with probability at least
	\[
	\frac{\accProb - (q + 1) \epsk (\secpar)}{1 - \epsk (\secpar)}.
	\]
	\end{lemma}

\begin{figure}[t]
	\centering
	\fbox{\parbox{\textwidth}{
			\begin{enumerate}
				\item Run $\zdv_{m + 1}$ as follows to obtain $(\vec{I}, \zkproof_1, v)$: relay the
				$q + \mu$ queries to the random oracle and record all query-response pairs. Set
				$i \gets I_m$, and let $c_i$ be the response to query $i$.
				\item If $v = 0$, abort with output $v = 0$. 
				\item Else, repeat
				\begin{itemize}
					\item sample $c'_i \in C \setminus \smallset{c_i}$ (without replacement);
					\item run $\zdv_{m + 1}$ as follows to obtain $(\vec{I'}, \zkproof', v')$, aborting right after the initial run of $\adv$ if $I'_m \neq I_m$: answer the query to $i$ with $c'_i$, while answering all other queries consistently if the query was performed by $\zdv_{m + 1}$ already on a previous run and with a fresh random value in $C$ otherwise; 
				\end{itemize}
				until either $k_m - 1$ additional challenges $c'_i$ with $v' = 1$ and $I'_m = I_m$ have been found or until all challenges $c'_i \in C$ have been tried. 
				\item In the former case, output $\vec{I}$, the $k_m$ accepting
				$(1, \ldots, 1, k_{m + 1}, \ldots, k_\mu)$-trees $\zkproof_1, \ldots, \zkproof_{k_m}$, and
				$v \gets 1$; in the latter case, output $v \gets 0$.
			\end{enumerate}
	}}
	\caption{Extractor $\zdv_m$ from Attema et al.~\cite{EPRINT:AttFehKlo21}. Here $\vec{I}$ is an index vector
		that contains all random oracle queries made by the prover for the output proof;
		that is, for prover's messages $\vec{a} = a_1, \ldots, a_{\mu + 1}$,
		$I_1 = (\inp, a_1), \ldots, I_{\mu} = (\inp, a_1, \ldots, a_\mu)$.  $\zkproof$ is a proof
		transcript that contains both prover's messages and random oracle responses, that is
		$\zkproof = (a_1, (\inp, a_1), a_2, (\inp, a_1, a_2), \ldots)$. Finally, $v$ is the
		verification bit, that is $v = \verifier (\srs, \inp, \zkproof)$. }
	\label{fig:Attema-ext}
\end{figure} 

\section{Polynomial Commitment Schemes}
\label{sec:pcom}
A polynomial commitment scheme $\PCOM = (\kgen, \com, \open, \verify)$ consists of four
algorithms and allows to commit to a polynomial $\p{f}$ and later open the evaluation in a
point $z$ to some value $s=\p{f}(z)$. More formally:
\begin{description}
\item[$\kgen(1^\secpar, \maxdeg)$:] The key generation algorithm takes in a security
  parameter $\secpar$ and a parameter $\maxdeg$ which determines the maximal degree of the
  committed polynomial. It outputs a structured reference string $\srs$ (the commitment
  key). In the following we will consider $\srs$ implicitly determines $\secpar$.
\item[$\com(\srs, \p{f})$:] The commitment algorithm $\com(\srs, \p{f})$ takes
  in $\srs$ and a polynomial $\p{f}$ with maximum degree $\maxdeg$, and outputs
  a commitment $c$.
\item[$\open(\srs, z, s, \p{f})$:] The opening algorithm
  takes as input $\srs$, an evaluation point $z$, a
  value $s$ and the polynomial $\p{f}$. It outputs an opening $o$.
\item[$\verify(\srs, c, z, s, o)$:] The verification algorithm takes in $\srs$,
  a commitment $c$, an evaluation point $z$, a value $s$ and an opening $o$. It
  outputs 1 if $o$ is a valid opening for $(c, z, s)$ and 0 otherwise.
\end{description} 

A secure polynomial commitment $\PCOM$ should satisfy correctness, evaluation binding,
opening uniqueness, hiding and knowledge-binding.  Note that since we are in the updatable
setting, $\srs$ in these security definitions is the SRS that $\advse$ finalises using the
update oracle $\initU$ (See~\cref{fig:upd}).

\begin{description}
\item[Evaluation binding:] A $\ppt$ adversary $\adv$ which outputs a commitment
  $\vec{c}$ and evaluation points $\vec{z}$ has at most negligible chances to open
  the commitment to two different evaluations $\vec{s}, \vec{s'}$. That is, let
  $k \in \NN$ be the number of committed polynomials, $l \in \NN$ number of
  evaluation points, $\vec{c} \in \GRP^k$ be the commitments, $\vec{z} \in
  \FF_p^l$ be the arguments the polynomials are evaluated at, $\vec{s},\vec{s}'
  \in \FF_p^k$ the evaluations, and $\vec{o},\vec{o}' \in \FF_p^l$ be the
  commitment openings. Then for every $\ppt$ adversary $\adv$
	\[
		\condprob{
			\begin{matrix}
				  \verify(\srs, \vec{c}, \vec{z}, \vec{s}, \vec{o}) = 1,  \\ 
				  \verify(\srs, \vec{c}, \vec{z}, \vec{s}', \vec{o}') = 1, \\
				  \vec{s} \neq \vec{s}'
			\end{matrix}}
			{
			\begin{matrix}
%				& \srs \gets \kgen(\secparam, \maxdeg),\\
				 (\vec{c}, \vec{z}, \vec{s}, \vec{s}', \vec{o}, \vec{o}') \gets \adv^{\initU}(\maxdeg)
			\end{matrix}
		} \leq \negl\,.
	\]

\end{description}
	
%We say that $\PCOM$ has the unique opening property if the following holds:
To show unique response property of our schemes we require that the polynomial
commitment scheme the proof system is using has unique openings defined as follows.
\begin{description}
\item[Opening uniqueness:] Intuitively, opening uniqueness assures that there is only one
  valid opening for the committed polynomial and given evaluation point. This property is
  crucial in showing \COMMENT{forking }simulation-extractability of $\plonk$, $\sonic$ and
  $\marlin$.
  Let $k \in \NN$ be the number of committed polynomials, $l \in \NN$ number of evaluation
  points, $\vec{c} \in \GRP^k$ be the commitments, $\vec{z} \in \FF_p^l$ be the arguments
  the polynomials are evaluated at, $\vec{s} \in \FF_p^k$ the evaluations, and
  $\vec{o}, \vec{o}' \in \FF_p^l$ be the commitment openings. Then for every $\ppt$ adversary $\adv$
	\[
		\condprob{
			\begin{matrix}
				  \verify(\srs, \vec{c}, \vec{z}, \vec{s}, \vec{o}) = 1,  \\ 
				  \verify(\srs, \vec{c}, \vec{z}, \vec{s}, \vec{o'}) = 1, \\
				 \vec{o} \neq \vec{o'}
			\end{matrix}
		}{
			\begin{matrix}
%				& \srs \gets \kgen(\secparam, \maxdeg),\\
				  (\vec{c}, \vec{z}, \vec{s}, \vec{o}, \vec{o'}) \gets \adv^{\initU}(\maxdeg)
			\end{matrix}
		}\leq \negl\,.
	\]
\end{description}
We show
that $\plonk$'s, $\sonic$'s, and $\marlin$'s polynomial commitment schemes satisfy this
requirement in \cref{lem:pcomp_op} and \cref{lem:pcoms_unique_op}
respectively.


\begin{description}
\item[Hiding:] We also formalize notion of $k$-hiding property of a polynomial commitment scheme. Let $\HHH$ be a set of size $\maxdeg + 1$ and $\ZERO_\HHH$ its
  vanishing polynomial. We say that a polynomial scheme is \emph{hiding} with
  security $\epsh(\secpar)$ if for every $\ppt$ adversary $\adv$, $k \in \NN$,
  probability
  \begin{align*}
    \condprob
   { b' = b}{
    (f_0, f_1, c, k, b') \gets \adv^{\initU, \oraclec}(\maxdeg, c), f_0, f_1 \in \FF^{\maxdeg}
    [X]}
\leq \frac{1}{2} + \eps(\secpar).
  \end{align*}
  Where $c = f'_b (\chi)$, for a random bit $b$ and the polynomial
      $f'_b (X) = f_b + \ZERO_\HHH (X) (a_0 + a_1 X + \ldots a_{k - 1} X^{k -
        1})$,
and the oracle $\oraclec$ on adversary's evaluation query $x$ it adds $x$ to initially empty set
      $Q_x$ and if $|Q_x| \leq k$, it provides $f'_b (x)$.
 
  \end{description}

\begin{description}
\item[Commitment of knowledge:] Intuitively, when a commitment scheme is ``of knowledge'' then if an
adversary produces a (valid) commitment $c$, which it can open correctly in an evaluation point, then it must
know the underlying polynomial $\p{f}$ which commits to that value.  For every $\ppt$ adversary $\adv$ who produces
  commitment $c$, evaluation $s$ and opening $o$ there
  exists a $\ppt$ extractor $\ext$ such that
\[
  \condprob{
    \begin{matrix}
       \deg \p{f} \leq \maxdeg,
       c = \com(\srs, \p{f}),\\
       \verify(\srs, c, z, s, o) = 1
    \end{matrix}
        }{
    \begin{matrix}
      %
     % & \srs \gets \kgen(\secparam, \maxdeg),\\
      c \gets \adv^{\initU}(\maxdeg),
      z \sample \FF_p \\
      (s, o) \gets \adv(c, z), \\
   \p{f} = \ext_\adv(\srs, c)\\
    \end{matrix}}
  \geq 1 - \epsk(\secpar).
\]
In that case we say that $\PCOM$ is $\epsk(\secpar)$-knowledge.
\end{description}


\cref{fig:pcomp,fig:pcoms} present variants of KZG~\cite{AC:KatZavGol10} polynomial
commitment schemes used in \plonk{}, \sonic{} and \marlin{}. The key generation algorithm
$\kgen$ takes as input a security parameter $\secparam$ and a parameter $\maxdeg$ which
determines the maximal degree of the committed polynomial. We assume that $\maxdeg$ can be
read from the output SRS. While the figures only describe trusted SRS setup, it is not
hard to lift the SRS generation into the updatable setting by defining the extra
algorithms $\upd$, $\verifyCRS$ (see~\cref{def:upd-scheme}) as described in~\cref{fig:upd-scheme}.  \cite{CCS:MBKM19}
shows, using AGM, that $\PCOMs$ is a commitment of knowledge.  The same reasoning could be
used to show that property for $\PCOMp$.
 



\begin{figure}[t!]
	\centering
	\fbox{
		\begin{minipage}[t]{0.76\linewidth}
			\procedure{$\kgen(\REL)$}{
				\chi \sample \FF_p \\ [\myskip]
				\srs := 
				\left( \gone{\smallset{\chi^i}_{i = 0}^{\dconst}},
				\gtwo{\chi} \right); 
				\rho =  \left(\gone{\chi, \chi}, \gtwo{\chi}\right) \\ [\myskip]
				\pcreturn (\srs, \rho) \\ [\myskip]
			}
		%
		\\
		%
		\procedure{$\verifyCRS(\srs, \{\rho_j \}_{j=1}^n)$}{
			\text{Parse }  \srs \text{ as } \left( \gone{\smallset{A_i}_{i = 0}^{\dconst}},
			\gtwo{B} \right) \text{and } \{\rho_j \}_{j=1}^n \text{ as } \left\{\left( P_j, \bP_j, \hP_j \right)\right\}_{j=1}^n \\ [\myskip]
			\text{Verify Update proofs: } \\ [\myskip]
			\t \bP_1 = P_1 \\ [\myskip]
			\t P_j \bullet \gtwo{1} = P_{j-1} \bullet \hP_j \quad \forall j \geq 2 \\ [\myskip]
			\t \bP_n \bullet \gtwo{1} = \gone{1} \bullet \hP_n \\ [\myskip]
			\text{Verify SRS structure: } \\ [\myskip]
			\t \gone{A_i} \bullet \gtwo{1} = \gone{A_{i-1}} \bullet \gtwo{B} \text{ for all } 0 < i \leq \dconst \\ [\myskip]
		}
		%
		\\
		%
		\procedure{$\upd(\srs, \{\rho_j \}_{j=1}^n)$}{
			\text{Parse } \srs \text{ as } \left( \gone{\smallset{A_i}_{i = 0}^{\dconst}},
			\gtwo{B} \right) \\ [\myskip]
			\chi' \sample \FF_p  \\ [\myskip]
			\srs' := 
			\left( \gone{\smallset{{\chi'}^i A_i}_{i = 0}^{\dconst}},
			\gtwo{\chi' B} \right); 
			\rho' =	\left( \gone{\chi' A_1, \chi'}, \gtwo{\chi'}\right) \\ [\myskip]
			\pcreturn (\srs', \rho')
		}
		\end{minipage}}
	\caption{Updatable SRS scheme for $\PCOMp$} 
	\label{fig:upd-scheme}
\end{figure}


\begin{figure}
  \small
\centering
\begin{pcvstack}[center,boxed]
		\begin{pchstack}
			\procedure{$\kgen(\secparam, \maxdeg)$}
			{
			\chi \sample \FF^2_p \\ [\myskip]
			\pcreturn \gone{1, \ldots, \chi^{\numberofconstrains + 2}}, \gtwo{\chi}\\ [\myskip]
				\hphantom{\hspace*{5.5cm}}	
        %\hphantom{\pcind \p{o}_i(X) \gets \sum_{j = 1}^{t_i} \gamma_i^{j - 1}
        %\frac{\p{f}_{i,j}(X) - \p{f}_{i, j}(z_i)}{X - z_i}}
      }
			
			\pchspace
			
			\procedure{$\com(\srs, \vec{\p{f}}(X))$}
			{ 
				\pcreturn \gone{\vec{c}} = \gone{\vec{\p{f}}(\chi)}\\ [\myskip]
				\hphantom{\pcind \pcif 
					\sum_{i = 1}^{\abs{\vec{z}}} r_i \cdot \gone{\sum_{j = 1}^{t_j}
					\gamma_i^{j - 1} c_{i, j} - \sum{j = 1}^{t_j} s_{i, j}} \bullet
				\gtwo{1} + }
			}
		\end{pchstack}
		% \pcvspace
    
		\begin{pchstack}
			\procedure{$\open(\srs, \vec{\gamma}, \vec{z}, \vec{s}, \vec{\p{f}}(X))$}
			{
			\pcfor i \in \range{1}{\abs{\vec{z}}} \pcdo\\ [\myskip]
      \pcind \p{o}_i(X) \gets \sum_{j = 1}^{t_i} \gamma_i^{j - 1}
      \frac{\p{f}_{i,j}(X) - \p{f}_{i, j}(z_i)}{X - z_i}\\ [\myskip] \pcreturn
      \vec{o} = \gone{\vec{\p{o}}(\chi)}\\ [\myskip]
				\hphantom{\hspace*{5.5cm}}	
			}
			
			\pchspace
			
			\procedure{$\verify(\srs, \gone{c}, \vec{z}, \vec{s}, \gone{\p{o}(\chi)})$}
			{
				\vec{r} \gets \FF_p^{\abs{\vec{z}}}\\ [\myskip]
				\pcfor i \in \range{1}{\abs{\vec{z}}} \pcdo \\ [\myskip]
				\pcind \pcif 
          \sum_{i = 1}^{\abs{\vec{z}}} r_i \cdot \gone{\sum_{j = 1}^{t_j}
          \gamma_i^{j - 1} c_{i, j} - \sum{j = 1}^{t_j} s_{i, j}} \bullet
          \gtwo{1} + \\ [\myskip] \pcind \sum_{i = 1}^{\abs{\vec{z}}} r_i z_i
          o_i
          \bullet \gtwo{1} \neq \gone{- \sum_{i = 1}^{\abs{\vec{z}}} r_i o_i }
          \bullet \gtwo{\chi} \pcthen  \\
					\pcind \pcreturn 0\\ [\myskip]
					\pcreturn 1.
			}
		\end{pchstack}
	\end{pcvstack}
	\caption{$\PCOMp$ polynomial commitment scheme.}
	\label{fig:pcomp}
  \end{figure}

% \begin{figure}[h!]
% \centering
% 	\begin{pcvstack}[center,boxed]
% 		\begin{pchstack}
% 			\procedure{$\kgen(\secparam, \maxdeg)$} {
% 				\alpha, \chi \sample \FF^2_p \\ [\myskip]
% 				\pcreturn \gone{\smallset{\chi^i}_{i = -\multconstr}^{\multconstr},
%           \smallset{\alpha \chi^i}_{i = -\multconstr, i \neq
%             0}^{\multconstr}},\\
%         \pcind \gtwo{\smallset{\chi^i, \alpha \chi^i}_{i =
%             -\multconstr}^{\multconstr}}, \gtar{\alpha}\\
% 				%\markulf{03.11.2020}{} \\
% 			%	\hphantom{\pcind \p{o}_i(X) \gets \sum_{j = 1}^{t_i} \gamma_i^{j - 1} \frac{\p{f}_{i,j}(X) - \p{f}_{i, j}(z_i)}{X - z_i}}
% 				\hphantom{\hspace*{5.5cm}}
% 		}
%
% 			\pchspace
%
% 			\procedure{$\com(\srs, \maxconst, \p{f}(X))$} {
% 				\p{c}(X) \gets \alpha \cdot X^{\dconst - \maxconst} \p{f}(X) \\ [\myskip]
% 				\pcreturn \gone{c} = \gone{\p{c}(\chi)}\\ [\myskip]
% 				\hphantom{\pcind \pcif \sum_{i = 1}^{\abs{\vec{z}}} r_i \cdot
%           \gone{\sum_{j = 1}^{t_j} \gamma_i^{j - 1} c_{i, j} - \sum_{j = 1}^{t_j}
%             s_{i, j}} \bullet \gtwo{1} + } }
% 		\end{pchstack}
% 		% \pcvspace
%
% 		\begin{pchstack}
% 			\procedure{$\open(\srs, z, s, f(X))$}
% 			{
% 				\p{o}(X) \gets \frac{\p{f}(X) - \p{f}(z)}{X - z}\\ [\myskip]
% 				\pcreturn \gone{\p{o}(\chi)}\\ [\myskip]
% 				\hphantom{\hspace*{5.5cm}}
% 			}
%
% 			\pchspace
%
% 			\procedure{$\verify(\srs, \maxconst, \gone{c}, z, s, \gone{\p{o}(\chi)})$}
%       {
%         \pcif \gone{\p{o}(\chi)} \bullet \gtwo{\alpha \chi} + \gone{s - z
%         \p{o}(\chi)} \bullet \gtwo{\alpha} = \\ [\myskip] \pcind \gone{c}
%         \bullet \gtwo{\chi^{- \dconst + \maxconst}} \pcthen  \pcreturn 1\\
%         [\myskip]
%         \rlap{\pcelse \pcreturn 0.} \hphantom{\pcind \pcif \sum_{i =
%             1}^{\abs{\vec{z}}} r_i \cdot \gone{\sum_{j = 1}^{t_j} \gamma_i^{j -
%               1} c_{i, j} - \sum{j = 1}^{t_j} s_{i, j}} \bullet \gtwo{1} + } }
% 		\end{pchstack}
% 	\end{pcvstack}
%
% 	\caption{$\PCOMs$ polynomial commitment scheme.}
% 	\label{fig:pcoms}
% \end{figure}

\subsection{Unique opening property of $\PCOMp$}
Now, we show that the version of the KZG polynomial
commitment scheme that is used in \plonk{}, $\PCOMp$, has the unique opening
property.

\begin{lemma}
\label{lem:pcomp_op}
Let $\PCOMp$ be a batched version of a KZG polynomial commitment,
cf.~\cref{fig:pcomp}, then $\PCOMp$ has the unique opening property  
 in the AGM with security
$\epsop(\secpar) \leq 2 \epsdlog(\secpar) + \infrac{1}{\abs{\FF_p}}$, where
$\epsdlog(\secpar)$ is security of the $(\noofc + 2, 1)$-$\udlog$ assumption and
$\FF_p$ is the field used in $\PCOMp$.\end{lemma}
\begin{proof}
  Let $\vec{z} = (z, z') \in \FF_p^2$ be the two points the polynomials are
  evaluated at, $k \in \NN$ be the number of the committed polynomials to be
  evaluated at $z$, $k' \in \NN$ be the number of the committed polynomials
  to be evaluated at $z'$, $\vec{c} \in \GRP^k, \vec{c'} \in \GRP^{k'}$ be the
  commitments, $\vec{s} \in \FF_p^k, \vec{s'} \in \FF_p^{k'}$ the evaluations,
  and $\vec{o} = (o, o') \in \FF_p^2$ be the commitment openings.  We need to
  show that the probability a $\ppt$ $\adv$ opens the same commitment in two
  different ways is at most $\epsop(\secpar)$, even when the commitment openings
  are verified in batches.

  The idealised verifier checks whether the following equality, for $\gamma, r'$
  picked at random, holds:
  \begin{multline}
    \label{eq:ver_eq_poly}
    \left(\sum_{i = 1}^{k} \gamma^{i - 1} \cdot \p{f}_i(X) - \sum_{i = 1}^{k}
      \gamma^{i - 1} \cdot s_i\right) + r' \left(\sum_{i = 1}^{k'} \gamma'^{i -
        1} \cdot \p{f'}_i(X) -
      \sum_{i = 1}^{k'} \gamma'^{i - 1} \cdot s'_i \right)\\
    \equiv \p{o}(X)(X - z) + r' \p{o}'(X)(X- z').
  \end{multline}
  Since $r'$ has been picked at random from $\FF$, probability that
  \cref{eq:ver_eq_poly} holds while either
  \[
    \sum_{i = 1}^{k} \gamma^{i - 1} \cdot \p{f}_i(X) - \sum_{i = 1}^{k}
    \gamma^{i - 1} \cdot s_i \not\equiv \p{o}(X)(X - z) \text{, or}
  \]
  \[
    \sum_{i = 1}^{k'} \gamma'^{i - 1} \cdot \p{f'}_i(X) - \sum_{i = 1}^{k'}
    \gamma'^{i - 1} \cdot s'_i \not\equiv \p{o'}(X)(X - z')
  \]
  is $\infrac{1}{\abs{\FF_p}}$~cf.~\cite{EPRINT:GabWilCio19}. 
  When \(
    \sum_{i = 1}^{k} \gamma^{i - 1} \cdot \p{f}_i(X) - \sum_{i = 1}^{k}
    \gamma^{i - 1} \cdot s_i = \p{o}(X)(X - z) 
  \)
  holds, polynomial $\p{o}(X)$ is uniquely determined from the uniqueness of
  polynomial composition. Similarly, $\p{o'}(X)$ is uniquely determined as well.

  Any discrepancy
  between the idealised verifier rejection and real verifier acceptance allows
  one to break the discrete logarithm problem.

%  \textcolor{red}{Old: The reduction $\rdvdlog$ proceeds as follows: $\rdvdlog$ builds a SRS $\srs$ using the input $\dlog$ instance. I.e., it answers $\adv$'s queries for SRS updates and sets the honest update of the SRS to be $\srs$. Let $\srs'$ be the finalised SRS. 
%  Consider a proof $\zkproof$ such
%      that $\vereq_{\inp, \zkproof}(X) \neq 0$, but
%      $\vereq_{\inp, \zkproof}(\chi') = 0$. Since $\adv$ is algebraic, all proof
%      elements are extended by their representation as a
%      combination of the input $\GRP_1$-elements. Therefore, all coefficients of the
%      verification equation polynomial $\vereq_{\inp, \zkproof}(X)$ are known.
%   Now, $\rdvdlog$ computes the roots of $\vereq_{\inp, \zkproof}(X)$ and finds $\chi'$ among
%      them.
%    Let $\chi_1, \ldots, \chi_\ell$ be the partial trapdoors of $\adv$'s SRS updates that are extracted by $\rdvdlog$ from the update proofs given by $\adv$.
%  $\rdvdlog$ returns $\chi = \chi' (\chi_1 \chi_2 \ldots \chi_\ell)^{-1}$.}

  \chb{The reduction $\rdvdulog$ proceeds as follows: $\rdvdulog$ answers $\adv$'s queries for SRS updates according to the answers it receives from its dlog update oracle. When $\adv$ finalizes a SRS, $\rdvdulog$ finalizes the corresponding dlog challenge. 
  	Consider a proof $\zkproof$ such
  	that $\vereq_{\inp, \zkproof}(X) \neq 0$, but
  	$\vereq_{\inp, \zkproof}(\chi') = 0$. Since $\adv$ is algebraic, all proof
  	elements are extended by their representation as a
  	combination of the input $\GRP_1$-elements. Therefore, all coefficients of the
  	verification equation polynomial $\vereq_{\inp, \zkproof}(X)$ are known.
  	Now, $\rdvdulog$ computes the roots of $\vereq_{\inp, \zkproof}(X)$ and finds $\chi'$ among
  	them. $\rdvdulog$ returns $\chi'$.}
  
  Since any discrepancy
  between the idealised verifier and real verifier rejection allows
  one to break the discrete logarithm problem, the probability that the real
  verifier accepts in one of the cases above is upper-bounded by
  $2 \epsdlog + \infrac{1}{\FF_p}$.

    \qed
\end{proof}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
