% !TeX spellcheck = en_GB
\let\accentvec\vec
\documentclass[runningheads,11pt]{llncs}
 % \documentclass[runningheads]{amsart}
\let\spvec\vec
\let\vec\accentvec

\usepackage{amssymb,amsmath}
\let\vec\spvec
\usepackage{lmodern}

\usepackage[T1]{fontenc}

\newcommand{\iflipics}[1] {}
\newcommand{\iflncs}[1] {#1}

\def\vec#1{\mathchoice{\mbox{\boldmath$\displaystyle#1$}}
	{\mbox{\boldmath$\textstyle#1$}}
	{\mbox{\boldmath$\scriptstyle#1$}}
	{\mbox{\boldmath$\scriptscriptstyle#1$}}}

\DeclareFontFamily{U}{mathx}{\hyphenchar\font45}
\DeclareFontShape{U}{mathx}{m}{n}{<-> mathx10}{}
\DeclareSymbolFont{mathx}{U}{mathx}{m}{n}
\DeclareMathAccent{\widebar}{0}{mathx}{"73}

% lncs size (as printed in books, with small margins):
\usepackage[paperheight=23.5cm,paperwidth=15.5cm,text={13.2cm,20.3cm},centering]{geometry}

\newcommand{\ifamsart}[1] {}
\ifamsart{
	\newtheorem{theorem}{Theorem}%[section]
	\newtheorem{proposition}[theorem]{Proposition}
	\newtheorem{lemma}[theorem]{Lemma}
	\newtheorem{corollary}[theorem]{Corollary}
	\theoremstyle{definition}
	\newtheorem{definition}[theorem]{Definition}
	\newtheorem{example}[theorem]{Example}
}
\usepackage{soul}
\usepackage{soulutf8}
\soulregister\cite7
\soulregister\ref7
\soulregister\pageref7
\usepackage{hyperref}
\usepackage[color=yellow]{todonotes}
\hypersetup{final}
\usepackage{mathrsfs}
\usepackage[advantage,asymptotics,adversary,sets,keys,ff,lambda,primitives,events,operators,probability,logic,mm,complexity]{cryptocode}
\usepackage[capitalise]{cleveref}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{paralist}
\usepackage[innerleftmargin=5pt,innerrightmargin=5pt]{mdframed}

\include{macros}

\title{On Simulation-Extractability of \textsc{Plonk}}

\author{Markulf Kohlweiss\inst{1,2} \and Michał Zając\inst{3}}
\iflncs{
  \institute{University of Edinburgh, Edinburgh, UK \and IOHK \\ \email{mkohlwei@inf.ed.ac.uk} \and Clearmatics, London UK \\ \email{m.p.zajac@gmail.com}}
}

\allowdisplaybreaks

\begin{document}
	\sloppy
	\maketitle

\begin{abstract}
	In this paper we prove that the most-efficient updatable universal zkSNARK---\plonk{}~\cite{EPRINT:GabWilCio19}---is (non black-box) simulation extractable.
	To that end, we generalise the result by Faust et al.~\cite{INDOCRYPT:FKMV12} (INDOCRYPT 2012) and show that any special-sound proof of knowledge that has the unique response property is also simulation-extractable if made non-interactive by the Fiat--Shamir transform. 
	We then explain why \plonk{} meets these requirements and conclude by showing its simulation-extractability.
	Unfortunately, we also show that relying on rewinding and Fiat--Shamir transform often comes at a great price of inefficient knowledge extraction and the security loss introduced by these techniques should always be taken into account.
	Because of the inefficiency and loosenes of the reduction we independently show that $\plonk{}$ is simulation-sound. 
	\task{15.05}{Check Sonic and Bulletproofs}
\end{abstract}

\section{Introduction}
\subsection{Motivation}
\paragraph{The rise of updatable zkSNARKs.}
\cite{C:GKMMM18}
\cite{EC:CHMMVW20}
\cite{CCS:MBKM19}
\cite{EPRINT:GabWilCio19}
\cite{EPRINT:Gabizon19c}
\cite{EPRINT:Lipmaa19a}

\paragraph{On the importance of the simulation extractability.}
\cite{AC:DHLW10}
\cite{AC:Groth07}
\cite{EPRINT:AbdRamSla20}
\cite{EPRINT:KZMQCP15}
\cite{EPRINT:AtaBag19}

\paragraph{State of the art---simulation-extractable updatable zkSNARKs.}
Up to our best knowledge, there are zkSNARKs that are simulation-extractable and zkSNARKs that are updatable, however there is no known zkSNARKs that enjoy both of these properties.
Given an updatable zkSNARK one could lift it to be simulation-extractable \michals{23.09}{Cite Coco, Lamassu, some Karim's work (?)}, but such lift comes with inevitably efficiency loss.
On the other hand, there is no known lift that would take a zkSNARK and make it updatable. Since updatable zkSNARKs are quite restrictive regarding format of their CRSs, making such lift seems as a very difficult task. 

\subsection{Our contribution}
First of all, we prove that $\plonk$ is simulation-extractable. Although we do not change the original protocol at all, we had to solve a number of problems in order to show that. The idea of the proof is presented below. 

Note that \plonk{}, as presented in \cite{EPRINT:GabWilCio19}, is a non-interactive protocol, which relies on an interactive proof of knowledge and the Fiat--Shamir transform. Thus, we denote the underlying protocol by $\plonkprot$ and the resulting, non-interactive one by $\plonkprot_\fs$. 

\subsubsection{Special soundness of $\plonkprot$.}
To be able to follow \cite{INDOCRYPT:FKMV12} it had to be shown that $\plonkprot$ is special-sound. However the standard definition of special soundness could not be met.
First of all, the standard definition requires extraction of a witness from merely two transcripts, each containing three messages, that share the first message. For $\plonkprot$ that gives nothing. The definition had to be tuned to cover protocols that have more rounds than just three. 
Furthermore, the number of transcripts required is much greater---$\numberofconstrains + 3$, where $\numberofconstrains$ is the number of constrains in the proven circuit---to be exact. Hence, we do not have a \emph{pair of transcripts}, but \emph{tree of transcripts}.

Secondly, the protocol has a trapdoor what allows an adversary who knows it to produce multiple proofs even without knowing the witness. Recall that the standard special soundness definition requires witness extraction from \emph{any} pair of acceptable transcripts that share a common root. Thus, the definition cannot be met. However, one could define a weaker version of special soundness, i.e.~a computational special soundness. More precisely, we show that either it is possible to extract a witness from a tree of acceptable transcripts or one could use the adversary that produced the tree to break some underlying computational assumption.

\subsubsection{Unique response property of $\plonkprot$.}
Another property that has to be proven for $\plonkprot$ is the unique response property \cite{C:Fischlin05} which states that except the first round, all messages sent by the prover are deterministic. As previously, we also could not use this definition right out of the box as $\plonkprot$ does not follow it---both first and the second prover's messages are randomised. We thus propose a generalisation of the definition which states that a protocol is $\ur{i}$ if the prover is deterministic after sending its $3$-rd message. This property $\plonkprot$ follows.

\subsubsection{Generalisation of the general forking lemma.}
Consider an interactive $3$-round special-sound protocol $\ps$ and its non-interactive version $\ps_\fs$ obtained by using the Fiat--Shamir transform. The general forking lemma provides an instrumental lower bound for probability of extracting a witness from two proofs for the same statement that share the first message.
Since $\plonkprot$ has $10$ rounds and is not special-sound, the forking lemma cannot be used directly. We thus propose its modification that covers protocols that have more rounds and require more transcript than merely two. 
Unfortunately, when more transcripts is needed the security gap is big. That is, probability that the extractor succeeds diminishes significantly. (That said, we have to note that the security loss is polynomial, albeit huge.)

We observe here that some modern zkSNARKs rely on the Fiat--Shamir transform and
the forking lemma heavily. First, an interactive protocol is proposed and its
security and special-soundness analysed; second, one uses an argument that the
Fiat--Shamir transform can be used to get a protocol that is non-interactive and
shares the same security properties.  We claim here that such an analysis is not
enough and one has to consider the security loss implied by the generalisation
of the forking lemma or disclose a transformation that does not suffer from the
the generalisation's inefficiency.

\subsubsection{Towards simulation-extractability.} Given modified, less
restrictive, definition for special-soundness and unique response property, and
generalised forking lemma we are able to show the announced result---simulation
extractability of $\plonkprot_\fs$. The proof is inspired by simulation-extractability and simulation-soundness proofs from \cite{INDOCRYPT:FKMV12}, with major modifications, which were required as \cite{INDOCRYPT:FKMV12} considers (Fiat--Shamir transformed) sigma-protocols that are undoubtedly simpler protocols than $\plonkprot_\fs$.
Since the proof highly relies on the (generalised) forking lemma, the security lost it introduces is considerable.

\subsubsection{Efficient simulation-soundness.}
Given that the security reduction for simulation-extractability introduces a security gap we also present a proof for $\plonkprot_\fs$ simulation soundness which utilises the algebraic group model and is tight. 
It remains an open question how to show simulation extractability tightly, e.g.~using AGM.

\subsubsection{Interactive zero knowledge vs non-interactive zero knowledge.}
Another issue we tackle with is a question whether NIZK proof systems are in fact zero-knowledge, see e.g.~\cite{C:Pass03}. This problem was raised as one could observe that a NIZK proof system has a property alien to interactive proofs---a verifier who obtains a proof $\zkproof$ for a statement $\inp \in \LANG$ inevitably learns how to prove this statement. More precisely, he can just reuse the obtained proof $\zkproof$. This makes the verifier learn undoubtedly more than simply the veracity of the proven statement. On the other hand, the verifier learns a particular proof $\zkproof$ for a concrete CRS $\crs$ only. However, the CRS generator is considered trusted, thus the proof $\zkproof$ could be considered as a proof for $\inp$ generally, regardless the CRS.

Simulation-extractable updatable NIZKs---and zkSNARKs in particular---tighten
the gap between interactive zero knowledge and non-interactive zero knowledge in
the CRS model. First, simulation-extractability assures that no adversary can
maul an existing proof and make a fresh one, what limits replay attacks. Second,
updatable NIZKs does not assume that there is a trusted party that provides a
CRS, but rather a sequence of parties (called updaters) that modify it. The
security model is radically different as now one believes in the veracity of a
proof only if she trusts that there is at least one honest party between the
updaters. 

We believe that our result may be useful for designing new zkSNARKs, especially those based on a polynomial commitment schemes~\cite{AC:KatZavGol10}, as it shows that a careful protocol design may give it a strong security notion for free.

\section{Preliminaries}
Let PPT denote probabilistic polynomial-time.
Let $\secpar \in \NN$ be the security parameter.
All adversaries will be stateful.
For an algorithm $\adv$, let $\image (\adv)$ be the image of $\adv$ (the set of valid outputs of $\adv$), let $\RND{\adv}$ denote the random tape of $\adv$ (assuming the given value of $\secpar$), and let $r \sample \RND{\adv}$ denote the random choice of the randomiser $r$ from $\RND{\adv}$.
We denote by $\negl$ an arbitrary negligible function.

Distributions $X$ and $Y$ have \emph{statistical distance} $\SD$ equals $\epsilon$ if $\sum_{a \in \supp{X \cup Y}} \abs{\prob{X = a} - \prob{Y = a}} = \epsilon$.
We write $X \approx_\secpar Y$ if $\SD(X, Y) \leq \negl$, where $\SD$ is the statistical distance between the distributions.
For values $a$ and $b$ we write $a \approx_\secpar b$ if $\abs{a - b} \leq \negl$.

Denote by $\RELGEN$ a \emph{relation generator}---a PPT algorithm that on input $\secparam$ outputs an $\npol$ relation $\REL$. We assume that if $\RELGEN$ provides any auxiliary input to $\REL$, it is benign. Directly from the description of $\REL$ one learns security parameter $\secpar$ and other necessary information like a description of a group $\GRP$, if the relation is a relation of group elements (as it usually is in case of zkSNARKs).

\paragraph{Bilinear groups.}
A bilinear group generator $\pgen (1^\secpar)$ returns $(p, \GRP_1, \GRP_2, \GRP_T, \pair, \gone{1}, \gtwo{1})$, where $\GRP_1$, $\GRP_2$, and $\GRP_T$ are additive cyclic groups of prime order $p = 2^{\Omega (\secpar)}$, $\gone{1}, \gtwo{1}$ are generators of $\GRP_1$, $\GRP_2$, resp., and $\pair: \GRP_1 \times \GRP_2 \to \GRP_T$ is a non-degenerate PPT-computable bilinear pairing.
We assume the bilinear pairing to be Type-3, i.e., that there is no efficient isomorphism from $\GRP_1$ to $\GRP_2$ or from $\GRP_2$ to $\GRP_1$.
We use the by now standard bracket notation, i.e., we write $\bmap{a}{\gi}$ to denote $a g_{\gi}$ where $g_{\gi}$ is a fixed generator of $\GRP_{\gi}$.
We denote $\pair (\gone{a}, \gtwo{b})$ as $\gone{a} \bullet \gtwo{b}$.
Thus, $\gone{a} \bullet \gtwo{b} = \gtar{a b}$.
We freely use the bracket notation with matrices, e.g., if $\vec{A} \vec{B} = \vec{C}$ then $\vec{A} \grpgi{\vec{B}} = \grpgi{\vec{C}}$ and $\gone{\vec{A}}\bullet \gtwo{\vec{B}} = \gtar{\vec{C}}$.

\paragraph{Compuational assumptions.}

\begin{definition}[$(q_1, q_2)\mhyph\dlog$ assumption]
	Let $\adv$ be a PPT adversary that gets as input $\gone{1, \chi, \ldots, \chi^{q_1}}, \gtwo{1, \chi, \ldots, \chi^{q_2}}$, for some randomly picked $\chi \in \FF_p$, then
	\[
		\condprob{\chi \gets \adv(\gone{1, \chi, \ldots, \chi^{q_1}}, \gtwo{1, \chi, \ldots, \chi^{q_2} })}{\chi \sample \FF_p} \leq \negl.
	\]
\end{definition}

\paragraph{Proofs by Game-Hoping.}
Proofs by \emph{game hoping} is a method of writing proofs popularised by e.g.~Shoup \cite{EPRINT:Shoup04} and Dent \cite{EPRINT:Dent06c}. The method relies on the following lemma.

\begin{lemma}[Difference lemma,  cf.~{\cite[Lemma 1]{EPRINT:Shoup04}}]
	\michals{22.09}{To be moved to preliminaries}
	\label{lem:difference_lemma}
	Let $\event{A}, \event{B}, \event{F}$ be events defined in some probability distribution, and suppose that $\event{A} \land \nevent{F} \iff \event{B} \land \nevent{F}$. 
	Then 
	\[
		\abs{\prob{\event{A}} - \prob{\event{B}}} \leq \prob{\event{F}}\,.
	\]
\end{lemma}

\subsection{Polynomial commitment.}
\label{sec:poly_com}

\begin{description}
	\item[Evaluation binding]
	\item[Opening uniqueness] 
	\michals{24.09}{Do we still need that?}
	\[
		\Pr
			\left[
			\begin{aligned}
				& \verify(\crs, \vec{c}, \vec{z}, \vec{s}, \vec{o}),  \\ 
				& \verify(\crs, \vec{c}, \vec{z}, \vec{s'}, \vec{o'}), \\
				& \vec{o} \neq \vec{o'}
			\end{aligned}
			\,\left|\,
			\begin{aligned}
				& \crs \gets \kcrs(\secparam),\\
				& (\vec{c}, \vec{z}, \vec{s}, \vec{s'}, \vec{o}, \vec{o'}) \gets \adv(\crs)
			\end{aligned}
			\right.\right] \leq \negl
	\]
\end{description}

\subsection{Algebraic Group Model}



\subsection{}

\subsection{Zero knowledge}
In a zero-knowledge proof or argument system, a prover convinces the verifier of the veracity of a statement without leaking any side information except that the statement is true.
Here, a proof (resp., an argument) system guarantees soundness against an unbounded (resp., a PPT) cheating prover.
The zero-knowledge property is proven by constructing a simulator that can simulate the view of a cheating verifier without knowing the secret information---witness---of the prover.

More precisely, let $\RELGEN(\secparam)$ be a relation generator that outputs an $\npol$ relation $\REL = \smallset{(\inp, \wit)}$. \markulf{09.07.20}{Not too fond of relation
  generators, but guess this is more general
  than family of relations.} Denote by $\LANG_\REL$ the language determined by $\REL$.
Let $\prover$ and $\verifier$ be algorithms, the former called \emph{prover} and the latter \emph{verifier}.
We denote by $\ip{\prover(\REL, \inp, \wit)}{\verifier(\REL, \inp)}$ a transcript of conversation between a $\prover$ with input $(\REL, \inp, \wit)$ and $\verifier$ with input $(\REL, \inp)$.
We write $\ip{\prover (\REL, \inp, \wit)}{\verifier(\REL, \inp)} = 1$ if in the end of the transcript the verifier $\verifier$ returns $1$ and say that $\verifier$ accepts the transcript.

\markulf{09.07.20}{Could also all quantify for Soundness and Zero knowledge?}
\michals{09.07.20}{I am not sure what you meant here. You want to have for all $\inp, \wit \in \REL$ or you doubt these properties make sense for all $\REL \gets \RELGEN$?}
A proof system $\proofsystem = (\prover, \verifier, \simulator)$ for $\RELGEN$ is required to have three properties: completeness, soundness and zero knowledge, which are defined as follows:
\begin{description}
	\item[Completeness] An interactive proof system $\proofsystem$ is \emph{complete} if an honest prover always convinces an honest verifier, that is for all $\REL \gets \RELGEN(\secparam)$ and $(\inp, \wit) \in \REL$
	\[
		\prob{\ip{\prover (\REL, \inp, \wit)}{\verifier (\REL, \inp)} = 1} = 1\,.
	\]
	\item[Soundness] We say that $\proofsystem$ for $\RELGEN$ is \emph{sound} if no PPT prover $\adv$ can convince an honest verifier $\verifier$ to accept a proof for a false statement, i.e~for $\inp \not\in\LANG$. More precisely, for all $\REL \gets \RELGEN(\secparam)$
	\[
		\condprob{\ip{\adv(\REL, \inp)}{\verifier(\REL, \inp)} = 1}{\inp \gets \adv(\REL); \inp \not\in \LANG_\REL} \leq \negl\,;
	\]
	\item[Zero knowledge] We call an interactive proof system $\proofsystem$ \emph{zero-knowledge} if for any $\REL \gets \RELGEN(\secparam)$ and adversary $\adv$ there exists a $\ppt$ simulator $\simulator$ such that
	\begin{multline*}
	  \left\{\ip{\prover(\REL, \inp, \wit)}{\adv(\REL, \inp, \wit)} \,\left|\, (\inp, \wit) \gets \adv(\REL)\vphantom{\simulator^\adv}\right.\right\} \approx_\secpar
		\\
		\left\{\simulator^{\adv}(\REL, \inp)\,\left|\, (\inp, \wit) \gets \adv(\REL)\vphantom{\simulator^\adv}\right.\right\}\,.
	\end{multline*}
	%
	We call zero knowledge \emph{perfect} if the distributions are equal and \emph{computational} if they are indistinguishable for any NUPPT distinguisher.
	
	Sometimes a stronger notion of soundness is required---except requiring that the verifier rejects proofs of statements outside the language, we request from the prover to know a witness corresponding to the proven statement. This property is formalised by the following notion:
	
	\item[Knowledge soundness] We call an interactive proof system $\proofsystem$ \emph{knowledge-sound} if for any $\REL \gets \RELGEN(\secparam)$ and a PPT adversary $\adv$
	% \begin{multline*}
	\[
	\Pr\left[
		\begin{aligned}
			& \text{$\trans$ is acceptable} \\
			& \land \REL(\inp, \wit) = 0
	 \end{aligned}
	  \,\left|\,
	 \begin{aligned}
		 & (\td, \crs) \gets \kcrs(\REL), \inp \gets \adv(\REL,\crs), \\
		 & (\wit, \trans) \gets \ext^{\ip{\adv(\REL, \crs, \inp)}{\verifier(\REL, \crs, \inp)}}(\REL, \inp)
	 \end{aligned}
	 \vphantom{\begin{aligned}
		 \adv (\trans) = 1, \\
		 \text{if $\trans{}$ is accepting} \\
		 \pcind \text{then $\REL(\inp, \wit)$}
	 \end{aligned}}\right.
	 \right] \leq \negl\,,
 % \end{multline*}
 \]
\end{description}

\paragraph{NIZKs in the Random Oracle Model.}
In NIZKs in the Random Oracle Model we distinguish, for the sake of clarity, two simulators, one denoted by $\simulator_\zkproof$ that is responsible for providing simulated proofs and $\simulator_\ro$ that picks a random oracle instantiation and takes care of all parties' queries to $\ro$.
% \michals{9.06}{Should we distinguish two simulators or just pack everything into a single one?}
For the sake of consistency (with random oracle-free NIZKs) we use $\simulator$
to denote the pair of state-sharing simulators $\simulator_\zkproof,
\simulator_\ro$.

\paragraph{Sigma protocols.}
A sigma protocol $\sigmaprot = (\prover, \verifier, \simulator)$  for a relation
$\REL \gets \RELGEN(\secparam)$  is a special case of an interactive proof which transcript compounds of three messages $(a, b, z)$, the middle being a challenge provided by the verifier.
Sigma protocols are specially-sound. That is, there exists an extractor $\ext$ which from two accepting transcripts $(a, b, z)$, $(a, b', z')$ for a statement $\inp$ can recreate the corresponding witness if $b \neq b'$. Formally,
\begin{description}
	\item[Special soundness] A sigma protocol $\sigmaprot$ is \emph{specially-sound} if for any adversary $\adv$ the probability
	\[
		\Pr\left[
		\begin{aligned}
				& \wit \gets \ext(\REL, \inp, (a, b, z), (a, b', z')),\\
				& \REL(\inp, \wit) = 0
		\end{aligned}
		\,\left|\,
		\begin{aligned}
			& (\inp, (a, b, z), (a, b', z')) \gets \adv(\REL), \\
			& \verifier(\REL, \inp, (a, b, z)) = \\
			& \qquad = \verifier(\REL, \inp, (a, b', z')) = 1, \\
		\end{aligned}
		\right.\right]
	\]
	is negligible in $\secpar$.
\end{description}

Furthermore sigma protocols are \emph{honest verifier zero-knowledge} (HVZK). That is the zero-knowledge property holds only for honest verifiers, what is formalized as follows:
\begin{description}
	\item[Honest verifier zero knowledge] A sigma protocol $\sigmaprot$ is \emph{honest verifier zero-knowledge} if for all adversaries $\adv$ holds
	\begin{multline*}
		\left\{\ip{\prover(\REL, \inp, \wit)}{\verifier(\REL, \inp)} \,\left|\, (\inp, \wit) \gets \adv(\REL)\vphantom{\simulator_\zkproof^\adv}\right.\right\} \approx_\secpar
		\left\{\simulator_\zkproof^{\verifier}(\REL, \inp)\,\left|\, (\inp, \wit) \gets \adv(\REL)\vphantom{\simulator^\adv}\right.\right\}\,.
	\end{multline*}
\end{description}
Although this notion is weaker than a standard zero knowledge it is often sufficient. Furthermore, a HVZK interactive proof system transformed by the Fiat--Shamir transformation is zero-knowledge.

Another property that sigma protocols sometimes have is, introduced by Fischlin \cite{C:Fischlin05}, a unique response property which states that no PPT adversary  can produce two accepting transcripts that differ only on the last element.
More precisely,
\begin{description}
	\item[Unique response property] Let $\sigmaprot = (\prover, \verifier, \simulator)$ be a standard-model sigma-protocol for relation $\REL \gets \RELGEN(\secparam)$ which proofs compound of three messages $(\alpha, \beta, \gamma)$. We say that $\sigmaprot$ is has a unique response property if for all PPT algorithms $\adv$ holds
	\[
	\condprob{\verifier (\alpha, \beta, \gamma) = \verifier (\alpha, \beta, \gamma')  = 1}{(\alpha, \beta, \gamma, \gamma') \gets \adv(\REL)} \leq \negl\,.
	\]
\end{description}
(If the unique response property holds even against unbounded adversaries, we call it \emph{strict}, cf.~\cite{INDOCRYPT:FKMV12}.)
Later on we often call protocols that follows this notion ur-protocols.
For the sake of completeness we note that many sigma-protocols, like e.g.~Schnorr's protocol \cite{C:Schnorr89}, fulfil this requirement.

\paragraph{Zero knowledge proof system in the CRS model.}
Many proof systems additionally compounds of a setup algorithm $\kcrs$ that on input $\REL$ outputs a common reference string (CRS) $\crs$. The common reference string comes with a corresponding trapdoor $\td$ that allows the simulator to simulate a proof.

\subsection{Simulation extractable NIZKs from sigma protocols}
Real life applications often require from a NIZK proof system to be non-malleable. That is, no adversary seeing a proof $\zkproof$ for a statement $\inp$ should be able to provide a new proof $\zkproof'$ related to $\zkproof$.
A strong version of non-malleability is formalised by simulation extractability.
This notion states that no adversary can produce valid proof without knowing
the corresponding witness. This must hold even if the adversary is allowed to see polynomially many simulated proofs for any statements it wishes.

\begin{definition}[Simulation-extractable NIZK]
	\label{def:simext}
	\michals{22.09}{To be moved to preliminaries}
	Let $\ps = (\kgen, \prover, \verifier, \simulator)$ be a special-sound HVZK proof and $\ps_\fs = (\kgen_\fs, \prover_\fs, \verifier_\fs, \simulator_\fs)$ be $\ps$ transformed by the Fiat--Shamir transform. 
	We say that $\ps_\fs$ is simulation extractable with \emph{extraction error} $\nu$ if for any PPT adversary $\adv$ that is given oracle access to a random oracle $\ro$ and simulator $\simulator_\fs$, and produces an accepting transcript of $\ps$ with probability
	$\waccProb$, that is
	\[
		\waccProb = \Pr \left[
		\begin{aligned}
			& \verifier_\fs(\REL, \crs, \inp_\advse, \zkproof_\advse) = 1,\\
			& (\inp_\advse, \zkproof_\advse) \not\in Q
		\end{aligned}
		\, \left| \,
		\begin{aligned}
			& \crs \gets \kgen(\REL, \secparam),\\
			& (\inp_\advse, \zkproof_\advse) \gets \advse^{\simulator_\fs, \ro} (\REL, \crs) 
		\end{aligned}
		\right.\right]\,,
	\]
	probability
	\[
		\frkProb = \Pr \left[
		\begin{aligned}
			& \verifier_\fs(\REL, \crs, \inp_\advse, \zkproof_\advse) = 1,\\
			& (\inp_\advse, \zkproof_\advse) \not\in Q,\\
			& \REL(\inp_\advse, \wit_\advse) = 0
		\end{aligned}
		\, \left| \,
		\begin{aligned}
			& \crs \gets \kgen(\REL, \secparam),\\
			& (\inp_\advse, \zkproof_\advse) \gets \advse^{\simulator_\fs, \ro} (\REL, \crs) \\
			& \wit_\advse \gets \ext_\ss (\trans_{\advse}) 
		\end{aligned}
		\right.\right]
	\]
	is at at least 
	\[
		\frkProb \geq \frac{1}{\poly} (\waccProb - \nu)^d - \eps(\secpar)\,,
	\]
	for some polynomial $\poly$, constant $d$ and negligible $\eps$ whenever $\waccProb \geq \nu$.
\end{definition}

% \begin{definition}[Simulation extractability]
% 	A proof system $\proofsystem$ is computationally (adaptively) \emph{strongly simulation-extractable for $\RELGEN$}, if for every NUPPT $\adv$, there exists a NUPPT extractor $\ext_\adv$, s.t.
% 	\[
% 	\condprob{
%   \begin{aligned}
%     &(\inp, \wit) \not\in \REL,\\
% 		&(\inp, \zkproof) \not\in Q, \\
%     & \verifier (\REL, \crs, \inp, \zkproof) = 1
%   \end{aligned}
%   }
%   {
% 		\begin{aligned}
% 		& \REL \gets \RELGEN (\secparam),
% 		(\crs, \td) \gets \kgen (\REL), r \sample \RND{\adv},
% 		\\ &
% 		((\inp, \zkproof)  \|  \wit) \gets (\adv^{\oracleo}  \|  \ext_\adv) (\REL, \crs; r)
% 		\end{aligned}
% 	} \leq \negl \enspace,
% 	\]
% 	where $\oracleo$ on input $\inp'$ returns $\zkproof' \gets \simulator(\REL, \crs, \td, \cdot)$ and writes $(\inp', \zkproof')$ to a list $Q$.
% \end{definition}

% Faust et al.~\cite{INDOCRYPT:FKMV12} show every
Consider a sigma protocol $\sigmaprot = (\prover, \verifier, \simulator)$ that
is specially sound and has a unique response property. Let $\sigmaprot_\fs = (\prover_\fs, \verifier_\fs, \simulator_\fs)$ be a NIZK obtained by applying the Fiat--Shamir transform to $\sigmaprot$.
Faust et al.~\cite{INDOCRYPT:FKMV12} show that every such $\sigmaprot_\fs$ is simulation-extractable.

\begin{theorem}[Simulation extractability of the Fiat--Shamir transform \cite{INDOCRYPT:FKMV12}]
	Let $\sigmaprot = (\prover, \verifier, \simulator_\zkproof)$ be a non-trivial sigma protocol with unique responses for a language $\LANG \in \npol$.
	In the random oracle model, the NIZK proof system $\sigmaprot_\fs = (\prover_\fs, \verifier_\fs, \simulator_{\fs})$ resulting by applying the Fiat--Shamir transform to $\sigmaprot$ is simulation extractable with extraction error $\eta = q/h$ for the simulator $\simulator$. Here, $q$ is the number of random oracle queries and $h$ is the number of elements in the range of $\ro$.
	% Furthermore, the extractor $\ext_\adv$ needs to run $\adv^{\simulator_{\fs, \ro}}, \adv^{\simulator_{\fs, \zkproof}}$ twice.
\end{theorem}

The theorem relies on the following classical lemma, called \emph{General forking lemma} \cite{JC:PoiSte00}.

\begin{lemma}[General forking lemma, cf.~\cite{INDOCRYPT:FKMV12,CCS:BelNev06}]
	\label{lem:forking_lemma}
	Fix $q \in \ZZ$ and a set $H$ of size $h > 2$. Let $\adv$ be a PPT algorithm that on input $y, h_1, \ldots, h_q$ returns $(i, s)$, where $i \in\range{0}{q}$ and $s$ is called a \emph{side output}.
	Denote by $\ig$ a randomised instance generator.
	We denote by $\accProb$ the probability
	\[
		\condprob{i > 0}{y \gets \ig; h_1, \ldots, h_q \sample H; (i, s) \gets \adv(y, h_1, \ldots, h_q)}\,.
	\]
	Let $\forking_\adv(y)$ denote the algorithm described in \cref{fig:forking_lemma}, then the probability $\frkProb$ defined as
	$
		\frkProb := \condprob{b = 1}{y \gets \ig; (b, s, s') \gets \forking_{\adv}(y)}
	$
	holds
	\[
		\frkProb \geq \accProb \brak{\frac{\accProb}{q} - \frac{1}{h}}\,.
	\]
	%
	\begin{figure}
		\centering
		\fbox{
		\procedure{$\forking_\adv (y)$}
		{
			r \sample \RND{\adv}\\
			h_1, \ldots, h_q \sample H\\
			(i, s) \gets \adv(y, h_1, \ldots, h_q; r)\\
			\pcif i = 0\ \pcreturn (0, \bot, \bot)\\
			h'_{i}, \ldots, h'_{q} \sample H\\
			(i', s') \gets \adv(y, h_1, \ldots, h_{i - 1}, h'_{i} h'_{q}; r)\\
			\pcif (i = i') \land (h_{i} \neq h'_{i})\ \pcreturn (1, s, s')\\
			\pcind \pcelse \pcreturn (0, \bot, \bot)
		}}
		\caption{Forking algorithm $\forking_\adv$}
		\label{fig:forking_lemma}
\end{figure}
\end{lemma}
%
In case of a sigma protocol, the probability $\frkProb$ can be interpreted as a lower bound for a successful witness extraction from two transcripts.
Let $\tr_1 = (\inp, a, z, \gamma)$ and $\tr_2 = (\inp, a, z', \gamma')$ be the transcripts.
Both $\tr_1$ and $\tr_2$ have to be \emph{acceptable}, i.e.~$i > 0$ and the probability that $\adv$ makes an acceptable transcript is denoted by $\accProb$. 
Index $i$ can be interpreted as an index of $h_i$ which was sent as a challenge for $(\inp, a)$, this index has to be guessed by the security reduction. 
For the sake of extractability, both transcripts have to have the same index $i$, i.e.~the same instance $\inp$ and the first message $a$, but the actual challenges $z = h_i$ and $z' = h'_{i}$ have to differ.

\section{Towards simulation extractability for multi-round protocols---definitions and lemmas}
Unfortunately, Faust et al.'s result cannot be directly applied in our case since the protocols we consider have more than three rounds of interaction, require more than just two transcript for the extractor to work and $\plonkprot$ is not special sound.

\subsection{Generalised forking lemma.}
First of all, although dubbed ``general'', \cref{lem:forking_lemma} is not general enough for our purpose as it useful only for protocols that extract witness from two transcripts. 
To be able to extract a witness from a $\plonkprot$ execution we need to obtain at least $\numberofconstrains + 3$ transcripts.
Fortunately, since the witness can be extracted by repeating only one round of the protocol, we can proceed similarly as in a protocol that utilises only one challenge.

Here we propose a generalisation of the general forking lemma that given probability $\accProb$ gives a lower bound on the probability of generating a \emph{tree of accepting transcripts}, which could be used to extract a witness. 

\begin{lemma}[General forking lemma II]
	\label{lem:generalised_forking_lemma}
	Fix $q \in \ZZ$ and set $H$ of size $h \geq m$. 
	Let $\adv$ be a PPT algorithm that on input $y, h_1, \ldots, h_q$ returns $(i, s)$ where $i \in \range{0}{q}$ and $s$ is called a side output. 
	Denote by $\ig$ a randomised instance generator. We denote by $\accProb$ the probability
	\[
		\condprob{i \neq 0}{ y \gets \ig;\ h_1, \ldots, h_q \sample H;\ (i, s) \gets \adv(y, h_1, \ldots, h_q)}\,.
	\]
	Let $\genforking_\adv$ denote the algorithm described in \cref{fig:genforking_lemma} then the probability $\frkProb := \condprob{b = 1}{y \gets \ig;\ (b, \vec{s}) \gets \genforking_\adv(y)}$ is at least 
	\[
		\frac{\accProb^m}{q^{m - 1}} - \frac{(m - 1) \cdot \accProb}{h}\,.
	\]
		
	\begin{figure}
		\centering
		\fbox{
		\procedure{$\genforking_\adv (y)$}
		{
			r \sample \RND{\adv}\\
			h_1, \ldots, h_{i - 1} \sample H\\
			\pcfor j \in \range{1}{m}\\
			\pcind h_{i_j}, \ldots, h_{q_j} \sample H\\
			\pcind (i_j, s_j) \gets \adv(y, h_1, \ldots, h_{i - 1}, h_{i_j}, \ldots, h_{q_j}; r)\\
			\pcind \pcif i = 0\ \pcreturn (0, \bot, \bot)\\
			\pcif \forall j, j'  \in \range{1}{m}\colon (i_{j} = i_{j'}) \land (h_{i_j} \neq h_{i_{j'}})\ \pcreturn (1, \vec{s})\\
			\pcind \pcelse \pcreturn (0, \bot, \bot)
		}}
		\caption{Generalised forking algorithm $\genforking_\adv$}
		\label{fig:genforking_lemma}
\end{figure}
\end{lemma}
\begin{proof}
	\michals{3.08.20}{DISCLAIMER: This proof is a naive generalisation of the general forking lemma from Bellare and Neven 06. Need to check that all (in)equalities hold!}
	We proceed similarly as in \cite{CCS:BelNev06} (with some parts taken almost verbatim).
	
	First let denote by $\accProb(y)$ and $\frkProb(y)$ the following probabilities
	\begin{align*}
		\accProb(y) & =  \condprob{i \neq 0}{h_1, \ldots, h_q \sample H;\ (i, s) \gets \adv(y, h_1, \ldots, h_q)}\,.\\
		\frkProb(y) & = \condprob{b = 1}{(b, \vec{s}) \gets \genforking_\adv(y)}\,.
	\end{align*}
	
	We start by claiming that for all $y$ 
	\begin{equation}\label{eq:frkProb_y}
		\frkProb(y) \geq 
			\frac{\accProb(y)^m}{q^{m - 1}} - \frac{(m - 1) \cdot  \accProb(y)}{h}\,.
	\end{equation}
	Then with the expectation taken over $y \sample \ig$, we have
	\begin{align}
		\frkProb & = \expected{\frkProb(y)} \geq \expected{\frac{\accProb(y)^m}{q^{m - 1}} - \frac{(m - 1) \cdot  \accProb(y)}{h}} \label{eq:use_eq1}\\
		& = \frac{\expected{\accProb(y)^m}}{q^{m - 1}} - \frac{(m - 1) \cdot \expected{\accProb(y)}}{h} \\
		& \geq \frac{\expected{\accProb(y)}^m}{q^{m - 1}} - \frac{(m - 1) \cdot \expected{\accProb(y)}}{h} \label{eq:by_lemma_jensen}\\
		& = \frac{\accProb^m}{q^{m - 1}} - \frac{(m - 1) \cdot  \accProb}{h}\label{eq:by_accProb}\,.
	\end{align}
	Where Ineq.~(\ref{eq:use_eq1}) comes from \cref{eq:frkProb_y};   Ineq.~(\ref{eq:by_lemma_jensen}) comes from \cref{lem:jensen}; and (\ref{eq:by_accProb}) holds by the fact that $\expected{\accProb(y)} = \accProb$.
	
	We now show \cref{eq:frkProb_y}.
	Denote by $J = \range{1}{m}^2 \setminus \smallset{(j, j)}_{j \in \range{1}{m}}$. 
	For any input $y$, with probabilities taken over the coin tosses of $\genforking_\adv$ we have
	\begin{align*}
		\frkProb (y) & = \prob{i_j = i_{j'} \land i_j \geq 1 \land h_{i_j} \neq h_{i_{j'}} \text{ for } (j, j') \in J}	\\
		& \geq \prob{i_j = i_{j'} \land i_j \geq 1 \text{ for } (j, j') \in J} \\
		& \qquad - \prob{i_j \geq 1 \land h_{i_j} = h_{i_{j'}} \text{ for some } (j, j') \in J}\\
		& = \prob{i_j = i_{j'} \land i_j \geq 1 \text{ for } (j, j') \in J} - \prob{i_j \geq 1} \cdot \frac{m - 1}{h} \\
		& = \prob{i_j = i_{j'} \land i_j \geq 1 \text{ for } (j, j') \in J} - \accProb(y) \cdot \frac{m - 1}{h}\,.
	\end{align*}
	It remains to show that $\prob{i_j = i_{j'} \land i_j \geq 1 \text{ for } (j, j') \in J} \geq \infrac{\accProb(y)^m}{q^{m - 1}}$.
	
	Let $\RND{\adv}$ denote the set from which $\adv$ picks its coins at random. For each $\iota \in \range{1}{q}$ let $X_\iota \colon \RND{\adv} \times H^{\iota - 1} \to [0, 1]$ be defined by setting $X_\iota(\rho, h_1, \ldots, h_\iota)$ to
	\[
		\condprob{i = \iota}{h_\iota, \ldots, h_q \sample H; (i, \vec{s}) \gets \adv(y, h_1, \ldots, h_q; \rho)} 
	\] 
	for all $\rho \in \RND{\adv}$ and $h_1, \ldots, h_{\iota - 1} \in H$. Consider $X_\iota$ as a random variable over the uniform distribution on its domain. 
	Then
	\begin{align*}
		& \prob{i_j = i_{j'} \land i_j \geq 1 \text{ for } (j, j') \in J} \\
		& = \sum_{\iota = 1}^{q} \prob{i_1 = \iota \land \ldots \land i_m = \iota} \\
		& = \sum_{\iota = 1}^{q} \prob{i_1 = \iota} \cdot \condprob{i_2 = \iota}{i_1 = \iota} \cdot \ldots \cdot \condprob{i_m = \iota}{i_1 = \ldots = i_{m - 1} = \iota} \\
		& = \sum_{\iota = 1}^{q} \sum_{\rho, h_1, \ldots, h_{\iota - 1}} X_{\iota} (\rho, h_1, \ldots, h_{\iota - 1})^{m} \cdot \frac{1}{\abs{\RND{\adv}} \cdot \abs{H}^{\iota - 1}}\\
		& = \sum_{\iota = 1}^{q} \expected{X_\iota^m} \,.
	\end{align*}
	Then by \cref{lem:jensen} we get
	\[
		\sum_{\iota = 1}^{q} \expected{X_\iota^m} \geq \sum_{\iota = 1}^{q} \expected{X_\iota}^m\,.
	\]
	We note that for e.g.~$X_i = 1$, $i \in \range{1}{q}$ the inequality becomes equality, that is, it is tight.
	 
	We now use the H\"older inequality from \cref{lem:holder} where we set  $x_i = \expected{X_i}$, $y_i = 1$, $p = m$, and $q = m/(m - 1)$ obtaining
	\begin{gather}
		\sum_{i = 1}^{q} \expected{X_i}  \leq \left(\sum_{i = 1}^{q} \expected{X_i}^m\right)^{\frac{1}{m}} \cdot \left(\sum_{i = 1}^{q} 1^\frac{m}{m - 1}\right)^{\frac{m - 1}{m}} \label{eq:tightness} \\
		\left(\sum_{i = 1}^{q} \expected{X_i}\right)^{m}  \leq \left(\sum_{i = 1}^{q} \expected{X_i}^m\right) \cdot q^{m - 1}\\
		\frac{1}{q^{m - 1}} \cdot \accProb(y)^{m} \leq \sum_{i = 1}^{q} \expected{X_i}^m\,.
	\end{gather}
	Finally, we get
	\[
		\frkProb(y) \geq \frac{\accProb(y)^m}{q^{m - 1}} - 
		\frac{(m - 1) \cdot \accProb(y)}{h}\,.
	\]
	\qed
\end{proof}

\begin{remark}[Tightness of \cref{eq:tightness}]
	In is important to note that Inequality (\ref{eq:tightness}) is tight. More precisely, for $\expected{X_i} = x$, $i \in \range{1}{q}$ we have
	\begin{gather*}
		\sum_{i = 1}^q x = \left(\sum_{i = 1}^{q} x^m\right)^\frac{1}{m} \cdot \left(\sum_{i = 1}^{q} 1^{\frac{m}{m - 1}}\right)^{\frac{m - 1}{m}} \\
		qx = \left(qx^m\right)^\frac{1}{m} \cdot q^{\frac{m - 1}{m}} \\
		(qx)^m = qx^m \cdot q^{m - 1} \\
		(qx)^m = (qx)^m\,.
	\end{gather*}
\end{remark}

\begin{lemma}\label{lem:jensen}
	Let $\RND{\adv}$ denote the set from which $\adv$ picks its coins at random. For each $\iota \in \range{1}{q}$ let $X_\iota \colon \RND{\adv} \times H^{\iota - 1} \to [0, 1]$ be defined by setting $X_\iota(\rho, h_1, \ldots, h_\iota)$ to 
	\[
		\condprob{i = \iota}{h_\iota, \ldots, h_q \sample H; (i, \vec{s}) \gets \adv(y, h_1, \ldots, h_q; \rho)} 
	\] 
	for all $\rho \in \RND{\adv}$ and $h_1, \ldots, h_{\iota - 1} \in H$. Consider $X_\iota$ as a random variable over the uniform distribution on its domain. 
	Then $\expected{X_\iota^m} \geq \expected{X_\iota}^m$.
\end{lemma}
\begin{proof}
	First we recall the Jensen inequality \cite{W:Weissten20}, if for some random variable $X$ holds $\abs{\expected{X}} \leq \infty$ and $f$ is a Borel convex function then 
	\[
		f(\expected{X}) \leq \expected{f(X)}\,.
	\] 
	Finally, we note that $\abs{\expected{X}} \leq \infty$ and taking to thee $m$-th power is a Borel convex function on $[0, 1]$ interval. 
	\qed
\end{proof}

\begin{lemma}[H\"older's inequality. Simplified.]\label{lem:holder}
	Let $x_i, y_i$, for $i \in \range{1}{q}$, and $p, q$ be real numbers such that $1/p + 1/q = 1$. Then
	\[
		\sum_{i = 1}^{q} x_i y_i \leq \left(\sum_{i = 1}^{q} x_i^p\right)^{\frac{1}{p}} \cdot \left(\sum_{i = 1}^{q} y_i^p\right)^{\frac{1}{q}}\,.
	\]
\end{lemma}

\subsection{Unique-response protocols.}
Another problem comes with another assumption required by Faust et al. That is, the unique response property of the transformed sigma protocol.
Fischlin's formulation, although perfectly fine for applications presented in \cite{C:Fischlin05}, is not enough in our case.
First of all, the property assumes that the protocol has three rounds, with the middle being the challenge from the verifier. That is not the case we consider here. Second, it is not entirely clear how to generalize the property. Should one require that after the first challenge from the verifier the responses are fixed? That could not work since if there is more challenges then they are random.
Another problem rises when the protocol contains some round---obviously, except the first one---where the prover randomises his message. In that case unique-responsiveness can not hold as well.
Last but not least, the protocol we consider here most, \plonk, is not in a standard-model, but utilises CRS. That also complicates things considerably.

We walk around these obstacles by providing a generalized notion of the unique response property.
More precisely, we say that a $(2\mu + 1)$-round protocol has \emph{unique responses after $i$} and is called a $\ur{i}$-protocol if
\begin{definition}[$\ur{i}$-protocol]
	\label{def:wiur}
	Let $\proofsystem$ be a multi-round proof system.
	Denote by $a_0, b_0, \ldots, a_{\mu - 1}, b_{\mu - 1}, a_{\mu}$ the consecutive messages exchanged in the protocol, where messages $a_i$ come from the prover and $b_i$ from the verifier.
	We say that $\proofsystem$ has \emph{unique responses after $i$}
	if after submitting its $i$-th message the prover is a deterministic function. That is, it does not use his randomness tape and deterministically answers verifier's challenges.
\end{definition}
\begin{example}
	The Schnorr protocol is $\ur{1}$. That is, after submitting his first message $a$, the prover is a deterministic function of the instance, $a$, and the verifier's challenge.
\end{example}

We note that the definition above is independent on whether the proof system $\proofsystem$ utilises CRS (and compounds of the CRS-generating $\kgen$ algorithm) or not.
% Furthermore it is also blind whether $\proofsystem$ is interactive or not.
\michals{08.07.20}{Should we change it to "deterministic prover property"?}

\subsection{Computational special soundness}
Note that the special soundness property (as usually defined) holds for all--- even computationally unbounded---adversaries. Since a simulation trapdoor for $\plonkprot$ exists, it is not special sound in that regard---as an unbounded adversary could reveal the trapdoor and build a number of simulated proofs for a fake statement. 
Hence, we provide a weaker, yet sufficient, definition of \emph{computational special soundness}. More precisely, we state that an adversary that is able to answer correctly multiple challenges either knows the witness or can be used to break some computational assumption. 

\begin{definition}[Computational special soundness]
	Let $\proofsystem$ be an $2k$-round zero-knowledge proof system for a relation $\REL$. 
	We say that $\proofsystem$ is $(n_1, \ldots, n_k)$-\emph{special sound} if for every PPT adversary $\adv$ that produces an accepting $(n_1, \ldots, n_k)$ tree of transcripts $\tree$ for a statement $\inp$ there exists an extractor $\ext$ that given $\tree$ extracts $\wit$ such that $\REL(\inp, \wit) = 1$ with an overwhelming probability.
\end{definition}

\section{Simulation-extractability---the general result}
\task{24.09}{Put here a general result -- a special sound, ur protocol is sim. ext after FS}

\section{Simulation extractability of $\plonkprotfs$} 
In this section we show that $\plonkprotfs$
is not only simulation-sound, but also simulation-extractable. To that end, we
proceed as follows. 
First we show that the version of the KZG polynomial commitment scheme that is proposed in the \plonk{} paper has the unique opening property, cf.~\cref{sec:poly_com} and \cref{lem:kzg_unique_op}. This is next used to show that $\plonkprot$ has $\ur{3}$ property, cf.~\cref{lem:plonkprot_ur}.

Then, we that 
$\plonkprot$ is (kind of) special-sound. That is, given a number of acceptable
transcripts which match on the first 3 rounds of the protocol we can either
reveal a correct witness for the proven statement or use one of the transcripts
to break the dlog assumption. The latter requires use of the AGM. More
precisely, we assume that each group element that is published as a part of the
transcripts comes with a vector of coefficients that represents the element in
the basis compound of the input group elements, i.e.~$\plonkprot$'s CRS. See \cref{lem:plonkprot_ss}.

Given special-soundness of $\plonkprot$, we use the fact that it is also $\ur{3}$ and show, in a similar fashion to \cite{INDOCRYPT:FKMV12}, that it is simulation-extractable. That is, we build reductions that given a simulation extractability adversary $\advse$ either breaks the protocol's unique response property or breaks the dlog assumption, if extracting a valid witness from a tree of transcripts is impossible. See \cref{thm:plonkprotfs_se}.

\subsection{Unique response property}
\begin{lemma}
	\label{lem:kzg_unique_op}
	Let $\PCOM$ be a batched version of a KZG polynomial commitment \cite{AC:KatZavGol10} as described in \cite{EPRINT:GabWilCio19}. Let $k \in \NN$, $\vec{z}, \vec{o} \in \FF_p^2$, $\vec{c}, \vec{s} \in \ZZ_p^k$, then for every PPT adversary $\adv$	
	\[
		\Pr
			\left[
				\begin{aligned}
					& \PCOM.\verify(\crs, \vec{c}, \vec{z}, \vec{s}, \vec{o}), \\
					& \PCOM.\verify(\crs, \vec{c}, \vec{z}, \vec{s}, \vec{o'}) \\
					% & \vec{s'} \neq \vec{s} \lor 
					&\vec{o'} \neq \vec{o}
				\end{aligned}
			\,\left|\,
			\vphantom{\begin{aligned}
				& \PCOM.\verify(\crs, \vec{c}, \vec{z}, \vec{s}, \vec{o}), \\
				& \PCOM.\verify(\crs, \vec{c}, \vec{z}, \vec{s}, \vec{o'}) \\
				% & \vec{s'} \neq \vec{s} \lor 
				&\vec{o'} \neq \vec{o}
			\end{aligned}}
			\begin{aligned}
				& \crs \gets \PCOM.\kcrs(\secparam), \\
				&	(\vec{c}, \vec{z}, \vec{s}, \vec{s'}, \vec{o}, \vec{o'}) \gets \adv(\crs)
			\end{aligned}
			\right.\right]
		 \leq \negl.
	\]
\end{lemma}
\markulf{30.08}{Explain what $\vec{c}, \vec{z}, \vec{s}, \vec{o}$ are. $\vec{z}$
vector of points? $\vec{s}$ vector of evaluation result}
\begin{proof}
	First, consider a case where the commitment is limited to commit to multiple polynomials which are evaluated at the same point $z$. 
	As noted in \cite[Lemma 2.2]{EPRINT:GabWilCio19} it is enough to upper bound
  the probability of the adversary succeeding using the idealised verification equation, which considers equality between polynomials, instead of the real verification equation, which consider equality of the polynomials' evaluations.
	
	For polynomials $\vec{f} = f_1, \ldots, f_k$, evaluation point $z$, evaluation result $\vec{s} = s_1, \ldots, s_k$, and opening $o$ the idealised check verifies that
	\begin{equation}
		\sum_{i = 1}^k \gamma^{i - 1} f_i(X) - \sum_{i = 1}^{k} \gamma^{i - 1} s_i \equiv o(X) (X - z)\,.
		\label{eq:pcom_idealised_check}
	\end{equation}
	Since $o(X)(X - z) \in \FF_p[X]$ then from the uniqueness of polynomial composition, there is only one $o(X)$ that fulfils the equation above.
	% If the check holds, then 
	% \[
	% 	\sum_{i = 1}^k \gamma^{i - 1} f_i(z) = \sum_{i = 1}^{k} \gamma^{i - 1} s_i\,
	% \]
	% and since $\gamma$ has been picked randomly and independently after the polynomials $\vec{f}$ were submitted it also holds 
	% \(
	% 	f_i(z) =  s_i,
	% \)
	%  for each individual $i \in \range{1}{k}$.
	\qed
\end{proof}
\comment{
\begin{corollary}
	Let $\PCOM$ be a modification of the KZG polynomial commitment scheme
  \cite{AC:KatZavGol10} as presented in \cite{EPRINT:GabWilCio19}. Then $\PCOM$
  is evaluation binding and has unique opening property.
\end{corollary}
}

\begin{lemma}
	\label{lem:plonkprot_ur}
	If a polynomial commitment scheme $\PCOM$ is evaluation binding and has unique openings property\michals{28.08}{Property formalised in Sec 2.1}, then $\plonkprot$ is $\ur{3}$.\footnote{An attentive reader may note that $\plonkprot$ is $\ur{2}$. However, in the case presented here, less is required.}
\end{lemma}
\begin{proof}
	Assume the opposite and an adversary $\adv$ that breaks $\ur{3}$-ness of
  $\plonkprot$. \markulf{30.08}{This is fine. But sounds as if the law of the
    excluded middle is needed here. I am not sure it is. :) Mostly a
    philosophical point.}
	We consider 2 cases, depending on which round $\adv$ is able to provide at
  least two outputs such that the resulting transcripts are acceptable.
  \markulf{30.08}{Rewrote this text: that in each of them $\adv$ breaks the
    evaluation binding property of $\PCOM$.}
  For the first case we show that $\adv$ breaks the evaluation binding property of $\PCOM$, while for the
  second case we show that it breaks the unique opening property of $\PCOM$.
	
	\case{1}
	In Round 4 the prover is asked to give evaluations of predefined polynomials at some point $\chz$. Naturally, for the given polynomials only one value at $\chz$ is correct.
	Assume $\adv$ is able to produce two different outputs in that round: $\vec{r_4} = (\ev{\p{a}}, \ev{\p{b}}, \ev{\p{c}}, \ev{\p{S_{\sigma 1}}}, \ev{\p{S_{\sigma 2}}}, \ev{\p{r}}, \ev{\p{z}})$ and 
	$\vec{r_4} = (\ev{\p{a}}', \ev{\p{b}}', \ev{\p{c}}', \ev{\p{S_{\sigma 1}}}', \ev{\p{S_{\sigma 2}}}', \ev{\p{r}}', \ev{\p{z}}')$
	which suppose to be evaluations at $\chz$ of polynomials $\p{a}, \p{b}, \p{c}, \p{S_{\sigma 1}}, \p{S_{\sigma 2}}, \p{r}$ and an evaluation at $\chz \omega$ of $\p{z}$.
	Clearly, at least one of $\vec{r_4}$, $\vec{r'_4}$ has to be incorrect, thus if both evaluations are acceptable by the $\PCOM.\verify$ then the evaluation binding property of $\PCOM$ is broken.
	
	\case{2}
	In the last round of the protocol the prover provides openings for the polynomial commitments done before. 
	Assume $\adv$ is able to produce two different polynomial commitment openings pairs: 
	$\vec{r_5} = (\ev{\p{W_\chz}}, \ev{\p{W_{\chz \omega}}})$ and 
	$\vec{r'_5} = (\ev{\p{W_\chz}}', \ev{\p{W_{\chz \omega}}}')$.
	% Since \cref{lem:kzg_unique_op}, 
	Since $\PCOM$ has unique opening property, 
	one of the openings has to be incorrect and should be rejected by the polynomial commitment verifier. 
	\michals{28.08}{In this case we also need to show that only one opening for a KZG polynomial commitment is acceptable. This property seems not be covered by the original KZG paper}
	\michals{28.08}{See the lemma above}
	\qed
\end{proof}


\subsection{Special soundness}
\begin{lemma}
	\label{lem:plonkprot_ss}
	Let $\adv$ be a PPT algebraic adversary. The probability $\epsss$ that $\adv$ breaks 
	 $(1, 1, 1, \numberofconstrains + 3, 1)$-computational special soundness of $\plonkprot$ is upper-bounded as
	 \[
	 	\epsss \leq \epsbatch + \epsdlog\,,
	 \] 
	 where $\epsbatch$ is (negligible) probability that $\plonkprot$'s idealised verification equation $\vereq(X)$ accepts an invalid proof because of batching and $\epsdlog$ is a probability that a PPT algorithm can break $(\numberofconstrains + 2, 1)$-dlog assumption.
\end{lemma}
\begin{proof}
	Let $\crs$ be $\plonkprot$'s CRS and denote by $\crs_1$ all CRS's $\GRP_1$-elements; that is, $\crs_1 = \gone{1, \chi, \ldots, \chi^{\numberofconstrains + 2}}$. 
	Let $\adv$ be an algebraic adversary that for a statement $\inp$ produces a $(1, 1, 1, \numberofconstrains + 3, 1)$-tree of acceptable transcripts $\tree$. % with non-negligible probability $\eta_\tree$. 
	Note that in all transcripts the instance $\inp$, proof elements $\gone{\p{a}(\chi), \p{b}(\chi), \p{c}(\chi), \p{z}(\chi), \p{t}(\chi)}$ and challenges $\alpha, \beta, \gamma$ are common as the transcripts share the first three rounds. 
	
	We consider two mutually disjunctive events. 
	First, $\event{E}$ holds when all of the transcripts are acceptable by the idealised verification equation, i.e.~$\vereq(X) = 0$ 
	Second, $\nevent{E}$ holds when there is a transcript that is acceptable, yet 
	for some transcript $\vereq(\chi) = 0$, but $\vereq(X) \neq 0$.
	We build a special extractor $\extss$ which given the tree of transcripts $\tree$ reveals the witness with an overwhelming probability when $\event{E}$ happens. 
	We show a reduction $\rdvdlog$ that, when $\nevent{E}$ happens, breaks the dlog assumption. 
	
	\ncase{When $\event{E}$ happens}  Since the protocol $\plonkprot$ is sound,
	except probability of batching failure $\epsbatch$, for a valid proof
	$\zkproof$ of a statement $\inp$ there exists a witness $\wit$, such that
	$\REL(\inp, \wit)$ holds.  Note that witness-carrying polynomials $\p{a}(X),
	\p{b}(X), \p{c}(X)$ have degree $(\numberofconstrains + 2)$ and since $\adv$
	answered honestly on $(\numberofconstrains + 3)$ different challenges $\chz$
	then $(\numberofconstrains + 3)$ evaluations of these polynomials (at
	different points) are known. The extractor $\extss$ interpolates the
	polynomials and reveals the corresponding witness $\wit$. 
	
	\ncase{When $\nevent{E}$ happens} Consider a transcript that such that
	$\vereq(X) \neq 0$, but $\vereq(\chi) = 0$.
	Since the adversary is algebraic, all group elements included in the tree of
  transcripts are extended by their representation as a combination of the input
  $\GRP_1$-elements i.e.~$\gone{1, \chi, \ldots, \chi^{\numberofconstrains +
      2}}$. Hence all coefficients of the verification equation polynomial
  $\vereq(X)$ are known and $\rdvdlog$ can find its zero points. Since
  $\vereq(\chi) = 0$, the targeted discrete log value $\chi$ is among them.
	\qed
\end{proof}

\subsection{From special-soundness and unique response property to simulation extractability}

Since \cref{lem:plonkprot_ur,lem:plonkprot_ss} hold, $\plonkprot$ is $\ur{3}$ and computationally special sound we are able to follow \cite{INDOCRYPT:FKMV12} and show that $\plonkprot_\fs$ is simulation-extractable as defined in \cref{def:simext}.

\begin{theorem}[Simulation extractability of $\plonkprot_\fs$]
	\label{thm:plonkprotfs_se}
	Assume that $(\numberofconstrains + 2, 1)$-dlog is $\eps_\dlog(\secpar)$-hard and $\plonkprot$ is $\ur{3}$ with security $\epsur(\secpar)$. 
	Let $\ro\colon \bin^* \to \bin^\secpar$ be a random oracle. 
	Let $\advse$ be a PPT adversary that can make up to $q$ random oracle queries and outputs an acceptable proof for $\plonkprotfs$ with probability at least $\waccProb$.
	Then $\plonkprotfs$ is simulation-extractable with extraction error $\eta = \epsur$.
\end{theorem}
\begin{proof}[by game hoping]
	The proof goes by game hoping. The games are controlled by an environment $\env$ that internally tuns a simulation extractability adversary $\advse$, simulates its with access to a random oracle and simulator, and when necessary rewinds it.
	The games differ by various breaking points, i.e.~points where the environment decides to abort the game. 
	
	To show that probability of $\advse$ winning does not change much from game to game we provide reductions $\rdvur$ and $\rdvss$ which seize difference in probabilities to either break $\plonkprot$'s unique response property ($\rdvur$) or its computational special soundness ($\rdvss$).
	\markulf{17.09}{Here we also need the computational special soundness property}
	\markulf{17.09}{The adversary that is being rewound for special soundness}

	% In the following we assume that a reduction $\rdv$, for $\rdv \in \smallset{\rdvur, \rdv_\ss}$, provides $\advse$ with access to a random oracle and simulator. That is, the reductions provide the adversary with simulated proofs. Also, it rewind the adversary when needed.
	Denote by $\zkproof_{\advse}, \zkproof_{\simulator}$ proofs
	returned by the adversary and the simulator respectively. We use $\zkproof[i]$
	to denote prover's message in the $i$-th round of the proof, $\zkproof[i].\ch$
	to denote the challenge that is given to the prover after $\zkproof[i]$, and
	$\zkproof\range{i}{j}$ to denote all messages of the proof including challenges between rounds $i$ and $j$.

	Without loss of generality, for every acceptable proof $\zkproof_{\advse}$, we
	assume that whenever $\advse$ outputs in Round $i$, $i 
	> 3$, a message $m$, then
	$\zkproof_{\advse}\range{1}{i}$ is a fresh query to the random oracle.
	\michals{22.09}{understand it in the light of a new proof approach}
	\michals{22.09}{added ", $i 
	> 3$", for $i \leq 2$ we need to allow the adversary to pick unfresh queries -- as he might randomize the first 2 rounds}
	In the following we denote the instance and proof output by $\advse$ by $\inp_\advse$ and $\zkproof_\advse$ respectively.
	
	\ngame{0} 
	This is a simulation extraction game played between an adversary $\advse$ who has given access to a random oracle $\ro$ and simulator $\plonkprotfs.\simulator$. 
	There is also an extractor $\ext$ that, from the proof $\zkproof_\advse$ for instance $\inp_\advse$ output by the adversary and from a transcripts of $\advse$'s operations, is tasked to extract a witness $\wit_\advse$ such that $\REL(\inp_\advse, \wit_\advse)$ holds.
	$\advse$ wins if it manages to produce an acceptable proof and the extractor fails to reveal the corresponding witness.
	In the following game hops we upper-bound probability that this happens.
	
	% In this game the environment $\env$ runs the adversary $\advse$ and provides it with access to a random oracle $\ro$ and $\plonkprotfs$ simulator $\plonkprotfs.\simulator$. It picks as input a CRS $\crs$ and inputs it to $\advse$.
	% \michals{18.09}{Who provides the CRS? Should it be taken "from the outside", i.e.~should the environment be an algorithm gets $\crs$ from some external $\plonkprot$ instance?}
	% The adversary wins if it provides an acceptable proof $\zkproof_\advse$ for a statement $\inp_\advse$ which it does not know a witness for.
	% \michals{18.09}{Who extracts the witness? Environment $\env$?}\\
	% \michals{18.09}{Is the environment here inefficient? (how it check the winning condition)?}\\
	% \michals{18.09}{Maybe the adversary should win if it gives an acceptable proof for a false statement (and remove the requirement of knowledge of the witness)?}
	
	\ngame{1}
	% \michals{17.09}{$\advse$ wins if there is no extractable witness for its proof, break when $\ur{3}$ broken}
	This is identical to $\game{0}$ except that now the game is aborted if there is a simulated proof $\zkproof_\simulator$ such that $\zkproof_\simulator\range{1}{3} = \zkproof_\advse\range{1}{3}$. That is, the adversary in its final proof reuses a part of a simulated proof it saw before and the proof is acceptable.
	Denote that event by $\event{\errur}$.
	
	\ncase{$\game{0} \mapsto \game{1}$}	
	We have, 
	\[
		\prob{\game{0} \land \nevent{\errur}} = \prob{\game{1} \land \nevent{\errur}}
	\]
	and, from the difference lemma, cf.~\cref{lem:difference_lemma}
	\[
		\abs{\prob{\game{0}} - \prob{\game{1}}} \leq \event{\errur}\,.
	\]
	Thus, to show that the transition from one game to another introduces only minor change in probability of $\advse$ winning it should be shown that $\prob{\event{\errur}}$ is small.
	
	Assume that $\advse$ queried the simulator on $\inp_{\advse}$---the instance which $\advse$ outputs. 
	We show a reduction $\rdvur$ that utilises $\advse$, who outputs a valid proof for $\inp_\advse$, to break the $\ur{3}$ property of $\plonkprot$. 

	Consider an algorithm $\rdvur$ that runs $\advse$ internally as a black-box:
	\begin{itemize}
		\item The reduction answers both queries to the simulator $\plonkprotfs.\simulator$ and to the random oracle. 
		It also keeps lists $Q$, for the simulated proofs, and $Q_\ro$ for the random oracle queries. 
		\item When $\advse$ outputs a fake proof $\zkproof_{\advse}$ for  $\inp_\advse$, $\rdvur$ looks through lists $Q$ and $Q_\ro$ until it finds 
		$\zkproof_{\simulator}\range{1}{3}$ such that $\zkproof_{\advse}\range{1}{2} = \zkproof_{\simulator}\range{1}{2}$ and a random oracle query $\zkproof_{\simulator}[2].\ch$ on $\zkproof_{\simulator}\range{1}{2}$.
		\item $\rdvur$ returns two proofs for $\inp_\advse$:
		\begin{align*}
			\zkproof_1 = (\inp_{\advse},\zkproof_{\simulator}\range{1}{2}, \zkproof_{\simulator}[2].\ch, \zkproof_{\simulator}\range{3}{5})\\
			\zkproof_2 = (\inp_{\advse}, \zkproof_{\simulator}\range{1}{2}, \zkproof_{\simulator}[2].\ch, \zkproof_{\advse}\range{3}{5})
		\end{align*}
		\end{itemize}  
		If $\zkproof_1 = \zkproof_2$, then $\advse$ fails to break simulation extractability, as $\zkproof_2 \in Q$.
		On the other hand, if the proofs are not equal, then $\rdvur$ breaks $\ur{3}$-ness of $\plonkprot$, what may happen with some negligible probability $\epsur$ only, hence
		\[
			\prob{\event{\errur}} \leq \epsur\,.
		\]
		
	\ngame{2}
	% \michals{17.09}{$\advse$ wins if there is no extractable witness for its proof, break when $\ur{3}$ broken or generating tree of transcripts fails}
	This is identical to $\game{1}$ except that now the environment aborts also when it fails to build a $(1, 1, 1, \numberofconstrains + 3, 1)$-tree of accepting transcripts $\tree$ by rewinding $\advse$. Denote that event 
	by $\event{\errfrk}$.
	
	\ncase{$\game{1} \mapsto \game{2}$}	
	As previously, 
	\[
		\abs{\prob{\game{1}} - \prob{\game{2}}} \leq \event{\errfrk}\,.
	\]
	Denote by $\accProb$ the probability that $\advse$ outputs a proof such that is acceptable and does not break $\ur{3}$-ness of $\plonkprot$. 
	From the generalised forking lemma, cf.~\cref{lem:generalised_forking_lemma}, 
	\[
		\prob{\event{\errfrk}} \leq 1 - \left(\frac{\accProb^{\numberofconstrains + 3}}{q^{\numberofconstrains + 2}} - \frac{\accProb \cdot (\numberofconstrains + 2)}{2^\secpar}\right)\,.
	\]
	
	\ngame{3}
	% \michals{17.09}{$\advse$ wins if there is no extractable witness for its proof, break when $\ur{3}$ broken, generating tree of transcripts fails, or special soundness is broken}
	This is identical to $\game{2}$ except that now the environment uses the tree $\tree$ to extract the witness for the proven statement and aborts when it fails. Denote that event by $\event{\errss}$.
	
	\ncase{$\game{2} \mapsto \game{3}$}	
	As previously, 
	\[
		\abs{\prob{\game{2}} - \prob{\game{3}}} \leq \event{\errss}\,.
	\]
	Since $\plonkprot$ is special-sound the probability that $\env$ fails in extracting the witness is upper-bounded by some negligible $\eps_\ss$.
	
	In the last game, Game $\game{3}$, the environment aborts when it fails to extract the correct witness, hence the adversary $\advse$ cannot win. 
	Thus, by the game-hoping argument, 
	\[
		\abs{\prob{\game{0}} - \prob{\game{3}}} \leq 1 - \left(\frac{\accProb^{\numberofconstrains + 3}}{q^{\numberofconstrains + 2}} - \frac{\accProb \cdot (\numberofconstrains + 2)}{2^\secpar}\right) + \epsur + \epsss\,.
	\]
	Thus the probability that extractor $\extss$ succeeds is at least
	\[
		\left(\frac{\accProb^{\numberofconstrains + 3}}{q^{\numberofconstrains + 2}} - \frac{\accProb \cdot (\numberofconstrains + 2)}{2^\secpar}\right) - \epsur - \epsss\,.
	\]
	Since $\accProb$ is probability of $\advse$ outputting acceptable transcript that does not break $\ur{3}$-ness of $\plonkprot$, then $\waccProb \leq \accProb + \epsur$, where $\waccProb$ is the probability of $\advse$ outputing an acceptable proof as defined in \cref{def:simext}. It thus holds
	\[
 		\label{eq:frk}
 		\extProb \geq \frac{(\waccProb - \epsur)^{\numberofconstrains + 3}}{q^{\numberofconstrains + 2}} - \underbrace{\frac{(\waccProb - \epsur) \cdot (\numberofconstrains + 2)}{2^\secpar} - \epsur - \epsss}_{\eps}\,.
 	\]
 	Note that the part of \cref{eq:frk} denoted by $\eps$ is negligible and 
 	\[
 		\extProb \geq \frac{1}{q^\numberofconstrains + 2} (\waccProb - \epsur)^{\numberofconstrains + 3} -\eps\,.
 	\] 
 	thus
 	$\plonkprot_\fs$ is simulation extractable with extraction error $\epsur$.
 	\qed
 \end{proof}

\section{(Tight) simulation soundness of $\plonk$}
\task{28.07}{All proofs in this section should be verified}
% \michals{15.09}{As MK noted, this proof holds only for simulation soundness. For extractability we use special soundness (cf the next section)}

\begin{theorem}[Simulation soundness]
	% \michals{16.09}{To be change to sim snd proof}
	Assume that $(\numberofconstrains + 2, 1)$-dlog is $\eps_\dlog(\secpar)$-hard, $\plonkprot$ is sound and $\ur{3}$ with security $\eps_{\ss}(\secpar)$ and $\epsur(\secpar)$ respectively. 
	Then the probability that an algebraic, PPT adversary $\advss$ breaks simulation soundness of $\plonkprotfs$ is upper-bounded by 
	\[
		\epsur(\secpar) + q_\ro^6 (\eps_{\dlog}(\secpar) + \epss(\secpar))\,,
	\]
	where $q_\ro$ is the total number of queries required by the adversary $\advss$.
\end{theorem}
\begin{proof}
	We proceed by contradiction. Suppose there exists a PPT adversary $\advss$ that breaks simulation soundness with non-negligible probability
	\[
	\eps := \Pr
		\left[
		\begin{aligned}
			& \plonkprotfs.\verifier(\REL, \crs, \inp, \zkproof_{\advss}),\\
			& (\inp_{\advss}, \zkproof_{\advss}) \not\in Q,\\
			& \inp_\advss \not\in \LANG_\REL 
		\end{aligned}
		\,\left|\, 
		\vphantom{\begin{aligned}
			& \plonkprotfs.\verifier(\REL, \crs, \inp, \zkproof_{\advss}),\\
			& (\inp_{\advss}, \zkproof_{\advss}) \not\in Q,\\
			& \inp_\advss \not\in \LANG_\REL 
		\end{aligned}}
		\begin{aligned}
			& \crs \gets \plonkprotfs.\kcrs(\REL, \secparam)\\
			& (\inp_{\advss}, \zkproof_{\advss}) \gets \advss^{\simulator, \ro} (\REL, \crs),		
		\end{aligned}
		\right.\right].
	\]

In such case, we are able to build reductions $\rdvs$, $\rdvur$, $\rdvdlog$ which using $\advss$ as a black-box, violate either the soundness, unique response properties of the underlying interactive protocol $\plonkprot$, or the $(\numberofconstrains + 2, 1)$-dlog assumption.

In the following we denote by $\zkproof_{\advss}, \zkproof_{\simulator}$ proofs
returned by the adversary and the simulator respectively. We use $\zkproof[i]$
to denote prover's message in the $i$-th round of the proof, $\zkproof[i].\ch$
to denote the challenge that is given to the prover after $\zkproof[i]$, and
$\zkproof\range{i}{j}$ to denote all messages of the proof including challenges between rounds $i$ and $j$.

% Without loss of generality, for every acceptable proof $\zkproof_{\advss}$, we
% assume that whenever $\advss$ outputs in Round $i$, $i \geq 3$, a message $m$, then
% $\zkproof_{\advss}\range{1}{i}$ is a fresh query to the random oracle.
% \markulf{30.08}{What does fresh mean here? What about messages coming from the simulator?} 
% \michals{30.08}{I thought that with this assumption we may just consider only queries from $\advss$}
Without loss of generality, we assume that whenever the accepting proof contains a response to a challenge from a random oracle, we assume that the adversary queried the oracle to get it. 
It is straightforward to transform any adversary that violates this condition into an adversary that makes these additional queries to the random oracle and wins with the same probability.

A crucial observation is that the adversary $\advss$ may have learned $\zkproof_{\advss}\range{1}{3}$ by querying the simulator on $\inp_{\advss}$ or might have computed it itself. We denote the first event by $\event{E}$ and the second by $\nevent{E}$. 
%
Additionally, we divide event $\nevent{E}$ into two disjunctive subevents: $\nevent{E}_0$ and $\nevent{E}_1$. 
Event $\nevent{E}_0$ considers a case when the final proof provided by the adversary $\advss$ is accepted by the idealised verification equation, i.e.~for that proof $\vereq(X) = 0$. 
Alternatively, event $\nevent{E}_1$ covers a case when for $\zkproof_\advss$ it
holds that $\vereq(\chi) = 0$, but $\vereq(X) \neq 0$, where $\chi$ is $\plonkprotfs$'s trapdoor.
%
As all these events are mutually exclusive and exhaustive, we have
\[
	\eps = \prob{\advss \text{ wins}} = \prob{\advss \text{ wins}, \event{E}} + \prob{\advss \text{ wins}, \nevent{E}_0} + \prob{\advss \text{ wins}, \nevent{E}_1}\,.
\]


Before analysing the events, we make the following observation.
First of all, we allow reductions $\rdv_\dlog, \rdvur, \rdvs$ to simulate the random oracle and simulator for the adversary $\advss$. We argue that since the reductions in their simulation behaves as real random oracle or simulator would, the chances the adversary breaks simulation soundness does not change. 

Furthermore, we note that since $\advss$ is algebraic, it outputs a proof $\zkproof_\advss$ that can be written as 
\[
	\zkproof_\advss = \vec{M} \cdot (\underbrace{1 \| \chi \| \ldots \| \chi^{\numberofconstrains + 2}}_{\crs} \| \vec{\tilde{\zkproof}_\simulator}_1^{\top} \| \ldots \| \vec{\tilde{\zkproof}_\simulator}_{q_\simulator}^\top)^\top\,,
\]
where $\gone{1, \chi, \ldots, \chi^{\numberofconstrains + 2}}$ are all $\GRP_1$-elements from the CRS of $\plonkprotfs$, $\vec{M}$ is a matrix of coefficients output by $\advss$ aside the proof, $\vec{\tilde{\zkproof}_\simulator}_i$ denote all $\GRP_1$-elements from the simulated proof ${\zkproof_\simulator}_i$, and the adversary makes $q_\simulator$ queries to the simulator. 
Since the reduction itself provides the simulated proofs, it knows a matrix $\vec{M'}$ such that
\begin{equation}
	\label{eq:M_prim}
	\zkproof_\advss = \vec{M'} \cdot (1 \| \chi \| \ldots \| \chi^{\numberofconstrains + 2})^\top\,.
\end{equation}
We use this property when analysing the success probability of reductions $\rdvs$ and $\rdvdlog$.

% Before analyzing the events $\nevent{E}_0$ and $\nevent{E}_1$, 
Also note that a proof $\zkproof$ could be accepted only if the verification equation $\vereq(\chi)$ holds. That is, the verifier plugs-in elements of $\zkproof$ into $\vereq(\chi)$ and checks whether it equals $0$. That is what is called a \emph{real check} in \cite{EPRINT:GabWilCio19}. 
On the other hand there is an \emph{idealised check}, which verifies whether $\vereq(X) = 0$ \emph{as a polynomial}---with proof elements being polynomials as well.

\ncase{When $\event{E}$ happens}
We assume that $\inp_{\advss}$ is submitted to the simulator $\simulator$. 
We show how $\rdvur$ utilizes $\advss$, that makes use of $\inp_\advss, \zkproof_{\advss}\range{1}{3}$, to break the $\ur{3}$ property of $\plonkprot$. 
This way we bound the probability $\prob{\adv \text{ wins}, \event{E}}$ by the probability of $\rdvur$ being able to win in the $\ur{3}$ game.

Consider an algorithm $\rdvur$ that runs $\advss$ internally as a black-box:
\begin{itemize}
	\item The reduction answers both queries to the simulator $\plonkprotfs.\simulator$ and to the random oracle. 
	It also keeps lists $Q$, for the simulated proofs, and $Q_\ro$ for the random oracle queries. 
	\item When $\advss$ outputs a fake proof $\zkproof_{\advss}$ for  $\inp_\advss$, $\rdvur$ looks through lists $Q$ and $Q_\ro$ until it finds 
	$\zkproof_{\simulator}\range{1}{3}$ such that $\zkproof_{\advss}\range{1}{2} = \zkproof_{\simulator}\range{1}{3}$ and a random oracle query $\zkproof_{\simulator}[3].\ch$ on $\zkproof_{\simulator}\range{1}{3}$.
	\item $\rdvur$ returns two proofs for $\inp_\advss$:
	\begin{align*}
		\zkproof_1 = (\zkproof_{\simulator}\range{1}{3}, \zkproof_{\simulator}[3].\ch, \zkproof_{\simulator}\range{4}{5})\\
		\zkproof_2 = (\zkproof_{\simulator}\range{1}{3}, \zkproof_{\simulator}[3].\ch, \zkproof_{\advss}\range{4}{5})
	\end{align*}
	\end{itemize}  
	If $\zkproof_1 = \zkproof_2$, then $\advss$ fails to break simulation extractability, as $\zkproof_2 \in Q$.
	On the other hand, if the proofs are not equal, then $\rdvur$ breaks $\ur{3}$-ness of $\plonkprot$. Thus 
	\[
		\prob{\advss \text{ wins}, \event{E}} \leq \epsur(\secpar).
	\]

\ncase{When $\nevent{E}_0$ happens}
In this case the reduction $\rdvs$ uses $\advss$ to break soundness of $\plonkprot$ with probability $\epss / q_{\ro}^6$, where $q_\ro$ is the number of total random oracle queries performed by the adversary or by $\rdvs$ on behalf of the simulator.
As previously, $\rdvs$ runs $\advss$ internally and simulates its environment by answering to its queries to $\plonkprotfs.\simulator$ and $\ro$. The reduction works as follows:
\begin{itemize}
\item It guesses indices $i_1, \ldots, i_6$ such that random oracle queries $h_{i_1}, \ldots, h_{i_6}$ are the queries used in $\zkproof_\advss$. This is done with probability at least $1/q_{\ro}^6$ (since there are $6$ challenges from the verifier in $\plonkprot$).
	\item On input $h$ for the $i$-th, $i \not\in \smallset{{i_1}, \ldots, {i_6}}$, random
    oracle query, $\rdvs$ returns randomly picked $
    y$, sets $\ro(h) = y $ and stores $(h, y)$ in $Q_\ro$ if $h$ is sent to $\ro$ the first time. If that is not the case, $\rdv$ finds $h$ in $Q_\ro$ and returns the corresponding $y$.
	\item On input $h_{i_j}$ for the $i_j$-th, $i_j \in \smallset{{i_1}, \ldots, {i_6}}$,
    random oracle query, $\rdvs$ parses $h_{i_j}$ as a partial proof transcript
    $\zkproof[1..j]$ and runs $\plonkprot$ using $\zkproof[j]$ as a $\plonkprot.\prover$'s $j$-th message to $\plonkprot.\verifier$. The verifier responds with a challenge $\zkproof[j].\ch$. The reduction sets $\ro(h_{i_j}) = \zkproof[j].\ch$.
	\item On query $\inp_\simulator$ to $\simulator$ it runs a simulator
    $\plonkprotfs.\simulator$ internally and returns $\zkproof_\simulator$. If
    the random oracle query with input $\zkproof_\simulator[j]$, $1 \leq j \leq 2$, of the simulator is the $i_j$-th query,
    generate $\zkproof_\simulator[j].\ch$ by invoking $\plonkprot.\verifier$ on
    $\zkproof_\simulator[j]$ and programming $\ro(h_{i_j}) = \zkproof_\simulator[j].\ch$.
	\item Answers $\plonkprot.\verifier$'s challenge $\zkproof[j].\ch$ using the answer given by $\advss$, i.e.~$\zkproof_\advss[j + 1]$.
\end{itemize}

Assume that the $\plonkprot.\verifier$ accepts $\zkproof_\advss$. We consider a case when the idealised verification equation accepts. (Thus, the real verification accepts as well.) 
In that case $\rdvs$ extracts from $\vec{M'}$ coefficients of $1, \chi, \ldots, \chi^{\numberofconstrains + 2}$ for polynomials $\p{a}(X), \p{b}(X)$, and $\p{c}(X)$ and reveals the witness $\wit_\advss$ (as it is encoded in theses polynomials' coefficients).
If $\REL(\inp_\advss, \wit_\advss)$ holds then $\advss$ failed to break simulation-soundness of $\plonkprotfs$. On the other hand, if that is not the case, then $\rdvs$ breaks soundness of $\plonkprot$.
%
Since the reduction guesses queries $h_{i_1}, \ldots, h_{i_6}$ with probability $1/q_\ro^6$, then 
\[
	\prob{\rdvs \text{ wins}} = \prob{\advss \text{ wins}, h_{i_1}, \ldots, h_{i_6} \text{ are guessed correctly}, \nevent{E}_0}\,.
\] 
Hence,
\[
	\prob{\advss \text{ wins}, \nevent{E}_0} \leq q_\ro^6 \cdot \epss(\secpar).
\]

\ncase{When $\nevent{E}_1$ happens}
The reduction $\rdvdlog$ runs internally a protocol $\plonkprotfs$, which CRS is computed from the challenge $\gone{1, \chi, \ldots, \chi^{\numberofconstrains + 2}}, \gtwo{\chi}$ from the $(\numberofconstrains + 2, 1)$-dlog assumption challenger. 
Then it proceeds as $\rdvs$ does, except in the last part, when the adversary provided its proof $\zkproof_\advss$, $\rdvdlog$ uses the fact that the real verification equation holds, but the ideal verification equation does not to break the dlog assumption. 

Since $\vereq(X) \neq 0$, but $\vereq(\chi) = 0$ and $\rdvdlog$ knows
$\vec{M'}$, as defined in \cref{eq:M_prim}, it can recreate all the polynomials
submitted by $\advss$ as part of the proof and included in $\vereq(X)$. This
way, it knows all coefficients of $\vereq(X)$. Thus it can factorise it and find
its roots, one of them is the required $\chi$. Hence it holds, by the analogous analysis as in the previous case, that
\[
	\prob{\advss \text{ wins}, \nevent{E}_1} \leq q_\ro^6 \cdot \eps_{\dlog}(\secpar).
\]

The proof is concluded by observing that the analysis of events $\event{E}, \nevent{E}_0, \nevent{E}_1$ gives
\[
	\eps \leq \epsur(\secpar) + q_\ro^6 (\eps_{\dlog}(\secpar) + \epss(\secpar))\,,
\]
hence $\eps$ is negligible if dlog is hard and $\plonkprot$ is sound and $\ur{3}$.
\qed
\end{proof}



\bibliographystyle{alpha}
\bibliography{cryptobib/abbrev1,cryptobib/crypto,additional_bib}

\appendix
\section{$\plonk$'s prover explained}
\label{sec:plonk_explained}

\paragraph{\fbox{\normalfont{$\plonk$ prover $\prover(\REL, \crs, \inp, \wit)$}}}


\paragraph{\fbox{\normalfont{$\plonk$ verifier $\verifier(\REL, \crs, \inp, \zkproof)$}}}\ \newline
The \plonk{} verifier works as follows
\begin{description}
	\item[Step 1] Validate all obtained group elements.
	\item[Step 2] Validate all obtained field elements.
	\item[Step 3] Validate the instance $\inp = \smallset{\wit_i}_{i = 1}^\instsize$.
	\item[Step 4] Compute challenges $\beta, \gamma, \alpha, \alpha', \chz, v, u$ from the transcript.
	\item[Step 5] Compute zero polynomial evaluation $\p{Z_H} (\chz)  =\chz^\numberofconstrains - 1$.
	\item[Step 6] Compute Lagrange polynomial evaluation $\lag_1 (\chz) = \frac{\chz^\numberofconstrains -1}{\numberofconstrains (\chz - 1)}$.
	\item[Step 7] Compute public input polynomial evaluation $\pubinppoly (\chz) = \sum_{i \in \range{1}{\instsize}} \wit_i \lag_i(\chz)$.
	\item[Step 8] Compute quotient polynomials evaluations
	\begin{multline*}
		\p{t} (\chz)  = \frac{1}{\p{Z_H}(\chz)}
		\Big(
			\p{r} (\chz) + \pubinppoly(\chz) - (\p{a}(\chz) + \beta \p{S_\sigma 1}(\chz) + \gamma) (\p{b}(\chz) + \beta \p{S_\sigma 2}(\chz) + \gamma) \\
			(\p{c}(\chz) +
			\gamma)\p{z}(\chz \omega) \alpha - \lag_1 (\chz) \alpha^2
		\Big) \,.
	\end{multline*}
	\item[Step 9] Compute batched polynomial commitment
	$\gone{D} = v \gone{r} + u \gone {z}$ that is
	\begin{align*}
		\gone{D} & = v
		\left(
		\begin{aligned}
			& \p{a}(\chz)\p{b}(\chz) \cdot \gone{\selmulti} + \p{a}(\chz)  \gone{\selleft} + \p{b}  \gone{\selright} + \p{c}  \gone{\seloutput} + \\
			& + (	(\p{a}(\chz) + \beta \chz + \gamma) (\p{b}(\chz) + \beta k_1 \chz + \gamma) (\p{c} + \beta k_2 \chz + \gamma) \alpha  + \lag_1(\chz) \alpha^2)  + \\
			% &   \\
			& - (\p{a}(\chz) + \beta \p{S_{\sigma 1}}(\chz) + \gamma) (\p{b}(\chz) + \beta \p{S_{\sigma 2}}(\chz) + \gamma) \alpha  \beta \p{z}(\chz \omega) \gone{\p{S_{\sigma 3}}(\chi)})
		\end{aligned}
		\right) + \\
		& + u \gone{\p{z}(\chi)}\,.
	\end{align*}
	\item[Step 10] Computes full batched polynomial commitment $\gone{F}$:
	\begin{align*}
		\gone{F} & = \left(\gone{\p{t_{lo}}(\chi)} + \chz^\numberofconstrains \gone{\p{t_{mid}}(\chi)} + \chz^{2 \numberofconstrains} \gone{\p{t_{hi}}(\chi)}\right) + u \gone{\p{z}(\chi)} + \\
		& + v
		\left(
		\begin{aligned}
			& \p{a}(\chz)\p{b}(\chz) \cdot \gone{\selmulti} + \p{a}(\chz)  \gone{\selleft} + \p{b}  \gone{\selright} + \p{c}  \gone{\seloutput} + \\
			& + (	(\p{a}(\chz) + \beta \chz + \gamma) (\p{b}(\chz) + \beta k_1 \chz + \gamma) (\p{c} + \beta k_2 \chz + \gamma) \alpha  + \lag_1(\chz) \alpha^2)  + \\
			% &   \\
			& - (\p{a}(\chz) + \beta \p{S_{\sigma 1}}(\chz) + \gamma) (\p{b}(\chz) + \beta \p{S_{\sigma 2}}(\chz) + \gamma) \alpha  \beta \p{z}(\chz \omega) \gone{\p{S_{\sigma 3}}(\chi)})
		\end{aligned}
		\right) \\
		& + v^2 \gone{\p{a}(\chi)} + v^3 \gone{\p{b}(\chi)} + v^4 \gone{\p{c}(\chi)} + v^5 \gone{\p{S_{\sigma 1}(\chi)}} + v^6 \gone{\p{S_{\sigma 2}}(\chi)}\,.
	\end{align*}
	\item[Step 11] Compute group-encoded batch evaluation $\gone{E}$
	\begin{align*}
		\gone{E}  = \frac{1}{\p{Z_H}(\chz)} & \gone{
		\begin{aligned}
			& \p{r}(\chz) + \pubinppoly(\chz) +  \alpha^2  \lag_1 (\chz) + \\
			& - \alpha \left( (\p{a}(\chz) + \beta \p{S_{\sigma 1}} (\chz) + \gamma) (\p{b}(\chz) + \beta \p{S_{\sigma 2}} (\chz) + \gamma) (\p{c}(\chz) + \gamma) \p{z}(\chz \omega) \right)
		\end{aligned}
		}\\
		 + & \gone{v \p{r}(\chz) + v^2 \p{a}(\chz) + v^3 \p{b}(\chz) + v^4 \p{c}(\chz) + v^5 \p{S_{\sigma 1}}(\chz) + v^6 \p{S_{\sigma 2}}(\chz) + u \p{z}(\chz \omega) }\,.
	\end{align*}
	\item[Step 12] Check whether the verification equation holds
	\begin{multline}
		\label{eq:ver_eq}
		\left(
		\gone{\p{W_{\chz}}(\chi)} + u \cdot \gone{\p{W_{\chz \omega}}(\chi)}
		\right) \bullet
		\gtwo{\chi} = \\
		\left(
			\chz \cdot \gone{\p{W_{\chz}}(\chi)} + u \chz \omega \cdot \gone{\p{W_{\chz \omega}}(\chi)} + \gone{F} - \gone{E}
		\right) \bullet
		\gtwo{1}\,.
	\end{multline}
The verification equation is a batched version of the verification equation from \cite{AC:KatZavGol10} which allows the verifier to check openings of multiple polynomials in two points (instead of checking an opening of a single polynomial at one point).
\end{description}

Since the original paper \cite{EPRINT:GabWilCio19} lacks of explanation how the simulator of \plonk{} works, it is presented here.
\paragraph{\fbox{\normalfont{$\plonk$ simulator $\simulator(\REL, \crs, \td, \inp)$}}}
% \paragraph{Simulation in \plonk.}
% The simulator $\simulator$ in $\plonk$ proceeds according to the following steps:
\begin{description}
	\item[Round 1]
	Since the simulator does not know a witness $\wit$ for the proven statement $\inp$, $\simulator$ cannot compute the output of this round accordingly to the protocol. Instead, it picks randomly both the "blinders" $b_1, \ldots, b_6$ and evaluations of polynomials $\p{a}, \p{b}, \p{c}$ by picking their coefficients randomly and outputting $\gone{\p{a}(\chi), \p{b}(\chi), \p{c}(\chi)}$.
	\item[Round 2]
	The simulator takes permutation argument challenges $\beta, \gamma$ as a random oracle output in the ongoing proof.
	Similarly as in the previous round, the simulator cannot evaluate the requested polynomial $\p{z}$ honestly as it does not know the witness, picks its coefficients randomly and outputs $\gone{\p{z}(\chi)}$.
	\item[Round 3]
	In this round the simulator starts by picking at random a challenge $\chz$ that will be later used to program a random oracle.
	Then it computes evaluations $\p{a}(\chz), \p{b}(\chz), \p{c}(\chz), \p{S_{\sigma 1}}(\chz), \p{S_{\sigma 2}}(\chz), \pubinppoly(\chz), \lag_1(\chz), \p{Z_H}(\chz),\allowbreak \p{z}(\chz\omega)$
	
	Given the evaluations $\simulator$ computes polynomial $\p{r}(X)$ honestly, i.e.
	\[
		\p{r}(X) = 
		\begin{aligned}
			& \p{a}(\chz) \p{b}(\chz) \selmulti(X) + \p{a}(\chz) \selleft(X) + \p{b}(\chz) \selright(X) + \p{c}(\chz) \seloutput(X) + \selconst(X) \\
			& + \alpha \cdot \left( (\p{a}(\chz) + \beta \chz + \gamma) (\p{b}(\chz) + \beta k_1 \chz + \gamma)(\p{c}(\chz) + \beta k_2 \chz + \gamma) \cdot \p{z}(X)\right) \\
			& - \alpha \cdot \left( (\p{a}(\chz) + \beta \p{S_{\sigma 1}}(\chz) + \gamma) (\p{b}(\chz) + \beta \p{S_{\sigma 2}}(\chz) + \gamma)\beta \p{z}(\chz\omega) \cdot \p{S_{\sigma 3}}(X)\right) \\
			& + \alpha^2 \cdot \lag_1(\chz) \cdot \p{z}(X)
		\end{aligned}
	\]
	and evaluates $\p{r}(X)$ at $\chz$.
	
	In the next step the simulator computes $\ev{t}$ as the verifier would compute in Step 8.
	Next, $\simulator$ picks randomly a polynomial $\p{t}$ such that $\p{t} (\chz) = \ev{t}$.
	The simulator concludes this round as an honest prover would by dividing $\p{t}$ into $\p{t_{hi}}, \p{t_{mid}}, \p{t_{lo}}$ and outputting $\gone{\p{t_{hi}}(\chi), \p{t_{mid}}(\chi), \p{t_{lo}}(\chi)}$. 
	\item[Round 4]
	The simulator program random oracle to return $\chz$ when queried on the current state of the transcript. 
	Since the necessary evaluations at $\chz$ are already computed, $\simulator$ simply outputs 
	\[
		\p{a}(\chz), \p{b}(\chz), \p{c}(\chz), \p{S_{\sigma 1}}(\chz), \p{S_{\sigma 2}}(\chz), \p{t}(\chz), \p{z}(\chz \omega)\,.
	\]
	\item[Round 5]
	In this round the simulator proceeds as an honest prover would.
	\end{description}
\end{document}

