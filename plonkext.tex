% !TeX spellcheck = en_GB
\let\accentvec\vec
\documentclass[runningheads,11pt]{llncs}
 % \documentclass[runningheads]{amsart}
\let\spvec\vec
\let\vec\accentvec
\usepackage{amssymb,amsmath}
\let\vec\spvec

\usepackage[T1]{fontenc}

\newcommand{\iflipics}[1] {}
\newcommand{\iflncs}[1] {#1}

\def\vec#1{\mathchoice{\mbox{\boldmath$\displaystyle#1$}}
	{\mbox{\boldmath$\textstyle#1$}}
	{\mbox{\boldmath$\scriptstyle#1$}}
	{\mbox{\boldmath$\scriptscriptstyle#1$}}}

\DeclareFontFamily{U}{mathx}{\hyphenchar\font45}
\DeclareFontShape{U}{mathx}{m}{n}{<-> mathx10}{}
\DeclareSymbolFont{mathx}{U}{mathx}{m}{n}
\DeclareMathAccent{\widebar}{0}{mathx}{"73}

% lncs size (as printed in books, with small margins):
\usepackage[paperheight=23.5cm,paperwidth=15.5cm,text={13.2cm,20.3cm},centering]{geometry}


\newcommand{\ifamsart}[1] {}
\ifamsart{
	\newtheorem{theorem}{Theorem}%[section]
	\newtheorem{proposition}[theorem]{Proposition}
	\newtheorem{lemma}[theorem]{Lemma}
	\newtheorem{corollary}[theorem]{Corollary}
	\theoremstyle{definition}
	\newtheorem{definition}[theorem]{Definition}
	\newtheorem{example}[theorem]{Example}
}
\usepackage{soul}
\usepackage{soulutf8}
\soulregister\cite7
\soulregister\ref7
\soulregister\pageref7
\usepackage{hyperref}
\usepackage[color=yellow]{todonotes}
\hypersetup{final}
\usepackage{mathrsfs}
\usepackage[advantage,asymptotics,adversary,sets,keys,ff,lambda,primitives,events,operators,probability,logic,mm,complexity]{cryptocode}
\usepackage[capitalise]{cleveref}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{paralist}
\usepackage[innerleftmargin=5pt,innerrightmargin=5pt]{mdframed}

\include{macros}

\title{On Simulation-Extractability of \textsc{Plonk}}

\author{Markulf Kohlweiss\inst{1,2} \and Michał Zając\inst{3}}
\iflncs{
  \institute{University of Edinburgh, Edinburgh, UK \and IOHK \\ \email{mkohlwei@inf.ed.ac.uk} \and Clearmatics, London UK \\ \email{m.p.zajac@gmail.com}}
}

\allowdisplaybreaks

\begin{document}
	\sloppy
	\maketitle

\begin{abstract}
	In this paper we prove that some most-efficient updatable universal zkSNARKs like \plonk{}~\cite{EPRINT:GabWilCio19}  is (non black-box) simulation extractable.
	To that end, we generalise the result by Faust et al.~\cite{INDOCRYPT:FKMV12} (INDOCRYPT 2012) and show that any witness-extended emulatable is also simulation-extractable if made non-interactive by the Fiat--Shamir transform. We then explain why \plonk{} is has witness-extended emulation and conclude by showing its simulation-extractability.
	\michals{14.05.20}{Since Sonic is witness-extended emulation then it may be simulation extractable as well. But does it have the unique response property?}
	\task{15.05}{Check Marlin}
\end{abstract}

\section{Introduction}
\paragraph{The rise of updatable zkSNARKs.}
\cite{C:GKMMM18}
\cite{EC:CHMMVW20}
\cite{CCS:MBKM19}
\cite{EPRINT:GabWilCio19}
\cite{EPRINT:Gabizon19c}
\cite{EPRINT:Lipmaa19a}

\paragraph{On the importance of the simulation extractability.}
\cite{AC:DHLW10}
\cite{AC:Groth07}
\cite{EPRINT:AbdRamSla20}
\cite{EPRINT:KZMQCP15}
\cite{EPRINT:AtaBag19}

\subsection{Our contribution}
First of all, we prove that $\plonk$ is simulation-extractable. Although we change the original protocol only little, we had to solve a number of problems in order to show that. The idea of the proof goes as follows.

\paragraph{Witness-extended emulation of \plonk{}.}
First, we show that $\plonk$ has witness-extended emulation. To that end we show how from a number of accepting transcript a witness can be extracted. Unfortunately, \plonk{} does not to fit well in the standard definitions of witness-extended emulations like by Lindell \cite{JC:Lindell03} or by Groth and Ishai \cite{EC:GroIsh08}. The former does not cover arguments that utilises a CRS; although the latter does, it does not consider giving the CRS trapdoor to the extractor. Thus, we had to modify the definition for the witness-extended emulation.
By this modification we bring the notion of the witness-extended emulation closer to the definition of simulation extractability, where giving the trapdoor to the extractor is a natural thing to do, cf.~\cite{AC:Groth06,AC:DHLW10,PKC:ADKNO13,DCC:DerSla19}.
We believe that our formulation would serve well in showing simulation-extractability of other NIZKs.

\paragraph{From witness-extended emulation to simulation extractability.}
Second, we took the classical result by Faust et al.~\cite{INDOCRYPT:FKMV12} which shows that a special-sound $\Sigma$-protocol that has the unique response property is simulation-extractable if made non-interactive by the Fiat--Shamir transform. This result also could not be used directly, as \plonk{} is not a $3$-round $\Sigma$-protocol, nor has the \emph{strict} unique response property.
To make Faust et al.~result working in our setting we had to prove it fits multi-round protocols and show that \plonk{} in fact has the unique response property.

\paragraph{Interactive zero knowledge vs non-interactive zero knowledge.}
Another issue we tackle with is a question whether NIZK proof systems are in fact zero-knowledge, see e.g.~\cite{C:Pass03}. This problem was raised as one could observe that a NIZK proof system has a property alien to interactive proofs---a verifier who obtains a proof $\zkproof$ for a statement $\inp \in \LANG$ inevitably learns how to prove this statement. More precisely, he can just reuse the obtained proof $\zkproof$. This makes the verifier learn undoubtedly more than simply the veracity of the proven statement. On the other hand, the verifier learns a particular proof $\zkproof$ for a concrete CRS $\crs$ only. However, the CRS generator is considered trusted, thus the proof $\zkproof$ could be considered as a proof for $\inp$ universally, regardless the CRS.

Simulation-extractable updatable NIZKs---and zkSNARKs in particular---tighten the gap between interactive zero knowledge and non-interactive zero knowledge in the CRS model.
First, simulation-extractability assures that no adversary can maul an existing proof and make a fresh one, what limits replay attacks.
Second, updatable NIZKs does not assume that there is a trusted party that
provides a CRS, but rather a sequence of parties (called updaters) that modify
it. The security model is radically different as now one believes in the
veracity of a proof only if she trusts that there is at least one honest party
between the updaters. 

We believe that our result may be useful for designing new zkSNARKs, especially those based on a polynomial commitment schemes~\cite{AC:KatZavGol10}, as it shows that a careful protocol design may give it a strong security notion for free.

\section{Preliminaries}
Let PPT denote probabilistic polynomial-time.
Let $\secpar \in \NN$ be the security parameter.
All adversaries will be stateful.
For an algorithm $\adv$, let $\image (\adv)$ be the image of $\adv$ (the set of valid outputs of $\adv$), let $\RND{\adv}$ denote the random tape of $\adv$ (assuming the given value of $\secpar$), and let $r \sample \RND{\adv}$ denote the random choice of the randomiser $r$ from $\RND{\adv}$.
We denote by $\negl$ an arbitrary negligible function.

Distributions $X$ and $Y$ have \emph{statistical distance} $\SD$ equals $\epsilon$ if $\sum_{a \in \supp{X \cup Y}} \abs{\prob{X = a} - \prob{Y = a}} = \epsilon$.
We write $X \approx_\secpar Y$ if $\SD(X, Y) \leq \negl$, where $\SD$ is the statistical distance between the distributions.
For values $a$ and $b$ we write $a \approx_\secpar b$ if $\abs{a - b} \leq \negl$.

Denote by $\RELGEN$ a \emph{relation generator}---a PPT algorithm that on input $\secparam$ outputs an $\npol$ relation $\REL$. We assume that if $\RELGEN$ provides any auxiliary input to $\REL$, it is benign. Directly from the description of $\REL$ one learns security parameter $\secpar$ and other necessary information like a description of a group $\GRP$, if the relation is a relation of group elements (as it usually is in case of zkSNARKs).

\paragraph{Bilinear groups.}
A bilinear group generator $\pgen (1^\secpar)$ returns $(p, \GRP_1, \GRP_2, \GRP_T, \pair, \gone{1}, \gtwo{1})$, where $\GRP_1$, $\GRP_2$, and $\GRP_T$ are additive cyclic groups of prime order $p = 2^{\Omega (\secpar)}$, $\gone{1}, \gtwo{1}$ are generators of $\GRP_1$, $\GRP_2$, resp., and $\pair: \GRP_1 \times \GRP_2 \to \GRP_T$ is a non-degenerate PPT-computable bilinear pairing.
We assume the bilinear pairing to be Type-3, i.e., that there is no efficient isomorphism from $\GRP_1$ to $\GRP_2$ or from $\GRP_2$ to $\GRP_1$.
We use the by now standard bracket notation, i.e., we write $\bmap{a}{\gi}$ to denote $a g_{\gi}$ where $g_{\gi}$ is a fixed generator of $\GRP_{\gi}$.
We denote $\pair (\gone{a}, \gtwo{b})$ as $\gone{a} \bullet \gtwo{b}$.
Thus, $\gone{a} \bullet \gtwo{b} = \gtar{a b}$.
We freely use the bracket notation with matrices, e.g., if $\vec{A} \vec{B} = \vec{C}$ then $\vec{A} \grpgi{\vec{B}} = \grpgi{\vec{C}}$ and $\gone{\vec{A}}\bullet \gtwo{\vec{B}} = \gtar{\vec{C}}$.

\subsection{Polynomial commitment}
\label{sec:poly_com}

\begin{description}
	\item[Evaluation binding]
	\item[Opening uniqueness] 
	\[
		\Pr
			\left[
			\begin{aligned}
				& \verify(\crs, \vec{c}, \vec{z}, \vec{s}, \vec{o}),  \\ 
				& \verify(\crs, \vec{c}, \vec{z}, \vec{s'}, \vec{o'}), \\
				& \vec{o} \neq \vec{o'}
			\end{aligned}
			\,\left|\,
			\begin{aligned}
				& \crs \gets \kcrs(\secparam),\\
				& (\vec{c}, \vec{z}, \vec{s}, \vec{s'}, \vec{o}, \vec{o'}) \gets \adv(\crs)
			\end{aligned}
			\right.\right] \leq \negl
	\]
\end{description}



\subsection{Zero knowledge}
In a zero-knowledge proof or argument system, a prover convinces the verifier of the veracity of a statement without leaking any side information except that the statement is true.
Here, a proof (resp., an argument) system guarantees soundness against an unbounded (resp., a PPT) cheating prover.
The zero-knowledge property is proven by constructing a simulator that can simulate the view of a cheating verifier without knowing the secret information---witness---of the prover.

More precisely, let $\RELGEN(\secparam)$ be a relation generator that outputs an $\npol$ relation $\REL = \smallset{(\inp, \wit)}$. \markulf{09.07.20}{Not too fond of relation
  generators, but guess this is more general
  than family of relations.} Denote by $\LANG_\REL$ the language determined by $\REL$.
Let $\prover$ and $\verifier$ be algorithms, the former called \emph{prover} and the latter \emph{verifier}.
We denote by $\ip{\prover(\REL, \inp, \wit)}{\verifier(\REL, \inp)}$ a transcript of conversation between a $\prover$ with input $(\REL, \inp, \wit)$ and $\verifier$ with input $(\REL, \inp)$.
We write $\ip{\prover (\REL, \inp, \wit)}{\verifier(\REL, \inp)} = 1$ if in the end of the transcript the verifier $\verifier$ returns $1$ and say that $\verifier$ accepts the transcript.

\markulf{09.07.20}{Could also all quantify for Soundness and Zero knowledge?}
\michals{09.07.20}{I am not sure what you meant here. You want to have for all $\inp, \wit \in \REL$ or you doubt these properties make sense for all $\REL \gets \RELGEN$?}
A proof system $\proofsystem = (\prover, \verifier, \simulator)$ for $\RELGEN$ is required to have three properties: completeness, soundness and zero knowledge, which are defined as follows:
\begin{description}
	\item[Completeness] An interactive proof system $\proofsystem$ is \emph{complete} if an honest prover always convinces an honest verifier, that is for all $\REL \gets \RELGEN(\secparam)$ and $(\inp, \wit) \in \REL$
	\[
		\prob{\ip{\prover (\REL, \inp, \wit)}{\verifier (\REL, \inp)} = 1} = 1\,.
	\]
	\item[Soundness] We say that $\proofsystem$ for $\RELGEN$ is \emph{sound} if no PPT prover $\adv$ can convince an honest verifier $\verifier$ to accept a proof for a false statement, i.e~for $\inp \not\in\LANG$. More precisely, for all $\REL \gets \RELGEN(\secparam)$
	\[
		\condprob{\ip{\adv(\REL, \inp)}{\verifier(\REL, \inp)} = 1}{\inp \gets \adv(\REL); \inp \not\in \LANG_\REL} \leq \negl\,;
	\]
	\item[Zero knowledge] We call an interactive proof system $\proofsystem$ \emph{zero-knowledge} if for any $\REL \gets \RELGEN(\secparam)$ and adversary $\adv$ there exists a $\ppt$ simulator $\simulator$ such that
	\begin{multline*}
	  \left\{\ip{\prover(\REL, \inp, \wit)}{\adv(\REL, \inp, \wit)} \,\left|\, (\inp, \wit) \gets \adv(\REL)\vphantom{\simulator^\adv}\right.\right\} \approx_\secpar
		\\
		\left\{\simulator^{\adv}(\REL, \inp)\,\left|\, (\inp, \wit) \gets \adv(\REL)\vphantom{\simulator^\adv}\right.\right\}\,.
	\end{multline*}
	%
	We call zero knowledge \emph{perfect} if the distributions are equal and \emph{computational} if they are indistinguishable for any NUPPT distinguisher.
	
	Sometimes a stronger notion of soundness is required---except requiring that the verifier rejects proofs of statements outside the language, we request from the prover to know a witness corresponding to the proven statement. This property is formalised by the following notion:
	
	\item[Knowledge soundness] We call an interactive proof system $\proofsystem$ \emph{knowledge-sound} if for any $\REL \gets \RELGEN(\secparam)$ and a PPT adversary $\adv$
	% \begin{multline*}
	\[
	\Pr\left[
		\begin{aligned}
			& \text{$\trans$ is acceptable} \\
			& \land \REL(\inp, \wit) = 0
	 \end{aligned}
	  \,\left|\,
	 \begin{aligned}
		 & (\td, \crs) \gets \kcrs(\REL), \inp \gets \adv(\REL,\crs), \\
		 & (\wit, \trans) \gets \ext^{\ip{\adv(\REL, \crs, \inp)}{\verifier(\REL, \crs, \inp)}}(\REL, \inp)
	 \end{aligned}
	 \vphantom{\begin{aligned}
		 \adv (\trans) = 1, \\
		 \text{if $\trans{}$ is accepting} \\
		 \pcind \text{then $\REL(\inp, \wit)$}
	 \end{aligned}}\right.
	 \right] \leq \negl\,,
 % \end{multline*}
 \]
\end{description}

\paragraph{NIZKs in the Random Oracle Model.}
In NIZKs in the Random Oracle Model we distinguish, for the sake of clarity, two simulators, one denoted by $\simulator_\zkproof$ that is responsible for providing simulated proofs and $\simulator_\ro$ that picks a random oracle instantiation and takes care of all parties' queries to $\ro$.
% \michals{9.06}{Should we distinguish two simulators or just pack everything into a single one?}
For the sake of consistency (with random oracle-free NIZKs) we use $\simulator$
to denote the pair of state-sharing simulators $\simulator_\zkproof,
\simulator_\ro$.

\paragraph{Sigma protocols.}
A sigma protocol $\sigmaprot = (\prover, \verifier, \simulator)$  for a relation
$\REL \gets \RELGEN(\secparam)$  is a special case of an interactive proof which transcript compounds of three messages $(a, b, z)$, the middle being a challenge provided by the verifier.
Sigma protocols are specially-sound. That is, there exists an extractor $\ext$ which from two accepting transcripts $(a, b, z)$, $(a, b', z')$ for a statement $\inp$ can recreate the corresponding witness if $b \neq b'$. Formally,
\begin{description}
	\item[Special soundness] A sigma protocol $\sigmaprot$ is \emph{specially-sound} if for any adversary $\adv$ the probability
	\[
		\Pr\left[
		\begin{aligned}
				& \wit \gets \ext(\REL, \inp, (a, b, z), (a, b', z')),\\
				& \REL(\inp, \wit) = 0
		\end{aligned}
		\,\left|\,
		\begin{aligned}
			& (\inp, (a, b, z), (a, b', z')) \gets \adv(\REL), \\
			& \verifier(\REL, \inp, (a, b, z)) = \\
			& \qquad = \verifier(\REL, \inp, (a, b', z')) = 1, \\
		\end{aligned}
		\right.\right]
	\]
	is negligible in $\secpar$.
\end{description}

Furthermore sigma protocols are \emph{honest verifier zero-knowledge} (HVZK). That is the zero-knowledge property holds only for honest verifiers, what is formalized as follows:
\begin{description}
	\item[Honest verifier zero knowledge] A sigma protocol $\sigmaprot$ is \emph{honest verifier zero-knowledge} if for all adversaries $\adv$ holds
	\begin{multline*}
		\left\{\ip{\prover(\REL, \inp, \wit)}{\verifier(\REL, \inp)} \,\left|\, (\inp, \wit) \gets \adv(\REL)\vphantom{\simulator_\zkproof^\adv}\right.\right\} \approx_\secpar
		\left\{\simulator_\zkproof^{\verifier}(\REL, \inp)\,\left|\, (\inp, \wit) \gets \adv(\REL)\vphantom{\simulator^\adv}\right.\right\}\,.
	\end{multline*}
\end{description}
Although this notion is weaker than a standard zero knowledge it is often sufficient. Furthermore, a HVZK interactive proof system transformed by the Fiat--Shamir transformation is zero-knowledge.

Another property that sigma protocols sometimes have is, introduced by Fischlin \cite{C:Fischlin05}, a unique response property which states that no PPT adversary  can produce two accepting transcripts that differ only on the last element.
More precisely,
\begin{description}
	\item[Unique response property] Let $\sigmaprot = (\prover, \verifier, \simulator)$ be a standard-model sigma-protocol for relation $\REL \gets \RELGEN(\secparam)$ which proofs compound of three messages $(\alpha, \beta, \gamma)$. We say that $\sigmaprot$ is has a unique response property if for all PPT algorithms $\adv$ holds
	\[
	\condprob{\verifier (\alpha, \beta, \gamma) = \verifier (\alpha, \beta, \gamma')  = 1}{(\alpha, \beta, \gamma, \gamma') \gets \adv(\REL)} \leq \negl\,.
	\]
\end{description}
(If the unique response property holds even against unbounded adversaries, we call it \emph{strict}, cf.~\cite{INDOCRYPT:FKMV12}.)
Later on we often call protocols that follows this notion ur-protocols.
For the sake of completeness we note that many sigma-protocols, like e.g.~Schnorr's protocol \cite{C:Schnorr89}, fulfil this requirement.

\paragraph{Zero knowledge proof system in the CRS model.}
Many proof systems additionally compounds of a setup algorithm $\kcrs$ that on input $\REL$ outputs a common reference string (CRS) $\crs$. The common reference string comes with a corresponding trapdoor $\td$ that allows the simulator to simulate a proof.

\comment{
\paragraph{Witness-extended emulation.}
Interactive proofs run in a multi-protocol environment are often required to fulfil a stronger notion of soundness called \emph{witness-extended emulation}~\cite{JC:Lindell03}.
The following definition is inspired by  \cite{EC:GroIsh08} as their formulation
of the witness-extended emulation considers proof systems that utilises a CRS.
However, there are some changes introduced to make it fit better our purpose.
More precisely, contrary to \cite{EC:GroIsh08,EC:BCCGP16} the extractor in
\cref{def:wit_ext_em} is given the trapdoor $\td$, thus seems to be bit more
powerful.\markulf{09.07.20}{This is the simulation trapdoor. There are no
  extraction trapdoors in our setting.}
	\michals{09.07.20}{In my first idea for extraction I wanted to extract from polynomial $\p{z}$ that is computed by the prover in Round 2. To do that the extract had to know the simulation trapdoor and no extractability definitions I saw equipped the extractor with it. Anyway, the idea now is to extract the witness from much simpler polynomials evaluated by the prover in Round 4: $\p{a}, \p{b}, \p{c}$. In that case the extractor doesn't need to know the trapdoor.}
This means that a protocol that has witness-extended emulation in terms of \cite{EC:GroIsh08} has it also according to \cref{def:wit_ext_em} below.
There, for the sake of succinctness, we denote by $\trans$ a transcript of a conversation between the prover and the verifier extended with verifier's input $(\REL, \inp)$ (or $(\REL, \crs, \inp)$ in case of a proof system with a setup).
Furthermore, a proof system $\proofsystem$ is \emph{public coin} if the messages the verifier sends are chosen uniformly at random and independently of the messages send by the prover or system parameters.

\begin{definition}[Witness-extended emulation]
	\label{def:wit_ext_em}
	We say a public coin proof system $\proofsystem = (\kcrs, \prover, \verifier,
  \simulator)$ has \emph{witness-extended emulation} if for all $\REL \in
  \image(\RELGEN)$, and deterministic adversary $\adv_1$ there exists an
  expected polynomial time extractor $\ext$ such that for all PPT adversaries $\adv_0$ holds
		\begin{multline*}
		\Pr\left[\adv_0 (\trans) = 1 \,\left|\,
		\begin{aligned}
				& (\td, \crs) \gets \kcrs(\REL), (\inp, \aux_{\adv_1}) \gets \adv_0, \\
				& \trans \gets \ip{\adv_1(\REL, \crs, \inp, \aux_{\adv_1})}{\verifier(\REL, \crs, \inp)}
			\end{aligned}
		\right.
		\right]
		 \approx_\secpar \\
		 \Pr\left[
			\begin{aligned}
				& \adv_0 (\trans) = 1\ , \\
				& \text{if $\trans$ is accepting} \\
				& \pcind \text{then $\REL(\inp, \wit)$}
			\end{aligned}\,\left|\,
			\begin{aligned}
				& (\td, \crs) \gets \kcrs(\REL), (\inp, \aux_{\adv_0}) \gets \adv_1(\REL), \\
				& (\trans, \wit )\gets \ext^{\ip{\adv_1(\REL, \crs, \inp, \aux_{\adv_1})}{\verifier(\REL, \crs, \inp)}}(\REL, \inp, \td)
			\end{aligned}
			\vphantom{\begin{aligned}
				\adv (\trans) = 1, \\
				\text{if $\trans{}$ is accepting} \\
				\pcind \text{then $\REL(\inp, \wit)$}
			\end{aligned}}\right.
			\right]\,,
\end{multline*}
\markulf{09.07.20}{fix left of $|$}
\michals{09.07}{what do you mean?}
\michals{14.08}{fixed}
where the extractor $\ext$ can rewind the conversation between the prover and the verifier to a particular round and run it again with a fresh randomness for the verifier.
\end{definition}
Although in the definition above the adversary $\adv_1$ is deterministic it obtains an auxiliary input $\aux_{\adv_1}$ that may be used by $\adv_1$ as a source of randomness. Groth and Ishai~\cite{EC:GroIsh08} note that since the protocol is public-coin, verifier's randomness is part of the transcript. Thus combining $\inp, \aux_\adv$ and an accepting transcript $\trans$ gives a view of both the prover and the verifier and thus gives a witness.
}

\subsection{Simulation extractable NIZKs from sigma protocols}
Real life applications often require from a NIZK proof system to be non-malleable. That is, no adversary seeing a proof $\zkproof$ for a statement $\inp$ should be able to provide a new proof $\zkproof'$ related to $\zkproof$.
A strong version of non-malleability is formalized by simulation extractability.
This notion states that no adversary can produce valid proof without knowning
the corresponding witness. This must hold even if the adversary is allowed to see polynomially many simulated proofs for any statements she wishes.

\begin{definition}[Simulation extractability]
	A proof system $\proofsystem$ is computationally (adaptively) \emph{strongly simulation-extractable for $\RELGEN$}, if for every NUPPT $\adv$, there exists a NUPPT extractor $\ext_\adv$, s.t.
	\[
	\condprob{
  \begin{aligned}
    &(\inp, \wit) \not\in \REL,\\
		&(\inp, \zkproof) \not\in Q, \\
    & \verifier (\REL, \crs, \inp, \zkproof) = 1
  \end{aligned}
  }
  {
		\begin{aligned}
		& \REL \gets \RELGEN (\secparam),
		(\crs, \td) \gets \kgen (\REL), r \sample \RND{\adv},
		\\ &
		((\inp, \zkproof)  \|  \wit) \gets (\adv^{\oracleo}  \|  \ext_\adv) (\REL, \crs; r)
		\end{aligned}
	} \leq \negl \enspace,
	\]
	where $\oracleo$ on input $\inp'$ returns $\zkproof' \gets \simulator(\REL, \crs, \td, \cdot)$ and writes $(\inp', \zkproof')$ to a list $Q$.
\end{definition}

% Faust et al.~\cite{INDOCRYPT:FKMV12} show every
Consider a sigma protocol $\sigmaprot = (\prover, \verifier, \simulator)$ that
is specially sound and has a unique response property. Let $\sigmaprot_\fs = (\prover_\fs, \verifier_\fs, \simulator_\fs)$ be a NIZK obtained by applying the Fiat--Shamir transform to $\sigmaprot$.
Faust et al.~\cite{INDOCRYPT:FKMV12} show that every such $\sigmaprot_\fs$ is simulation-extractable.

\begin{theorem}[Simulation extractability of the Fiat--Shamir transform \cite{INDOCRYPT:FKMV12}]
	Let $\sigmaprot = (\prover, \verifier, \simulator_\zkproof)$ be a non-trivial sigma protocol with unique responses for a language $\LANG \in \npol$.
	In the random oracle model, the NIZK proof system $\sigmaprot_\fs = (\prover_\fs, \verifier_\fs, \simulator_{\fs})$ resulting by applying the Fiat--Shamir transform to $\sigmaprot$ is simulation extractable with extraction error $\eta = q/h$ for the simulator $\simulator$. Here, $q$ is the number of random oracle queries and $h$ is the number of elements in the range of $\ro$.
	% Furthermore, the extractor $\ext_\adv$ needs to run $\adv^{\simulator_{\fs, \ro}}, \adv^{\simulator_{\fs, \zkproof}}$ twice.
\end{theorem}

The theorem relies on the following classical lemma, called \emph{General forking lemma} \cite{JC:PoiSte00}.

\begin{lemma}[General forking lemma, cf.~\cite{INDOCRYPT:FKMV12,CCS:BelNev06}]
	\label{lem:forking_lemma}
	Fix $q \in \ZZ$ and a set $H$ of size $h > 2$. Let $\adv$ be a PPT algorithm that on input $y, h_1, \ldots, h_q$ returns $(i, s)$, where $i \in\range{0}{q}$ and $s$ is called a \emph{side output}.
	Denote by $\ig$ a randomised instance generator.
	We denote by $\accProb$ the probability
	\[
		\condprob{i > 0}{y \gets \ig; h_1, \ldots, h_q \sample H; (i, s) \gets \adv(y, h_1, \ldots, h_q)}\,.
	\]
	Let $\forking_\adv(y)$ denote the algorithm described in \cref{fig:forking_lemma}, then the probability $\frkProb$ defined as
	$
		\frkProb := \condprob{b = 1}{y \gets \ig; (b, s, s') \gets \forking_{\adv}(y)}
	$
	holds
	\[
		\frkProb \geq \accProb \brak{\frac{\accProb}{q} - \frac{1}{h}}\,.
	\]
	%
	\begin{figure}
		\centering
		\fbox{
		\procedure{$\forking_\adv (y)$}
		{
			r \sample \RND{\adv}\\
			h_1, \ldots, h_q \sample H\\
			(i, s) \gets \adv(y, h_1, \ldots, h_q; r)\\
			\pcif i = 0\ \pcreturn (0, \bot, \bot)\\
			h'_{i}, \ldots, h'_{q} \sample H\\
			(i', s') \gets \adv(y, h_1, \ldots, h_{i - 1}, h'_{i} h'_{q}; r)\\
			\pcif (i = i') \land (h_{i} \neq h'_{i})\ \pcreturn (1, s, s')\\
			\pcind \pcelse \pcreturn (0, \bot, \bot)
		}}
		\caption{Forking algorithm $\forking_\adv$}
		\label{fig:forking_lemma}
\end{figure}
\end{lemma}
%
In case of a sigma protocol, the probability $\frkProb$ can be interpreted as a lower bound for a successful witness extraction from two transcripts.
Let $\tr_1 = (\inp, a, z, \gamma)$ and $\tr_2 = (\inp, a, z', \gamma')$ be the transcripts.
Both $\tr_1$ and $\tr_2$ have to be \emph{acceptable}, i.e.~$i > 0$ and the probability that $\adv$ makes an acceptable transcript is denoted by $\accProb$. 
Index $i$ can be interpreted as an index of $h_i$ which was sent as a challenge for $(\inp, a)$, this index has to be guessed by the security reduction. 
For the sake of extractability, both transcripts have to have the same index $i$, i.e.~the same instance $\inp$ and the first message $a$, but the actual challenges $z = h_i$ and $z' = h'_{i}$ have to differ.

\subsection{Simulation extractability for multi-round protocols}
Unfortunately, Faust et al.'s result cannot be directly applied in our case since the protocols we consider have more than three rounds of interaction.

\paragraph{Generalised forking lemma.}
First of all, although dubbed ``general'', \cref{lem:forking_lemma} is not general enough for our purpose as it useful only for protocols that extract witness from two transcripts. 
To be able to extract a witness from a \plonk{} execution we need to obtain at least $\numberofconstrains + 3$ transcripts.
Fortunately, since the witness can be extracted by repeating only one round of the protocol, we can proceed similarly as in a protocol that utylises only one challenge.
\michals{15.07}{Is that true?}

Here we propose a generalisation of the general forking lemma that given probability $\accProb$ gives a lower bound on the probability of generating a \emph{tree of accepting transcripts}, which could be used to extract a witness. 

\begin{lemma}[General forking lemma II]
	% Let $\proofsystem$ be a $(2 \mu + 1)$-round protocol and $\proofsystem_\fs$ its $\fs$-transformed version.
	Fix $q \in \ZZ$ and set $H$ of size $h \geq m$. 
	Let $\adv$ be a PPT algorithm that on input $y, h_1, \ldots, h_q$ returns $(i, s)$ where $i \in \range{0}{q}$ and $s$ is called a side output. 
	Denote by $\ig$ a randomised instance generator. We denote by $\accProb$ the probability
	\[
		\condprob{i \neq 0}{ y \gets \ig;\ h_1, \ldots, h_q \sample H;\ (i, s) \gets \adv(y, h_1, \ldots, h_q)}\,.
	\]
	Let $\genforking_\adv$ denote the algorithm described in \cref{fig:genforking_lemma} then the probability $\frkProb := \condprob{b = 1}{y \gets \ig;\ (b, \vec{s}) \gets \genforking_\adv(y)}$ is at least 
	\[
		\frac{\accProb^m}{q^{m - 1}} - \frac{(m - 1) \cdot \accProb}{h}\,.
	\]
		
	\begin{figure}
		\centering
		\fbox{
		\procedure{$\genforking_\adv (y)$}
		{
			r \sample \RND{\adv}\\
			h_1, \ldots, h_{i - 1} \sample H\\
			\pcfor j \in \range{1}{m}\\
			\pcind h_{i_j}, \ldots, h_{q_j} \sample H\\
			\pcind (i_j, s_j) \gets \adv(y, h_1, \ldots, h_{i - 1}, h_{i_j}, \ldots, h_{q_j}; r)\\
			\pcind \pcif i = 0\ \pcreturn (0, \bot, \bot)\\
			\pcif \forall j, j'  \in \range{1}{m}\colon (i_{j} = i_{j'}) \land (h_{i_j} \neq h_{i_{j'}})\ \pcreturn (1, \vec{s})\\
			\pcind \pcelse \pcreturn (0, \bot, \bot)
		}}
		\caption{Generalised forking algorithm $\genforking_\adv$}
		\label{fig:genforking_lemma}
\end{figure}
\end{lemma}
\begin{proof}
	\michals{3.08.20}{DISCLAIMER: This proof is a naive generalisation of the general forking lemma from Bellare and Neven 06. Need to check that all (in)equalities hold!}
	We proceed similarly as in \cite{CCS:BelNev06} (with some parts taken almost verbatim).
	
	First let denote by $\accProb(y)$ and $\frkProb(y)$ the following probabilities
	\begin{align*}
		\accProb(y) & =  \condprob{i \neq 0}{h_1, \ldots, h_q \sample H;\ (i, s) \gets \adv(y, h_1, \ldots, h_q)}\,.\\
		\frkProb(y) & = \condprob{b = 1}{(b, \vec{s}) \gets \genforking_\adv(y)}\,.
	\end{align*}
	
	We start by claiming that for all $y$ 
	\begin{equation}\label{eq:frkProb_y}
		\frkProb(y) \geq 
			\frac{\accProb(y)^m}{q^{m - 1}} - \frac{(m - 1) \cdot  \accProb(y)}{h}\,.
	\end{equation}
	Then with the expectation taken over $y \sample \ig$, we have
	\begin{align}
		\frkProb & = \expected{\frkProb(y)} \geq \expected{\frac{\accProb(y)^m}{q^{m - 1}} - \frac{(m - 1) \cdot  \accProb(y)}{h}} \label{eq:use_eq1}\\
		& = \frac{\expected{\accProb(y)^m}}{q^{m - 1}} - \frac{(m - 1) \cdot \expected{\accProb(y)}}{h} \\
		& \geq \frac{\expected{\accProb(y)}^m}{q^{m - 1}} - \frac{(m - 1) \cdot \expected{\accProb(y)}}{h} \label{eq:by_lemma_jensen}\\
		& = \frac{\accProb^m}{q^{m - 1}} - \frac{(m - 1) \cdot  \accProb}{h}\label{eq:by_accProb}\,.
	\end{align}
	Where Ineq.~(\ref{eq:use_eq1}) comes from \cref{eq:frkProb_y};   Ineq.~(\ref{eq:by_lemma_jensen}) comes from \cref{lem:jensen}; and (\ref{eq:by_accProb}) holds by the fact that $\expected{\accProb(y)} = \accProb$.
	
	We now show \cref{eq:frkProb_y}.
	Denote by $J = \range{1}{m}^2 \setminus \smallset{(j, j)}_{j \in \range{1}{m}}$. 
	For any input $y$, with probabilities taken over the coin tosses of $\genforking_\adv$ we have
	\begin{align*}
		\frkProb (y) & = \prob{i_j = i_{j'} \land i_j \geq 1 \land h_{i_j} \neq h_{i_{j'}} \text{ for } (j, j') \in J}	\\
		& \geq \prob{i_j = i_{j'} \land i_j \geq 1 \text{ for } (j, j') \in J} \\
		& \qquad - \prob{i_j \geq 1 \land h_{i_j} = h_{i_{j'}} \text{ for some } (j, j') \in J}\\
		& = \prob{i_j = i_{j'} \land i_j \geq 1 \text{ for } (j, j') \in J} - \prob{i_j \geq 1} \cdot \frac{m - 1}{h} \\
		& = \prob{i_j = i_{j'} \land i_j \geq 1 \text{ for } (j, j') \in J} - \accProb(y) \cdot \frac{m - 1}{h}\,.
	\end{align*}
	It remains to show that $\prob{i_j = i_{j'} \land i_j \geq 1 \text{ for } (j, j') \in J} \geq \infrac{\accProb(y)^m}{q^{m - 1}}$.
	
	Let $\RND{\adv}$ denote the set from which $\adv$ picks its coins at random. For each $\iota \in \range{1}{q}$ let $X_\iota \colon \RND{\adv} \times H^{\iota - 1} \to [0, 1]$ be defined by setting $X_\iota(\rho, h_1, \ldots, h_\iota)$ to
	\[
		\condprob{i = \iota}{h_\iota, \ldots, h_q \sample H; (i, \vec{s}) \gets \adv(y, h_1, \ldots, h_q; \rho)} 
	\] 
	for all $\rho \in \RND{\adv}$ and $h_1, \ldots, h_{\iota - 1} \in H$. Consider $X_\iota$ as a random variable over the uniform distribution on its domain. 
	Then
	\begin{align*}
		& \prob{i_j = i_{j'} \land i_j \geq 1 \text{ for } (j, j') \in J} \\
		& = \sum_{\iota = 1}^{q} \prob{i_1 = \iota \land \ldots \land i_m = \iota} \\
		& = \sum_{\iota = 1}^{q} \prob{i_1 = \iota} \cdot \condprob{i_2 = \iota}{i_1 = \iota} \cdot \ldots \cdot \condprob{i_m = \iota}{i_1 = \ldots = i_{m - 1} = \iota} \\
		& = \sum_{\iota = 1}^{q} \sum_{\rho, h_1, \ldots, h_{\iota - 1}} X_{\iota} (\rho, h_1, \ldots, h_{\iota - 1})^{m} \cdot \frac{1}{\abs{\RND{\adv}} \cdot \abs{H}^{\iota - 1}}\\
		& = \sum_{\iota = 1}^{q} \expected{X_\iota^m} \,.
	\end{align*}
	Then by \cref{lem:jensen} we get
	\[
		\sum_{\iota = 1}^{q} \expected{X_\iota^m} \geq \sum_{\iota = 1}^{q} \expected{X_\iota}^m\,.
	\]
	We note that for e.g.~$X_i = 1$, $i \in \range{1}{q}$ the inequality becomes equality, that is, it is tight.
	 
	We now use the H\"older inequality from \cref{lem:holder} where we set  $x_i = \expected{X_i}$, $y_i = 1$, $p = m$, and $q = m/(m - 1)$ obtaining
	\begin{gather}
		\sum_{i = 1}^{q} \expected{X_i}  \leq \left(\sum_{i = 1}^{q} \expected{X_i}^m\right)^{\frac{1}{m}} \cdot \left(\sum_{i = 1}^{q} 1^\frac{m}{m - 1}\right)^{\frac{m - 1}{m}} \label{eq:tightness} \\
		\left(\sum_{i = 1}^{q} \expected{X_i}\right)^{m}  \leq \left(\sum_{i = 1}^{q} \expected{X_i}^m\right) \cdot q^{m - 1}\\
		\frac{1}{q^{m - 1}} \cdot \accProb(y)^{m} \leq \sum_{i = 1}^{q} \expected{X_i}^m\,.
	\end{gather}
	Finally, we get
	\[
		\frkProb(y) \geq \frac{\accProb(y)^m}{q^{m - 1}} - 
		\frac{(m - 1) \cdot \accProb(y)}{h}\,.
	\]
	\qed
\end{proof}

\begin{remark}[Tightness of \cref{eq:tightness}]
	In is important to note that Inequality (\ref{eq:tightness}) is tight. More precisely, for $\expected{X_i} = x$, $i \in \range{1}{q}$ we have
	\begin{gather*}
		\sum_{i = 1}^q x = \left(\sum_{i = 1}^{q} x^m\right)^\frac{1}{m} \cdot \left(\sum_{i = 1}^{q} 1^{\frac{m}{m - 1}}\right)^{\frac{m - 1}{m}} \\
		qx = \left(qx^m\right)^\frac{1}{m} \cdot q^{\frac{m - 1}{m}} \\
		(qx)^m = qx^m \cdot q^{m - 1} \\
		(qx)^m = (qx)^m\,.
	\end{gather*}
\end{remark}

\begin{lemma}\label{lem:jensen}
	Let $\RND{\adv}$ denote the set from which $\adv$ picks its coins at random. For each $\iota \in \range{1}{q}$ let $X_\iota \colon \RND{\adv} \times H^{\iota - 1} \to [0, 1]$ be defined by setting $X_\iota(\rho, h_1, \ldots, h_\iota)$ to 
	\[
		\condprob{i = \iota}{h_\iota, \ldots, h_q \sample H; (i, \vec{s}) \gets \adv(y, h_1, \ldots, h_q; \rho)} 
	\] 
	for all $\rho \in \RND{\adv}$ and $h_1, \ldots, h_{\iota - 1} \in H$. Consider $X_\iota$ as a random variable over the uniform distribution on its domain. 
	Then $\expected{X_\iota^m} \geq \expected{X_\iota}^m$.
\end{lemma}
\begin{proof}
	First we recall the Jensen inequality \cite{W:Weissten20}, if for some random variable $X$ holds $\abs{\expected{X}} \leq \infty$ and $f$ is a Borel convex function then 
	\[
		f(\expected{X}) \leq \expected{f(X)}\,.
	\] 
	Finally, we note that $\abs{\expected{X}} \leq \infty$ and taking to thee $m$-th power is a Borel convex function on $[0, 1]$ interval. 
	\qed
\end{proof}

\begin{lemma}[H\"older's inequality. Simplified.]\label{lem:holder}
	Let $x_i, y_i$, for $i \in \range{1}{q}$, and $p, q$ be real numbers such that $1/p + 1/q = 1$. Then
	\[
		\sum_{i = 1}^{q} x_i y_i \leq \left(\sum_{i = 1}^{q} x_i^p\right)^{\frac{1}{p}} \cdot \left(\sum_{i = 1}^{q} y_i^p\right)^{\frac{1}{q}}\,.
	\]
\end{lemma}

\paragraph{Unique-response protocols.}
Another problem comes with another assumption required by Faust et al. That is, the unique response property of the transformed sigma protocol.
Fischlin's formulation, although perfectly fine for applications presented in \cite{C:Fischlin05}, is not enough in our case.
First of all, the property assumes that the protocol has three rounds, with the middle being the challenge from the verifier. That is not the case we consider here. Second, it is not entirely clear how to generalize the property. Should one require that after the first challenge from the verifier the responses are fixed? That could not work since if there is more challenges then they are random.
Another problem rises when the protocol contains some round---obviously, except the first one---where the prover randomises his message. In that case unique-responsiveness can not hold as well.
Last but not least, the protocol we consider here most, \plonk, is not in a standard-model, but utilises CRS. That also complicates things considerably.

We walk around these obstacles by providing a generalized notion of the unique response property.
More precisely, we say that a $(2\mu + 1)$-round protocol has \emph{unique responses after $i$} and is called a $\ur{i}$-protocol if
\begin{definition}[$\ur{i}$-protocol]
	\label{def:wiur}
	Let $\proofsystem$ be a multi-round proof system.
	Denote by $a_0, b_0, \ldots, a_{\mu - 1}, b_{\mu - 1}, a_{\mu}$ the consecutive messages exchanged in the protocol, where messages $a_i$ come from the prover and $b_i$ from the verifier.
	We say that $\proofsystem$ has \emph{unique responses after $i$}
	if after submitting its $i$-th message the prover is a deterministic function. That is, it does not use his randomness tape and deterministically answers verifier's challenges.
\end{definition}
\begin{example}
	The Schnorr protocol is $\ur{1}$. That is, after submitting his first message $a$, the prover is a deterministic function of the instance, $a$, and the verifier's challenge.
\end{example}

We note that the definition above is independent on whether the proof system $\proofsystem$ utilises CRS (and compounds of the CRS-generating $\kgen$ algorithm) or not.
% Furthermore it is also blind whether $\proofsystem$ is interactive or not.
\michals{08.07.20}{Should we change it to "deterministic prover property"?}

\comment{
\paragraph{Simulatability of proofs.}
We note that in the standard model protocols the simulator does not require any additional power like knowledge of a CRS trapdoor or programmability of the random oracle. This implies that every adversary can produce a simulated proof by its own.
On the other hand, we have CRS-based zk-proofs where knowledge of trapdoor is required to make an simulated proof.

Given a multi-round Fiat--Shamir-transformed protocol which simulation utilises
trapdoor we can ask another question---how many rounds, from the beginning of
the protocol, can be simulated by the adversary unless the trapdoor is required?
\markulf{}{interesting}\michals{09.07}{I am not sure this property is needed, but the question seems interesting. It came from the following---in the case of a standard model protocol $\proofsystem$, as in your Indocrypt paper, one can easy make a reduction from breaking a simulation extractability of $\proofsystem_\fs$ to breaking a soundness of $\proofsystem$ (or breaking the unique resp. prop of $\proofsystem$ but that's not the case we consider here). This comes since the reduction can easily simulate proofs of $\proofsystem$ for the se adversary $\adv$.
This reduction is not that easy if $\proofsystem$ uses a CRS---now the reduction does not know the trapdoor and cannot provide simulated proofs.}
% \michals{09.07.20}{Also, it is not clear for me that in a multiround protocol we can simply use the following argument from your Indocrypt paper -- let $\inp, \vec{a}$ be a partially proof provided by the adversary, then it is a fresh query to the random oracle, otherwise }
% \michals{09.07}{There is also another question -- in Plonk's round 4 the simulator outputs some randomised message. }
% Note that to answer this question we shall quantify over all possible simulators. That would not be a problem though in the setting we consider.

\begin{definition}[$k$-out-of-$n$ simulatable proof system]
	Let $\proofsystem = (\kgen, \prover, \verifier, \simulator)$ for $\RELGEN$ be
  a $n$-round \markulf{09.07.20}{2n-1 round}\michals{09.07}{To be precised. I generally wanted to denote the round by a pair of challenge--response. But can change that if that is not standard.} interactive proof. Let $(\inp, a_0, b_0, \ldots, b_{n - 2}, a_{n - 1})$ be a proof for a statement $\inp$ where $a_i$-s, $i \in \range{0}{n - 1}$ are messages send by the prover and $b_i$-s, $i \in \range{0}{n - 2}$ by the verifier.
	% Similarly we denote by $(\inp, a^{\simulator}_0, b^{\simulator}_0, \ldots, b^{\simulator}_{n - 2}, a^{\simulator}_{n - 1})$ a proof output by the simulator $\simulator$.
	We say that $\proofsystem$ is \emph{$k$-out-of-$n$ simulatable} if for  $\REL \in \image{\RELGEN(\secparam)}$ there exists a $\ppt$ algorithm $\bdv$ that for every PPT adversary $\adv$ can produce a proof $(\inp, a_0, b_0, \ldots, b_{n - 2}, a_{n - 1})$ such that
	\begin{multline*}
		\left\{(\inp, a_0, b_0, \ldots, b_{k - 1}, a_{k}) \gets \bdv(\REL ,\crs) \,\left\vert\,
		\begin{aligned}
			 & (\crs, \td) \gets \kgen(\REL) \\
			 & \inp \gets \adv(\REL, \crs)
		\end{aligned}
		\right.
		\right\} \approx_\secpar \\
		\left\{(\inp, a_0, b_0, \ldots, b_{k - 1}, a_{k}) \gets \simulator(\REL, \crs, \td) \,\left\vert\,
		\begin{aligned}
			 & (\crs, \td) \gets \kgen(\REL) \\
			 & \inp \gets \adv(\REL, \crs)
		\end{aligned}
		\right.
		\right\}\,.
	\end{multline*}
	\michals{3.07.20}{Note that $\inp$ doesn't need to be in the language!}
\end{definition}

This definition will have consequences later on as in a $k$-out-of-$n$ simulatable proof system learning first $2k - 1$ messages of the simulated proof gives the adversary no additional power as it could compute these messages by its own.
This property will be important later in the simulation-extractability proof.
\michals{03.07}{a proof for that statement would be nice.}
}

\section{Simulation extractability of $\plonk$}
\task{28.07}{All proofs in this section should be verified}
\begin{lemma}
	\label{lem:kzg_unique_op}
	Let $\PCOM$ be a batched varsion of a KZG polynomial commitment \cite{AC:KatZavGol10} as described in \cite{EPRINT:GabWilCio19}. Let $k \in \NN$, $\vec{z}, \vec{o} \in \FF_p^2$, $\vec{c}, \vec{s} \in \ZZ_p^k$, then for every PPT adversary $\adv$	
	\[
		\Pr
			\left[
				\begin{aligned}
					& \PCOM.\verify(\crs, \vec{c}, \vec{z}, \vec{s}, \vec{o}), \\
					& \PCOM.\verify(\crs, \vec{c}, \vec{z}, \vec{s}, \vec{o'}) \\
					% & \vec{s'} \neq \vec{s} \lor 
					&\vec{o'} \neq \vec{o}
				\end{aligned}
			\,\left|\,
			\vphantom{\begin{aligned}
				& \PCOM.\verify(\crs, \vec{c}, \vec{z}, \vec{s}, \vec{o}), \\
				& \PCOM.\verify(\crs, \vec{c}, \vec{z}, \vec{s}, \vec{o'}) \\
				% & \vec{s'} \neq \vec{s} \lor 
				&\vec{o'} \neq \vec{o}
			\end{aligned}}
			\begin{aligned}
				& \crs \gets \PCOM.\kcrs(\secparam), 
					(\vec{c}, \vec{z}, \vec{s}, \vec{o}) \gets \adv(\crs)
			\end{aligned}
			\right.\right]
		 \leq \negl.
	\]
\end{lemma}
\begin{proof}
	First, consider a case where the commitment limited to commit to multiple polynomials which are evaluated at the same point $z$. 
	As noted in \cite[Lemma 2.2]{EPRINT:GabWilCio19} it is enough to upper bound the probability of adversary succeeding using the idealised verification equation, which considers equality between polynomials, instead of the real verification equation, which consider equality of the polynomials' evaluations.
	
	For polynomials $\vec{f} = f_1, \ldots, f_k$, evaluation point $z$, evaluation result $\vec{s} = s_1, \ldots, s_k$, and opening $o$ the idealised check verifies that
	\begin{equation}
		\sum_{i = 1}^k \gamma^{i - 1} f_i(X) - \sum_{i = 1}^{k} \gamma^{i - 1} s_i \equiv o(X) (X - z)\,.
		\label{eq:pcom_idealised_check}
	\end{equation}
	Since $o(X)(X - z) \in \FF_p[X]$ then from the uniqueness of polynomial composition, there is only one $o(X)$ that fulfils the equation above.
	% If the check holds, then 
	% \[
	% 	\sum_{i = 1}^k \gamma^{i - 1} f_i(z) = \sum_{i = 1}^{k} \gamma^{i - 1} s_i\,
	% \]
	% and since $\gamma$ has been picked randomly and independently after the polynomials $\vec{f}$ were submitted it also holds 
	% \(
	% 	f_i(z) =  s_i,
	% \)
	%  for each individual $i \in \range{1}{k}$.
	\qed
\end{proof}

\begin{corollary}
	Let $\PCOM$ be a modification of the KZG polynomial commitment scheme \cite{AC:KatZavGol10} as presented in \cite{EPRINT:GabWilCio19}. Then $\PCOM$ is evaluation binding and has unique response property.
\end{corollary}

\begin{lemma}
	\label{lem:plonkprot_ur}
	If a polynomial commitment scheme $\PCOM$ is evaluation binding and has unique openings property\michals{28.08}{Property formalised in Sec 2.1}, then $\plonkprot$ is $\ur{3}$.\footnote{An attentive reader may note that $\plonkprot$ is $\ur{2}$. However, in the case presented here, less is required.}
\end{lemma}
\begin{proof}
	Assume the opposite and an adversary $\adv$ that breaks $\ur{3}$-ness of $\plonkprot$. 
	We consider 2 cases, depending on which round $\adv$ is able to provide at least two outputs such that the resulting transcripts are acceptable, and show that in each of them $\adv$ breaks evaluation binding property of $\PCOM$.
	
	\case{1}
	In Round 4 the prover is asked to give evaluations of predefined polynomials at some point $\chz$. Naturally, for the given polynomials only one value at $\chz$ is correct.
	Assume $\adv$ is able to produce two different outputs in that round: $\vec{r_4} = (\ev{\p{a}}, \ev{\p{b}}, \ev{\p{c}}, \ev{\p{S_{\sigma 1}}}, \ev{\p{S_{\sigma 2}}}, \ev{\p{r}}, \ev{\p{z}})$ and 
	$\vec{r_4} = (\ev{\p{a}}', \ev{\p{b}}', \ev{\p{c}}', \ev{\p{S_{\sigma 1}}}', \ev{\p{S_{\sigma 2}}}', \ev{\p{r}}', \ev{\p{z}}')$
	which suppose to be evaluations at $\chz$ of polynomials $\p{a}, \p{b}, \p{c}, \p{S_{\sigma 1}}, \p{S_{\sigma 2}}, \p{r}$ and an evaluation at $\chz \omega$ of $\p{z}$.
	Clearly, at least one of $\vec{r_4}$, $\vec{r'_4}$ has to be incorrect, thus if both evaluations are acceptable by the $\PCOM.\verify$ then the evaluation binding property of $\PCOM$ is broken.
	
	\case{2}
	In the last round of the protocol the prover provides openings for the polynomial commitments done before. 
	Assume $\adv$ is able to produce two different polynomial commitment openings pairs: 
	$\vec{r_5} = (\ev{\p{W_\chz}}, \ev{\p{W_{\chz \omega}}})$ and 
	$\vec{r'_5} = (\ev{\p{W_\chz}}', \ev{\p{W_{\chz \omega}}}')$.
	% Since \cref{lem:kzg_unique_op}, 
	Since $\PCOM$ has unique opening property, 
	one of the openings has to be incorrect and should be rejected by the polynomial commitment verifier. 
	\michals{28.08}{In this case we also need to show that only one opening for a KZG polynomial commitment is acceptable. This property seems not be covered by the original KZG paper}
	\michals{28.08}{See the lemma above}
	\qed
\end{proof}

\comment{
Equipped with \cref{lem:plonkprot_ur} we show the main theorem and prove that $\plonk$ is simulation extractable. The theorem assumes that dlog is hard, the interactive protocol underlying $\plonk$ is knowledge sound and has unique response property (after third round).

The proof goes by contradiction. Below we show some intuitions behind it.
Let $\advse$ be an adversary that breaks simulation extractability of $\plonkprotfs$ with some non-negligible probability. 
We show a $\rdv$ which use $\advse$ to either break knowledge soundness of $\plonkprot$ or to break $(\numberofconstrains + 2)$-dlog assumption.

The proof idea is following. First the reduction takes the CRS from a challenger
$\cdv_\plonkprot$ or $\cdv_\dlog$ \markulf{27.08}{For dlog the CRS needs to be
  computed from the monomials?}
	\michals{27.08}{I guess you meant for Plonk---yes, it needs to be computed from the monomials}, where the former represents game where the reduction tries to break soundness of $\plonkprot$ and the latter game of breaking the dlog assumption. We run the reductions in parallel and use $\rdv$ to denote either $\rdvks$ or $\rdvdlog$.
% For the sake of simiplicity we assume that $\rdv$ picks the challenger randomly. 

Then, the CRS is provided to the simulation extractability adversary. The reduction allows $\advse$ to make calls to a random oracle and get simulated proofs on required statements. All these queries are handled by $\rdv$.
Note that $\plonkprotfs$ makes $6$ calls to a random oracle to produce a proof
and for the adversary to be successful, it has to perform at least that number
of queries to produce its simulation extractability-breaking
proof.\markulf{27.08}{Why is this obvious? The adversary could randomize a
  simulated proof without having to make RO queries? I think we need to use the
  unique response property here.}
	\michals{27.08}{My idea was to include in these queries also the queries the simulator makes. I.e.~if adversary asks the simulator to produce a proof it, the simulator makes ro queries which are also counted.}
	 The reduction tries to guess which queries,
out of all random oracle queries submitted by the adversary
\markulf{27.08}{Maybe include all oracle queries, not just adversarial ones
  here? At least one query needs to be adversarial however?},\michals{27.08}{Yes} are going to be used in the final proof. Denote the queries by $h_{i_1}, \ldots, h_{i_6}$. 
The reduction on query $h_{i_1}$, which contain the first part of the proof and the proven statement $\inp$, engages in a conversation with $\plonkprot.\verifier$ and try to make a convincing proof for $\inp$ and sends $h_{i_1}$ as its first message for $\plonkprot.\verifier$. Given the verifier's challenge it passes the challenge to the adversary as a result of $\ro(h_{i_1})$. 
Similarly for the rest of the queries $h_{i_2}, \ldots, h_{i_6}$---the reduction passes them to the verifier and responds to the adversary with the verifier's challenges.

In the end, the adversary outputs a proof $\zkproof$ that should be acceptable
by $\plonkprotfs.\verifier$, thus the proof produced by $\rdv$ with challenges
from $\plonkprot.\verifier$ should be acceptable as well. Using the fact that
the adversary is algebraic, the reduction knows coefficients of the CRS elements
used in the output proof. For the adversary to be successful the proof cannot
only be acceptable, it should also be impossible to extract a correct witness
from it. We consider two cases. In the first, the proof is acceptable, but the
statement is false. This allows $\rdv$ to break the dlog assumption.
\markulf{27.08}{Guessing this is explained in more detail below.} Another case is when the proof is acceptable, statement is valid, but the witness cannot be extracted. This proof allows $\rdv$ to break knowledge soundness of $\plonkprot$.
}

\begin{theorem}
	Assume that $(\numberofconstrains + 2)$-dlog is hard, $\plonkprot$ is knowledge sound and $\ur{3}$. 
	Then $\plonkprotfs$ is simulation-extractable against algebraic adversaries.
\end{theorem}
\michals{28.08}{Minor thing -- need to change the reduction for dlog -- the CRS for Plonk requires also $\gtwo{\chi}$, which is not given as a part of the dlog challenge. I guess the simplest way to solve is would be to introduce a slight modification of the dlog assumption -- where the adversary learns not only $\gone{1, x, ..., x^n}$ but also $\gtwo{x}$.}
\begin{proof}
	The proof goes by contradiction. Assume there exists an adversary $\advse$ that breaks simulation extractability with non-negligible probability $\eps$. 
	We use $\advse$ to build two reductions $\rdvks$ and $\rdvdlog$, where the former uses $\advse$ to break knowledge soundness of $\plonkprot$ and the latter to break the $(\numberofconstrains + 2)$-dlog assumption.
	We start with picking a reduction at random and denote by $\rdv$ the chosen one.
	
	The reduction $\rdvks$ starts with obtaining a CRS $\crs$ from $\plonkprot.\kgen$ and passing it to $\advse$. 
	Similarly, $\rdvdlog$ gets its challenge $c$ from the $(\numberofconstrains + 2)$-dlog challenger $\cdv_\dlog$ and then internally starts $\plonkprot.\verifier$ equipping it with the CRS $\crs = c$. (Although the CRS from $\plonkprot.\kgen$ given to $\rdvks$ may not equal the challenge given by $\cdv_\dlog$ we use $\gone{1, \chi, \ldots, \chi^{\numberofconstrains + 2}}, \gtwo{\chi}$ to denote both of them.)
	%
	The reductions answer $\advse$ queries to the random oracle and provide it with simulated proofs $\vec{\zkproof_{\simulator, 1}}, \ldots, \vec{\zkproof_{\simulator, q_\simulator}}$ on submitted instances, where $q_\simulator$ is the total number of required simulated proofs---this is possible since the reductions control the random oracle instances and can program them as they wish.
	
	We assume that the adversary makes at most $q_\ro$ random oracle
  queries---including the queries that the simulator has to perform to be able
  to provide a simulated proof.
	\markulf{27.08}{That's consistent with what I
    suggested above then.} 
	To make a proof in $\plonkprotfs$ the adversary has to make at least $6$ random oracle queries. 
	Denote by $h$ a list of random oracle queries $h_{i_1}, \ldots, h_{i_6}$ that are used in the final proof $\zkproof_{\advse}$ returned by $\advse$.
	Denote by $\zkproof[i]$ the transcript of a proof after Round $i$. 
	For the proof to be acceptable with non-negligible probability it has to hold
	\begin{align*}
		h_{i_1} & = \zkproof_{\advse}[1] \| 0 \quad \pccomment{challenge $\beta$}\\
		h_{i_2} & = \zkproof_{\advse}[1] \| 1 \quad \pccomment{challenge $\gamma$}\\
		h_{i_3} & = \zkproof_{\advse}[2] \qquad \pccomment{challenge $\alpha$}\\
		h_{i_4} & = \zkproof_{\advse}[3] \qquad \pccomment{challenge $\chz$}\\
		h_{i_5} & = \zkproof_{\advse}[4] \qquad \pccomment{challenge $v$}\\
		h_{i_6} & = \zkproof_{\advse}[5] \qquad \pccomment{challenge $u$}
	\end{align*}
	The reduction guesses the indices $i_1, \ldots, i_6$ of the queries with probability at least $\infrac{1}{q_\ro^6}$. We assume that the guess is correct.
	
	Given query $i_1$ the reduction starts its interaction with $\plonkprot.\verifier$. That is, it sends $h_{i_1}$ as the first message to the verifier and gets the corresponding challenge. The challenge is returned to the adversary $\advse$ as an output of $\ro(h_{i_1})$. 
	Similarly for other guessed queries $h_{i_2}, \ldots, h_{i_6}$, except in that case the reduction continues its interaction with  $\plonkprot.\verifier$.
  \markulf{27.08}{I struggle to understand how this would work when simulated RO queries are reused.}
	\michals{28.08}{See the paragraph below}
	
	Assume $\zkproof_{\advse}[3] = \zkproof_{\simulator_k}[3]$, for some simulated proof $\zkproof_{\simulator_k}$.
	In that case the reduction has to abort since 
	on adversary's query $h_{i_4}$, which should equal $\zkproof_{\advse}[3]$, $\rdv$ has to return a challenge $\chz$ from the verifier $\plonkprot.\verifier$ to be able to finish its proof $\zkproof_\rdv$. 
	On the other hand, in a simulated proof the challenge $\chz_k$ that comes after Round 3 has to be programmed. 
	Unfortunately, if $\chz_k \neq \chz$, what happens except negligible probability, the reduction cannot provide $\chz$ to the adversary as it could spot the inconsistency in the random oracle responses---namely, it is once $\chz$ and $\chz_k$ another time despite the transcripts being equal. On the other hand, $\rdv$ also cannot provide $\advse$ with $\chz_k$ (again) as it differ from the verifier's challenge.
	%
	Fortunately, this situation happens with negligible probability only. 
	That is, assume that $\zkproof_{\advse}$ is acceptable by the verifier $\plonkprotfs.\verifier$ and differs from all simulated proofs $\zkproof_{\simulator_1}, \ldots, \zkproof_{\simulator_{q_\simulator}}$, 
	% (as we need $\advse$ to be successful) 
	and $\zkproof_{\advse}[3] =\zkproof_{\simulator_k}[3]$. 
	Since the produced proof has to be different from all simulated proofs, then $\advse$ could be used to break the $\ur{3}$-ness of $\plonkprot$.
	Thus we may assume that the random oracle query done by $\advse$ on $\zkproof_{\advse}[3]$ is fresh.

	Eventually, the adversary returns a proof $\zkproof$ for some statement $\inp$. We assume that $\plonkprot.\verifier$ accepts $\zkproof$, if that is not the case $\advse$ fails.
	
	Since $\advse$ is algebraic the adversary provides along the proof $\zkproof$ also vectors of coefficients of all group elements it learnt for all group elements in the proof---that is, for each group element $\gone{\iota}$ included in the proof $\advse$ provides vector of coefficients $\vec{\iota}$ such that
	\[
		\iota = \vec{\iota}^\top \cdot (\underbrace{1 \| \chi \| \ldots \| \chi^{\numberofconstrains + 2}}_{\crs} \| \vec{\tilde{\zkproof}_\simulator}_1^{\top} \| \ldots \| \vec{\tilde{\zkproof}_\simulator}_{q_\simulator}^\top)^\top,
	\]
	where $\vec{\tilde{\zkproof}_\simulator}_{j}$ is a vector of group elements contained in the $j$-th simulated proof requested by the adversary.
	Since the reduction also constructs its simulated proofs by using $\crs = \gone{1, \chi, \ldots, \chi^{\numberofconstrains + 2}}$ it knows the representation of $\vec{\tilde{\zkproof}_\simulator}_1, \ldots, \vec{\tilde{\zkproof}_\simulator}_{q_\simulator}$ as vectors of $(1, \chi, \ldots, \chi^{\numberofconstrains + 2})$. 
	That is, it knows a vector $\vec{\tilde{\iota}}$ such that
	\[
		\gone{\iota} = \vec{\tilde{\iota}}^\top \cdot (1 \| \chi \| \ldots \| \chi^{\numberofconstrains + 2})^\top\,.
	\]
	
	Recall $\plonkprot$'s verification equation, \cref{eq:ver_eq}. Let $\vereq(X)$ be a polynomial such that 
	\[
		\vereq(X) = \p{W_{\chz}}(X) + u \cdot \p{W_{\chz \omega}}(X)
		\cdot X - \chz \cdot \p{W_{\chz}}(X) - u \chz \omega \cdot \p{W_{\chz \omega}}(X) -  F(X) + E = 0\,.
	\]
	Hence, from the soundness of the polynomial protocol underlying $\plonkprot$ the polynomial $\vereq(X)$ should be a zero-polynomial if all the constrains of the proof system are fulfilled. However, in the real life protocol only $\vereq$'s value at $\chi$ is checked to be $0$.
	
	Consider two cases. 
	First, when $\vereq(X) = 0$. Obviously then it also holds that $\vereq(\chi) =
  0$, i.e.~the verifier accepts the proof. In that case $\rdvks$ reconstructs
  polynomials $\p{a}(X), \p{b}(X), \p{c}(X)$ from the corresponding vectors of
  coefficients of the CRS elements, which are output by $\advse$ since it is algebraic. 
	Given the coefficients of the polynomials, $\rdvks$ reveals a witness $\wit$ and verifies whether $\REL(\inp, \wit) = 1$.
  \markulf{27.08}{How is the knowledge extraction extractor $E$ used here?}
	\michals{27.08}{Quite naturally -- since the reduction knows coefficients of polynomials $a, b, c$ it knows the witness as the witness is included in these coefficients.}
	If it does then $\rdvks$ fails, but also $\advse$ fails. Alternatively, if
  $\REL(\inp, \wit) = 0$, then $\rdvks$ produced a
  $\plonkprot.\verifier$-acceptable transcript for a false statement. Thus it
  breaks $\plonkprot$'s soundness. \markulf{27.08}{Soundness or knowledge soundness?}
	\michals{27.08}{Good question. I think it may even break soundness}
	
	Second, if $\vereq(X)$ is not identically equal zero, but $\vereq(\chi) = 0$, then the reduction $\rdvdlog$ can find zeroes of $\vereq(X)$ and hence reveal $\chi$ breaking the $(\numberofconstrains + 2)$-dlog assumption.
	\qed
\end{proof}

\begin{theorem}[Simulation extractability]
	~\newline\michals{29.08}{Proof done similarly to \cite{INDOCRYPT:FKMV12}}
	Assume that $(\numberofconstrains + 2)$-dlog is $\eps_\dlog(\secpar)$-hard, $\plonkprot$ is knowledge sound and $\ur{3}$ with security $\eps_{\ks}(\secpar)$ and $\eps_{\ur{3}}(\secpar)$ respectively. 
	Then the probability that an algebraic, PPT adversary $\advse$ breaks simulation extractability of $\plonkprotfs$ is upper-bounded by 
	\[
		\eps_{\ur{3}}(\secpar) + q_\ro^6 (\eps_{\dlog}(\secpar) + \eps_{\ks}(\secpar))\,,
	\]
	where $q_\ro$ is the total number of queries required by the adversary $\advse$.
\end{theorem}
\begin{proof}
	We proceed by contradiction. Suppose there exists a PPT adversary $\advse$ that breaks simulation extractability with non-negligible probability
	\[
	\eps := \Pr
		\left[
		\begin{aligned}
			& \plonkprotfs.\verifier(\REL, \crs, \inp, \zkproof_{\advse}),\\
			& (\inp_{\advse}, \zkproof_{\advse}) \not\in Q,\\
			& \neg \REL(\inp_{\advse}, \wit_{\advse}) 
		\end{aligned}
		\,\left|\,
		\begin{aligned}
			& \crs \gets \plonkprotfs.\kcrs(\REL, \secparam)\\
			& (\inp_{\advse}, \zkproof_{\advse}) \gets \advse^{\simulator, \ro} (\REL, \crs),\\
			& \wit_{\advse} \gets \ext_{\advse}(\REL, \crs, \inp, \zkproof_{\advse})
		\end{aligned}
		\right.\right].
	\]

In such case, we are able to build reductions $\rdvks$, $\rdvur$, $\rdvdlog$ which using $\advse$ as a black-box, violate either the soundness, unique response properties of the underlying interactive protocol $\plonkprot$, or the $(\numberofconstrains + 2)$-dlog assumption.

In the following we denote by $\zkproof_{\advse}, \zkproof_{\simulator}$ proofs returned by the adversary and the simulator respectively. We use $\zkproof[i]$ to denote prover's message in the $i$-th round of the proof, $\zkproof[i].\ch$ to denote the challenge that is given to the prover after $\zkproof[i]$, and $\zkproof\range{i}{j}$ to denote all messages of the proof between rounds $i$ and $j$.

Without loss of generality, for every acceptable proof $\zkproof_{\advse}$, we assume that whenever $\advse$ outputs in Round $i$ a message $m$, then $\zkproof_{\advse}\range{1}{i}$ is a fresh query to the random oracle. 
It is straightforward to transform any adversary that violates this condition into an adversary that makes these additional queries to the random oracle and wins with the same probability.

A crucial observation is that the adversary $\advse$ may have learned $\zkproof_{\advse}\range{1}{3}$ by querying the simulator on $\inp_{\advse}$ or might have computed it itself. We denote the first event by $\event{E}$ and the second by $\nevent{E}$. 
%
Additionally, we divide event $\nevent{E}$ into two disjunctive subevents: $\nevent{E}_0$ and $\nevent{E}_1$. 
Event $\nevent{E}_0$ considers a case when the final proof provided by the adversary $\advse$ is accepted by the idealised verification equation, i.e.~for that proof $\vereq(X) = 0$. 
Alternatively, event $\nevent{E}_1$ covers a case when for $\zkproof_\advse$ holds $\vereq(\chi) = 0$, but $\vereq(X) \neq 0$, where $\chi$ is $\plonkprotfs$'s trapdoor.
%
As all these events are mutually exclusive and exhaustive, we have
\[
	\eps = \prob{\advse \text{ wins}} = \prob{\advse \text{ wins}, \event{E}} + \prob{\advse \text{ wins}, \nevent{E}_0} + \prob{\adv \text{ wins}, \nevent{E}_1}\,.
\]

\ncase{When $\event{E}$ happens}
We assume that $\inp_{\advse}$ is submitted to the simulator $\simulator$. 
We show how $\rdvur$ utylises $\advse$, that makes use of $\inp_\advse, \zkproof_{\advse}\range{1}{3}$, to break the $\ur{3}$ property of $\plonkprot$. 
This way we bound the probability $\prob{\adv \text{ wins}, \event{E}}$ by the probability of $\rdvur$ being able to win in the $\ur{3}$ game.

Consider an algorithm $\rdvur$ that runs $\advse$ internally as a black-box:
\begin{itemize}
	\item The reduction answers both queries to the simulator $\plonkprotfs.\simulator$ and to the random oracle. 
	It also keeps lists $Q$, for the simulated proofs, and $Q_\ro$ for the random oracle queries. 
	\item When $\advse$ outputs a fake proof $\zkproof_{\advse}$ for  $\inp_\advse$, $\rdvur$ looks through lists $Q$ and $Q_\ro$ until it finds 
	$\zkproof_{\simulator}\range{1}{3}$ such that $\zkproof_{\advse}\range{1}{2} = \zkproof_{\simulator}\range{1}{2}$ and a random oracle query $\zkproof_{\simulator}[2].\ch$ on $\zkproof_{\simulator}\range{1}{2}$.
	\item $\rdvur$ returns two proofs for $\inp_\advse$:
	\begin{align*}
		\zkproof_1 = (\inp_{\advse},\zkproof_{\simulator}\range{1}{2}, \zkproof_{\simulator}[2].\ch, \zkproof_{\simulator}\range{3}{5})\\
		\zkproof_2 = (\inp_{\advse}, \zkproof_{\simulator}\range{1}{2}, \zkproof_{\simulator}[2].\ch, \zkproof_{\advse}\range{3}{5})
	\end{align*}
	\end{itemize}  
	If $\zkproof_1 = \zkproof_2$, then $\advse$ fails to break simulation extractability, as $\zkproof_2 \in Q$.
	On the other hand, if the proofs are not equal, then $\rdvur$ breaks $\ur{3}$-ness of $\plonkprot$. Thus 
	\[
		\prob{\adv \text{ wins}, \event{E}} \leq \eps_{\ur{3}}(\secpar).
	\]
	
	Before the events $\nevent{E}_0$ and $\nevent{E}_1$ are analysed, the following observation should be made.
	Since $\advse$ is algebraic, the proof $\zkproof_\advse$ it outputs can be written as 
	\[
		\zkproof_\advse = \vec{M} \cdot (\underbrace{1 \| \chi \| \ldots \| \chi^{\numberofconstrains + 2}}_{\crs} \| \vec{\tilde{\zkproof}_\simulator}_1^{\top} \| \ldots \| \vec{\tilde{\zkproof}_\simulator}_{q_\simulator}^\top)^\top\,,
	\]
	where $\gone{1, \chi, \ldots, \chi^{\numberofconstrains + 2}}$ are all $\GRP_1$-elements from the CRS of $\plonkprotfs$, $\vec{M}$ is a matrix of coefficients output by $\advse$ aside the proof, and $\vec{\tilde{\zkproof}_\simulator}_i$ denote all $\GRP_1$-elements from the simulated proof ${\zkproof_\simulator}_i$. 
	Since the reduction provides the simulated proofs, it knows a matrix $\vec{M'}$ such that
	\begin{equation}
		\label{eq:M_prim}
		\zkproof_\advse = \vec{M'} \cdot (1 \| \chi \| \ldots \| \chi^{\numberofconstrains + 2})^\top\,.
	\end{equation}
	We use this property when analysing probability success of reductions $\rdvks$ and $\rdvdlog$.
	
	We also note that a proof $\zkproof$ could be accepted only if the verification equation $\vereq(\chi)$ holds. That is, the verifier plugs-in elements of $\zkproof$ into $\vereq(\chi)$ and checks whether it equals $0$. That is what is called a \emph{real check} in \cite{EPRINT:GabWilCio19}. 
	On the other hand there is an \emph{idealised check}, which verifies whether $\vereq(X) = 0$ \emph{as a polynomial} (with proof elements being polynomials as well).

\ncase{When $\nevent{E}_0$ happens}
In this case the reduction $\rdvks$ uses $\advse$ to break the \hl{knowledge} soundness of $\plonkprot$ with probability $\eps_\ks / q_{\ro}^6$, where $q_\ro$ is the number of total random oracle queries performed by the adversary or by $\rdvks$ on behalf of the simulator.
As previously, $\rdvks$ runs $\advse$ internally and simulates its environment by answering to its queries to $\plonkprotfs.\simulator$ and $\ro$. The reduction works as follows:
\begin{itemize}
	\item It guesses indices $i_1, \ldots, i_6$ such that $\advse$'s queries $h_{i_1}, \ldots, h_{i_6}$ are the queries used in $\zkproof_\advse$. This is done with probability at least $1/q_{\ro}^6$ (since there are $6$ challenges from the verifier in $\plonkprot$).
	\item On query $h \not\in \smallset{h_{i_1}, \ldots, h_{i_6}}$, $\rdvks$ returns randomly picked $y$, sets $\ro(h) = y $ and stores $(h, y)$ in $Q_\ro$ if $h$ is sent to $\ro$ the first time. If that is not the case, $\rdv$ finds $h$ in $Q_\ro$ and returns the corresponding $y$.
	\item On query $h \in \smallset{h_{i_1}, \ldots, h_{i_6}}$, $\rdvks$ runs $\plonkprot$ with $\plonkprot.\verifier$ using $h_{i_j}$ as a $\plonkprot.\prover$'s $j$-th message. The verifier responds with a challenge $\zkproof[j].\ch$. The reduction sets $\ro(h) = \zkproof[j].\ch$
	\item On query $\inp_\simulator$ to $\simulator$ it runs a simulator $\plonkprotfs.\simulator$ internally and returns $\zkproof_\simulator$.
	\item Answers $\plonkprot.\verifier$'s challenge $\zkproof[j].\ch$ using $\zkproof_\advse[j + 1]$.
\end{itemize}

Assume that the $\plonkprot.\verifier$ accepts $\zkproof_\advse$. We consider a case when the idealised verification equation accepts. (Thus, the real verification accepts as well.) 
In that case $\rdvks$ extracts from $\vec{M'}$ coefficients of $1, \chi, \ldots, \chi^{\numberofconstrains + 2}$ for polynomials $\p{a}, \p{b}$, and $\p{c}$ and reveals the witness $\wit_\advse$ (as it is encoded in theses polynomials' coefficients).
If $\REL(\inp_\advse, \wit_\advse)$ holds then $\advse$ failed to break simulation-extractability of $\plonkprotfs$. On the other hand, if that is not the case, then $\rdvks$ breaks soundness of $\plonkprot$.
%
Since the reduction guesses queries $h_{i_1}, \ldots, h_{i_6}$ with probability $1/q_\ro^6$, then 
\begin{gather*}
	\prob{\rdvks \text{ wins}} = \prob{\advse \text{ wins}, h_{i_1}, \ldots, h_{i_6} \text{ are guessed correctly}, \nevent{E}_0}, \text{ hence}\\
	\prob{\advse \text{ wins}, \nevent{E}_0} \leq q_\ro^6 \cdot \eps_{\ks}(\secpar).
\end{gather*}

\ncase{When $\nevent{E}_1$ happens}
The reduction $\rdvdlog$ runs internally a protocol $\plonkprotfs$, which CRS is computed from the challenge $\gone{1, \chi, \ldots, \chi^{\numberofconstrains + 2}}, \gtwo{\chi}$ from the $(\numberofconstrains + 2)$-dlog assumption challenger. 
Then it proceeds as $\rdvks$ does, except in the last part, when the adversary provided its proof $\zkproof_\advse$, $\rdvdlog$ uses the fact that the real verification equation holds, but the ideal verification equation does not to break the dlog assumption. 


Since $\vereq(X) \neq 0$, but $\vereq(\chi) = 0$ and $\rdvdlog$ knows $\vec{M'}$, as defined in \cref{eq:M_prim}, it can recreate all the polynomials submitted by $\advse$ as part of the proof and included in $\vereq(X)$. This way, it knows all coefficients of $\vereq(X)$. Thus it can factorise it and find its roots, one of the would be the required $\chi$. Hence, by the analogous analysis as in the previous case, holds
\[
	\prob{\advse \text{ wins}, \nevent{E}_1} \leq q_\ro^6 \cdot \eps_{\dlog}(\secpar).
\]

The proof is concluded by observing that the analysis of events $\event{E}, \nevent{E}_0, \nevent{E}_1$ gives
\[
	\eps \leq \eps_{\ur{3}}(\secpar) + q_\ro^6 (\eps_{\dlog}(\secpar) + \eps_{\ks}(\secpar))\,,
\]
hence $\eps$ is negligible if dlog is hard and $\plonkprot$ is sound and $\ur{3}$.
\qed
\end{proof}

\section{Simulation extractability with special soundness and no AGM}
	\task{26.08}{Here the generalised forking lemma could go}
\bibliographystyle{alpha}
\bibliography{cryptobib/abbrev1,cryptobib/crypto,additional_bib}

\appendix
\section{$\plonk$'s prover explained}
\label{sec:plonk_explained}

\paragraph{\fbox{\normalfont{$\plonk$ prover $\prover(\REL, \crs, \inp, \wit)$}}}


\paragraph{\fbox{\normalfont{$\plonk$ verifier $\verifier(\REL, \crs, \inp, \zkproof)$}}}\ \newline
The \plonk{} verifier works as follows
\begin{description}
	\item[Step 1] Validate all obtained group elements.
	\item[Step 2] Validate all obtained field elements.
	\item[Step 3] Validate the instace $\inp = \smallset{\wit_i}_{i = 1}^\instsize$.
	\item[Step 4] Compute challenges $\beta, \gamma, \alpha, \alpha', \chz, v, u$ from the transcript.
	\item[Step 5] Compute zero polynomial evaluation $\p{Z_H} (\chz)  =\chz^\numberofconstrains - 1$.
	\item[Step 6] Compute Lagrange polynomial evaluation $\lag_1 (\chz) = \frac{\chz^\numberofconstrains -1}{\numberofconstrains (\chz - 1)}$.
	\item[Step 7] Compute public input polynomial evaluation $\pubinppoly (\chz) = \sum_{i \in \range{1}{\instsize}} \wit_i \lag_i(\chz)$.
	\item[Step 8] Compute quotient polynomials evaluations
	\begin{multline*}
		\p{t} (\chz)  = \frac{1}{\p{Z_H}(\chz)}
		\Big(
			\p{r} (\chz) + \pubinppoly(\chz) - (\p{a}(\chz) + \beta \p{S_\sigma 1}(\chz) + \gamma) (\p{b}(\chz) + \beta \p{S_\sigma 2}(\chz) + \gamma) \\
			(\p{c}(\chz) +
			\gamma)\p{z}(\chz \omega) \alpha - \lag_1 (\chz) \alpha^2
		\Big) \,.
	\end{multline*}
	\item[Step 9] Compute batched polynomial commitment
	$\gone{D} = v \gone{r} + u \gone {z}$ that is
	\begin{align*}
		\gone{D} & = v
		\left(
		\begin{aligned}
			& \p{a}(\chz)\p{b}(\chz) \cdot \gone{\selmulti} + \p{a}(\chz)  \gone{\selleft} + \p{b}  \gone{\selright} + \p{c}  \gone{\seloutput} + \\
			& + (	(\p{a}(\chz) + \beta \chz + \gamma) (\p{b}(\chz) + \beta k_1 \chz + \gamma) (\p{c} + \beta k_2 \chz + \gamma) \alpha  + \lag_1(\chz) \alpha^2)  + \\
			% &   \\
			& - (\p{a}(\chz) + \beta \p{S_{\sigma 1}}(\chz) + \gamma) (\p{b}(\chz) + \beta \p{S_{\sigma 2}}(\chz) + \gamma) \alpha  \beta \p{z}(\chz \omega) \gone{\p{S_{\sigma 3}}(\chi)})
		\end{aligned}
		\right) + \\
		& + u \gone{\p{z}(\chi)}\,.
	\end{align*}
	\item[Step 10] Computes full batched polynomial commitment $\gone{F}$:
	\begin{align*}
		\gone{F} & = \left(\gone{\p{t_{lo}}(\chi)} + \chz^\numberofconstrains \gone{\p{t_{mid}}(\chi)} + \chz^{2 \numberofconstrains} \gone{\p{t_{hi}}(\chi)}\right) + u \gone{\p{z}(\chi)} + \\
		& + v
		\left(
		\begin{aligned}
			& \p{a}(\chz)\p{b}(\chz) \cdot \gone{\selmulti} + \p{a}(\chz)  \gone{\selleft} + \p{b}  \gone{\selright} + \p{c}  \gone{\seloutput} + \\
			& + (	(\p{a}(\chz) + \beta \chz + \gamma) (\p{b}(\chz) + \beta k_1 \chz + \gamma) (\p{c} + \beta k_2 \chz + \gamma) \alpha  + \lag_1(\chz) \alpha^2)  + \\
			% &   \\
			& - (\p{a}(\chz) + \beta \p{S_{\sigma 1}}(\chz) + \gamma) (\p{b}(\chz) + \beta \p{S_{\sigma 2}}(\chz) + \gamma) \alpha  \beta \p{z}(\chz \omega) \gone{\p{S_{\sigma 3}}(\chi)})
		\end{aligned}
		\right) \\
		& + v^2 \gone{\p{a}(\chi)} + v^3 \gone{\p{b}(\chi)} + v^4 \gone{\p{c}(\chi)} + v^5 \gone{\p{S_{\sigma 1}(\chi)}} + v^6 \gone{\p{S_{\sigma 2}}(\chi)}\,.
	\end{align*}
	\item[Step 11] Compute group-encoded batch evaluation $\gone{E}$
	\begin{align*}
		\gone{E}  = \frac{1}{\p{Z_H}(\chz)} & \gone{
		\begin{aligned}
			& \p{r}(\chz) + \pubinppoly(\chz) +  \alpha^2  \lag_1 (\chz) + \\
			& - \alpha \left( (\p{a}(\chz) + \beta \p{S_{\sigma 1}} (\chz) + \gamma) (\p{b}(\chz) + \beta \p{S_{\sigma 2}} (\chz) + \gamma) (\p{c}(\chz) + \gamma) \p{z}(\chz \omega) \right)
		\end{aligned}
		}\\
		 + & \gone{v \p{r}(\chz) + v^2 \p{a}(\chz) + v^3 \p{b}(\chz) + v^4 \p{c}(\chz) + v^5 \p{S_{\sigma 1}}(\chz) + v^6 \p{S_{\sigma 2}}(\chz) + u \p{z}(\chz \omega) }\,.
	\end{align*}
	\item[Step 12] Check whether the verification equation holds
	\begin{multline}
		\label{eq:ver_eq}
		\left(
		\gone{\p{W_{\chz}}(\chi)} + u \cdot \gone{\p{W_{\chz \omega}}(\chi)}
		\right) \bullet
		\gtwo{\chi} = \\
		\left(
			\chz \cdot \gone{\p{W_{\chz}}(\chi)} + u \chz \omega \cdot \gone{\p{W_{\chz \omega}}(\chi)} + \gone{F} - \gone{E}
		\right) \bullet
		\gtwo{1}\,.
	\end{multline}
The verification equation is a batched version of the verification equation from \cite{AC:KatZavGol10} which allows the verifier to check openings of multiple polynomials in two points (instead of checking an opening of a single polynomial at one point).
\end{description}

Since the original paper \cite{EPRINT:GabWilCio19} lacks of explanation how the simulator of \plonk{} works, it is presented here.
\paragraph{\fbox{\normalfont{$\plonk$ simulator $\simulator(\REL, \crs, \td, \inp)$}}}
% \paragraph{Simulation in \plonk.}
% The simulator $\simulator$ in $\plonk$ proceeds according to the following steps:
\begin{description}
	\item[Round 1]
	Since the simulator does not know a witness $\wit$ for the proven statement $\inp$, $\simulator$ cannot compute the output of this round accordingly to the protocol. Instead, it picks randomly both the "blinders" $b_1, \ldots, b_6$ and evaluations of polynomials $\p{a}, \p{b}, \p{c}$ by picking their coefficients randomly and outputting $\gone{\p{a}(\chi), \p{b}(\chi), \p{c}(\chi)}$.
	\item[Round 2]
	The simulator takes permutation argument challenges $\beta, \gamma$ as a random oracle output in the ongoing proof.
	Similarly as in the previous round, the simulator cannot evaluate the requested polynomial $\p{z}$ honestly as it does not know the witness, picks its coefficients randomly and outputs $\gone{\p{z}(\chi)}$.
	\item[Round 3]
	In this round the simulator starts by picking at random a challenge $\chz$ that will be later used to program a random oracle.
	Then it computes evaluations $\p{a}(\chz), \p{b}(\chz), \p{c}(\chz), \p{S_{\sigma 1}}(\chz), \p{S_{\sigma 2}}(\chz), \pubinppoly(\chz), \lag_1(\chz), \p{Z_H}(\chz),\allowbreak \p{z}(\chz\omega)$
	
	Given the evaluations $\simulator$ computes polynomial $\p{r}(X)$ honestly, i.e.
	\[
		\p{r}(X) = 
		\begin{aligned}
			& \p{a}(\chz) \p{b}(\chz) \selmulti(X) + \p{a}(\chz) \selleft(X) + \p{b}(\chz) \selright(X) + \p{c}(\chz) \seloutput(X) + \selconst(X) \\
			& + \alpha \cdot \left( (\p{a}(\chz) + \beta \chz + \gamma) (\p{b}(\chz) + \beta k_1 \chz + \gamma)(\p{c}(\chz) + \beta k_2 \chz + \gamma) \cdot \p{z}(X)\right) \\
			& - \alpha \cdot \left( (\p{a}(\chz) + \beta \p{S_{\sigma 1}}(\chz) + \gamma) (\p{b}(\chz) + \beta \p{S_{\sigma 2}}(\chz) + \gamma)\beta \p{z}(\chz\omega) \cdot \p{S_{\sigma 3}}(X)\right) \\
			& + \alpha^2 \cdot \lag_1(\chz) \cdot \p{z}(X)
		\end{aligned}
	\]
	and evaluates $\p{r}(X)$ at $\chz$.
	
	In the next step the simulator computes $\ev{t}$ as the verifier would compute in Step 8.
	Next, $\simulator$ picks randomly a polynomial $\p{t}$ such that $\p{t} (\chz) = \ev{t}$.
	The simulator concludes this round as an honest prover would by dividing $\p{t}$ into $\p{t_{hi}}, \p{t_{mid}}, \p{t_{lo}}$ and outputting $\gone{\p{t_{hi}}(\chi), \p{t_{mid}}(\chi), \p{t_{lo}}(\chi)}$. 
	\item[Round 4]
	The simulator program random oracle to return $\chz$ when queried on the current state of the transcript. 
	Since the necessary evaluations at $\chz$ are already computed, $\simulator$ simply outputs 
	\[
		\p{a}(\chz), \p{b}(\chz), \p{c}(\chz), \p{S_{\sigma 1}}(\chz), \p{S_{\sigma 2}}(\chz), \p{t}(\chz), \p{z}(\chz \omega)\,.
	\]
	\item[Round 5]
	In this round the simulator proceeds as an honest prover would.
	\end{description}
	
	\section{OLDIES}
	section
	{Simulation extractability from unique responses and witness-extended emulation.}
	We can now present two proofs for the Fiat--Shamir transform simulation extractability, one for the standard---weaker---version of the unique response property, one for the stronger.
	\michals{08.07.20}{That probably will be changed as we don't have disctinction of weak and strong ur prop.---the weak version that worked for CRS-less protocols has been provisionally removed.}

	In the former, we assume that the underlying interactive proof system is in the standard model. More precisely, we require that the only additional power given to the simulator is the ability of producing proof elements in any order it wants. Especially, producing a simulated proof does not require knowledge of some sort of a trapdoor.
	Although we believe that this result may be of independent interest, it is not enough in our case, it is not enough to show simulation extractability of \plonk.
	This is since we show our result by contradiction and build an adversary $\bdv$ that breaks the unique response property using an adversary $\adv$ that breaks simulation extractability. Thus, to make the reduction hold we need to allow $\bdv$ to make simulated proofs for $\adv$.

	To make the result useful in the context of CRS-model zkSNARKs like \plonk, we need to rely on a stronger version of the unique response property presented in \cref{def:wiur} to allow the unique-response-property adversary to learn the simulated proofs as well.

	\begin{theorem}[Simulation extractability of the Fiat--Shamir transform II]
		\label{thm:wit_ext_em_FS_II}
		Let $\proofsystem = (\kgen, \prover, \verifier, \simulator)$ be an interactive $\mu$-round $\ur{i}$ protocol for a relation $\REL$ and $i < \mu$.
		Assume there exists an extractor $\ext$ that extracts the witness from a $(n_1, \ldots, n_\mu)$-tree of accepting transcripts of $\proofsystem$ and $\prod_{j = 1}^\mu n_j \leq \poly$.
		Then $\proofsystem_\fs$ is simulation-extractable in the random oracle model.
	\end{theorem}
	\begin{proof}
		The proof goes similarly to \cite[Theorem 3]{INDOCRYPT:FKMV12}. For the sake of clarity let divide the simulator algorithm $\simulator_\fs$ of $\proofsystem_\fs$  into two subroutines:
		\begin{description}
			\item[$\simulator_{\fs, \ro}$] that takes care about random oracle queries. Assume that there is an upper bound $Q = \poly$ for the number of queries that may be submitted.
			For a query $x$ simulator $\simulator_{\fs, \ro}$ checks whether a list of queries $L$ already contains a pair $(x, y)$, for some $y$, and, if that is the case, outputs $y$.
			Otherwise, it picks an element $y'$ from the random oracle codomain, outputs it and adds $(x, y')$ to $L$. Importantly $y'$ is picked accordingly to the randomness tape provided to $\simulator_{\fs, \ro}$, i.e.~one may assume that $\simulator_{\fs, \ro}$ gets as input a randomness tape $r$ that provides values $y_1, \ldots, y_Q$.
			When the simulator needs to answer a fresh query $x$ it takes the successive $y_i$ from $r$.
			\item[$\simulator_{\fs, \zkproof}$] that provides simulated proofs. The simulator may also program random oracle queries as it wishes. That is, it may add pair $(x, y)$ to $L$ unless there is a pair that have $x$ on the first position. In that case it aborts.
		\end{description}

		Let $\adv_\se^{\simulator_\fs}$ be a simulation-extractability adversary for $\proofsystem_\fs$, $\inp$ the instance $\adv_\se$ proves and $\zkproof = \vec{a} = (a_0, \ldots, a_\mu)$ the corresponding acceptable proof.
		W.l.o.g.~we may assume that $(\inp, \pi)$ is output after $\adv_\se$ learnt simulated proofs from $\simulator_{\fs, \zkproof}$.

		For each $j > i$, divide the adversary's proof $\zkproof$ into two parts:
		first, $\vec{a}_{[0:j]} = (a_0, \ldots, a_j)$ and second $\vec{a}_{{[j + 1:\mu]}} = (a_{j + 1}, \ldots, a_\mu)$.
		Note that $(\inp, \vec{a}_{[0:j]})$ is a fresh query to the random oracle that is performed by the adversary.
		Otherwise, if the query was made by the simulator $\simulator_{\fs, \zkproof}$ then, since $\proofsystem$ is an $\ur{i}$-protocol and $j > i$, a proof starting with $(\inp, \vec{a}_{[0:j]})$ is already in the list of simulated proofs $Q$ and cannot be used by the simulation-extractability adversary $\adv_\se$.

		The tree of accepting transcripts is generating by rewinding the adversary as depicted on~\cref{fig:rewinding_advse}, which is a version of the tree extraction algorithm from \cref{fig:rewinding_prover} tuned for non-interactive proofs and adversaries that have access to simulated proofs.
		To obtain the full tree of transcripts the extractor runs $\treebuild_{\adv_\se, \simulator_{\fs, \zkproof}, \simulator_{\fs, \ro}}^{\REL, \crs, \inp}(1)$, verifies whether all collected transcripts are acceptable and the tree is valid and, if that is the case, returns the witness.

		\begin{figure}
			\centering
			\fbox{
			\procedure{$\treebuild_{\adv_\se, \simulator_{\fs, \zkproof}, \simulator_{\fs, \ro}}^{\REL, \crs, \inp} (i)$}
			{
				\pcif i = \mu + 1 \pcthen\\
					\pcind \zkproof \gets \adv_\se^{\simulator_{\fs, \zkproof}, \simulator_{\fs, \ro}}(\REL, \crs)\\
					\pcind \pcif (\inp, \zkproof) \in Q \pcthen \pcreturn (\zkproof, \bot) \\
					\pcind \pcind \pccomment{$Q$ is the list of $(\inp, \zkproof)$ pairs that have been submitted to  $\simulator_{\fs, \ro}$.}\\
					\pcind b \gets \verifier(\REL, \crs, \inp, \zkproof)\\
					\pcind \pcif b = 0 \pcthen \pcreturn (\zkproof, \bot)\\
					\pcind \pcif b = 1 \pcthen \\
					\pcind \pcind \tree \gets \smallset{\zkproof}\ \pcreturn (\zkproof, \tree)	\\
				\text{Run $\adv_\se$ up to and including query $(\inp, \vec{a}_{[0 : i]})$ to $\simulator_{\FS, \ro}$}\\
				(\zkproof, \tree) \gets \treebuild(i + 1)\\
				\pcif \tree = \bot \pcthen \pcreturn (\zkproof, \bot)\\
				\counter \gets 1\\
				\pcwhile \counter \leq n_i \pcthen\\
				\pcind \text{Rewind $\adv_\se$ back until just before it gets response to $\simulator_{\fs, \ro}$ query $(\inp, \vec{a}_{[0 : i - 1]})$}\\
				\pcind (\zkproof', \tree') \gets \treebuild(i + 1)\\
				\pcind \pcif \tree' \neq \bot \pcthen\\
				\pcind \pcind \tree \gets \tree \cup \smallset{\zkproof'} \\
				\pcind \pcind \counter \gets \counter + 1\\
				\pcreturn \zkproof, \tree
			}}
			\caption{Rewinding strategy for $\adv_\se$---getting a tree of accepting transcripts. For the sake of clarity parameters of $\treebuild$ algorithm have been omitted in the code. We also assume that $\adv_\se$ separately outputs instance $\inp$ which it plans to prove.}
			\label{fig:rewinding_advse}
	\end{figure}
		\qed
	\end{proof}
\end{document}

