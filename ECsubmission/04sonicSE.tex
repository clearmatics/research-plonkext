% !TEX root = main.tex
% !TEX spellcheck = en-US


\section{Non-malleability of $\sonicprotfs$}
\label{sec:sonic}
\subsection{\sonic{} protocol rolled out}
In this section we present $\sonic$'s constraint system and algorithms. Reader
familiar with them may jump directly to the next section.

\oursubsub{The constraint system}
\label{sec:sonic_constraint_system}
\sonic's system of constraints composes of three $\multconstr$-long vectors
$\va, \vb, \vc$ which corresponds to left and right inputs to multiplication
gates and their outputs. It hence holds $\va \cdot \vb = \vc$.

There is also $\linconstr$ linear constrains of the form
\[
  \va \vec{u_q} + \vb \vec{v_q} + \vc \vec{w_q} = k_q,
\]
where $\vec{u_q}, \vec{v_q}, \vec{w_q}$ are vectors for the $q$-th linear
constraint with instance value $k_q \in \FF_p$. Furthermore define polynomials
\begin{equation}
  \begin{split}
    \p{u_i}(Y) & = \sum_{q = 1}^\linconstr Y^{q + \multconstr} u_{q, i}\,,\\
    \p{v_i}(Y) & = \sum_{q = 1}^\linconstr Y^{q + \multconstr} v_{q, i}\,,\\
  \end{split}
  \qquad
  \begin{split}
    \p{w_i}(Y) & = -Y^i - Y^{-i} + \sum_{q = 1}^\linconstr Y^{q +
      \multconstr} w_{q, i}\,,\\
    \p{k}(Y) & = \sum_{q = 1}^\linconstr Y^{q + \multconstr} k_{q}.
  \end{split}
\end{equation}

$\sonic$ constraint system requires that
\begin{align}
  \label{eq:sonic_constraint}
  \vec{a}^\top \cdot \vec{\p{u}} (Y) + \vec{b}^\top \cdot \vec{\p{v}} (Y) +
  \vec{c}^\top \cdot \vec{\p{w}} (Y) + \sum_{i = 1}^{\multconstr} a_i b_i (Y^i +
  Y^{-i}) - \p{k} (Y) = 0.
\end{align}

In \sonic{} we will use commitments to the following polynomials.
\begin{align*}
  \pr(X, Y) & = \sum_{i = 1}^{\multconstr} \left(a_i X^i Y^i + b_i X^{-i} Y^{-i}
              + c_i X^{-i - \multconstr} Y^{-i - \multconstr}\right) \\
  \p{s}(X, Y) & = \sum_{i = 1}^{\multconstr} \left( u_i (Y) X^{-i} +
                v_i(Y) X^i + w_i(Y) X^{i + \multconstr}\right)\\
  \pt(X, Y) & = \pr(X, 1) (\pr(X, Y) + \p{s}(X, Y)) - \p{k}(Y)\,.
\end{align*}

Polynomials $\p{r} (X, Y), \p{s} (X, Y), \p{t} (X, Y)$ are designed such that
$\p{t} (0, Y) = \vec{a}^\top \cdot \vec{\p{u}} (Y) + \vec{b}^\top \cdot
\vec{\p{v}} (Y) + \vec{c}^\top \cdot \vec{\p{w}} (Y) + \sum_{i =
  1}^{\multconstr} a_i b_i (Y^i + Y^{-i}) - \p{k} (Y) $. That is, the prover is
asked to show that $\p{t} (0, Y) = 0$, cf.~\cref{eq:sonic_constraint}.

Furthermore, the commitment system in $\sonic$ is designed such that it is
infeasible for a $\ppt$ algorithm to commit to a polynomial with non-zero
constant term.

\oursubsub{Algorithms rolled out}
\ourpar{$\sonic$ SRS generation $\kgen(\REL)$.} The SRS generating algorithm picks
randomly $\alpha, \chi \sample \FF_p$ and outputs
	\[
      \srs = \left( \gone{\smallset{\chi^i}_{i = -\dconst}^{\dconst},
          \smallset{\alpha \chi^i}_{i = -\dconst, i \neq 0}^{\dconst}},
        \gtwo{\smallset{\chi^i, \alpha \chi^i}_{i = - \dconst}^{\dconst}},
        \gtar{\alpha} \right)
	\]
\ourpar{$\sonic$ prover $\prover(\srs, \inp, \wit=\va, \vb, \vc)$.}
\begin{description}
\item[Round 1] The prover picks randomly randomisers
  $c_{\multconstr + 1}, c_{\multconstr + 2}, c_{\multconstr + 3}, c_{\multconstr
    + 4} \sample \FF_p$. Sets
  $\pr(X, Y) \gets \pr(X, Y) + \sum_{i = 1}^4 c_{\multconstr + i} X^{- 2
    \multconstr - i}$. Commits to $\pr(X, 1)$ and outputs
  $\gone{r} \gets \com(\srs, \multconstr, \pr(X, 1))$.  Then it gets challenge $y$ from
  the verifier.
\item[Round 2] $\prover$ commits to $\pt(X, y)$ and outputs
  $\gone{t} \gets \com(\srs, \dconst, \pt(X, y))$. Then it gets a challenge $z$ from
  the verifier.
\item[Round 3] The prover computes commitment openings. That is, it outputs
  \begin{align*}
    \gone{o_a} & = \open(\srs, z, \pr(z, 1), \pr(X, 1)) \\
    \gone{o_b} & = \open(\srs, yz, \pr(yz, 1), \pr(X, 1)) \\
    \gone{o_t} & = \open(\srs, z, \pt(z, y), \pt(X, y)) 
  \end{align*}
  along with evaluations $a' = \pr(z, 1), b' = \pr(y, z), t' = \pt(z, y)$.  Then it
  engages in the signature of correct computation playing the role of the
  helper, i.e.~it commits to $\p{s}(X, y)$ and sends the commitment $\gone{s}$, commitment opening
  \begin{align*}
    \gone{o_s} & = \open(\srs, z, \p{s}(z, y), \p{s}(X, y)), \\
  \end{align*} and $s'=\p{s}(z, y)$. 
%
  Then
  it obtains a challenge $u$ from the verifier.
\item[Round 4] In the next round the prover computes
  $\gone{c} \gets \com(\srs, \dconst, \p{s}(u, Y))$ and
  computes commitments' openings
  \begin{align*}
    \gone{w} & = \open(\srs, u, \p{s}(u, y), \p{s}(X, y)), \\
    \gone{q_y} & = \open(\srs, y,\p{s}(u, y), \p{s}(u, Y)),
  \end{align*}
  and returns $\gone{w}, \gone{q_y}, s = \p{s}(u, y)$. Eventually the prover gets the last challenge
  from the verifier---$z'$.
\item[Round 5] In the final round, $\prover$ computes opening
  $\gone{q_{z'}} = \open(\srs, z', \p{s}(u, z'), \p{s}(u, X))$ and outputs $\gone{q_{z'}}$.
\end{description}

\ourpar{$\sonic$ verifier $\verifier(\srs, \inp, \zkproof)$.} The verifier
in \sonic{} runs as subroutines the verifier for the polynomial commitment. That
is it sets $t' = a'(b' + s') - \p{k}(y)$ and checks the following:
\begin{equation*}
  \begin{split}
    &\PCOMs.\verifier(\srs, \multconstr, \gone{r}, z, a', \gone{o_a}), \\
    &\PCOMs.\verifier(\srs, \multconstr, \gone{r}, yz, b', \gone{o_b}),\\
    &\PCOMs.\verifier(\srs, \dconst, \gone{t}, z, t', \gone{o_t}),\\
    &\PCOMs.\verifier(\srs, \dconst, \gone{s}, z, s', \gone{o_s}),\\
  \end{split}
  \qquad
  \begin{split}
    &\PCOMs.\verifier(\srs, \dconst, \gone{s}, u, s, \gone{w}),\\
    &\PCOMs.\verifier(\srs, \dconst, \gone{c}, y, s, \gone{q_y}),\\
    &\PCOMs.\verifier(\srs, \dconst, \gone{c}, z', \p{s}(u, z'), \gone{q_{z'}}),
  \end{split}
\end{equation*}
and accepts the proof iff all the checks holds. Note that the value
$\p{s}(u, z')$ that is recomputed by the verifier uses separate challenges $u$
and $z'$. This enables the batching of many proof and outsourcing of this
part of the proof to an untrusted helper.

\subsection{Unique opening property of $\PCOMs$}
\begin{lemma}
\label{lem:pcoms_unique_op}
$\PCOMs$ has the unique opening property in the AGM. 
\end{lemma}
\begin{proof}
Let 
$z \in \FF_p$ be the attribute the polynomial is evaluated at,
$\gone{c} \in \GRP$ be the commitment,  
$s \in \FF_p$ the evaluation value, and 
$o \in \GRP$ be the commitment opening. 
We need to show that for every $\ppt$ adversary $\adv$ probability
\[
  \Pr \left[
    \begin{aligned}
      & \verify(\srs, \gone{c}, z, s, \gone{o}) = 1, \\
      & \verify(\srs, \gone{c}, z, \tilde{s}, \gone{\tilde{o}}) = 1
    \end{aligned}
    \,\left|\, \vphantom{\begin{aligned}
          & \verify(\srs, \gone{c}, z, s, \gone{o}),\\
          & \verify(\srs, \gone{c}, z, \tilde{s}, \gone{\tilde{o}}) \\
          &o \neq \tilde{o})
		\end{aligned}}
      \begin{aligned}
        & \srs \gets \kgen(\secparam, \maxdeg), \\
        & (\gone{c}, z, s, \tilde{s}, \gone{o}, \gone{\tilde{o}}) \gets \adv(\srs)
      \end{aligned}
    \right.\right]
  % \leq \negl.
\]
is at most negligible.

As noted in \cite[Lemma 2.2]{EPRINT:GabWilCio19} it is enough to upper bound the
probability of the adversary succeeding using the idealised verification
equation---which considers equality between polynomials---instead of the real
verification equation---which considers equality of the polynomials' evaluations.

For a polynomial $f$, its degree upper bound $\maxconst$, evaluation point $z$,
evaluation result $s$, and opening $\gone{o(X)}$ the idealised check verifies that
\begin{equation}
  \alpha (X^{\dconst - \maxconst}f(X) \cdot X^{-\dconst + \maxconst} -  s) \equiv \alpha \cdot o(X) (X - z)\,,
\end{equation}
what is equivalent to 
\begin{equation}
	f(X) -  s \equiv o(X) (X - z)\,.
	\label{eq:pcoms_idealised_check}
\end{equation}
Since $o(X)(X - z) \in \FF_p[X]$ then from the uniqueness of polynomial
composition, there is only one $o(X)$ that fulfils the equation above.
\qed
\end{proof}


\subsection{Unique response property}
The unique response property of $\sonicprot$ follows from the unique opening
property of the used polynomial commitment scheme $\PCOMs$.
\begin{lemma}
\label{lem:sonicprot_ur}
If a polynomial commitment scheme $\PCOMs$ is evaluation binding with
parameter $\epsbind(\secpar)$ and has unique openings property with parameter
$\epsop(\secpar)$, then $\sonicprot$ is $\ur{1}$ with parameter $\epsur(\secpar) \leq
\epsbind(\secpar) + \epsop(\secpar)$.  
\end{lemma}
\begin{proof}
  Let $\adv$ be an adversary that breaks $\ur{1}$-ness of $\sonicprot$.  We
  consider two cases, depending on which round $\adv$ is able to provide at
  least two different outputs such that the resulting transcripts are
  acceptable.  For the first case we show that $\adv$ can be used to break the
  evaluation binding property of $\PCOMs$, while for the second case we show
  that it can be used to break the unique opening property of $\PCOMs$.

  The proof goes similarly to the proof of \cref{lem:plonkprot_ur} thus we
  provide only draft of it here.  In each Round $i$, for $i > 1$, the prover
  either commits to some well-defined polynomials (deterministically), evaluates
  these on randomly picked points, or shows that the evaluations were performed
  correctly.  Obviously, for a committed polynomial $\p{p}$ evaluated at point
  $x$ only one value $y = \p{p}(x)$ is correct. If the adversary was able to
  provide two different values $y$ and $\tilde{y}$ that would be accepted as an
  evaluation of $\p{p}$ at $x$ then the $\PCOMs$'s evaluation binding would be
  broken.  Alternatively, if $\adv$ was able to provide two openings $\p{W}$ and
  $\p{\tilde{W}}$ for $y = \p{p}(x)$ then the unique opening property would be
  broken.
%
Hence the probability that $\adv$ breaks $\ur{1}$-property of $\PCOMs$ is
upper-bounded by $\epsbind(\secpar) + \epsop(\secpar)$. 
\qed

\end{proof}

\subsection{Forking soundness}
\begin{lemma}
	\label{lem:sonicprot_ss}
  $\sonicprot$ is $(\epsss(\secpar), 2, \multconstr + \linconstr + 1)$-forking sound against
  algebraic adversaries who can make up to $S$ simulation oracle queries, with
  \[
			\epss(\secpar) \leq \epsid(\secpar) + \epsldlog(\secpar) + 4 \cdot
      S \cdot \epsh(\secpar)\,,
	\]
	where $\epsid(\secpar)$ is a soundness error of the idealized verifier, $\epsldlog(\secpar)$ is
  security of $(\dconst, \dconst)$-$\ldlog$ assumption, and $\epsh (\secpar)$ is
  a security of hiding of the polynomial commitment scheme.
\end{lemma}
\begin{proof}
  Similarly as in the case of $\plonk$, the main idea of the proof is to show
  that an adversary who breaks forking soundness can be used to break hiding
  properties of the polynomial commitment scheme or a $\dlog$ problem
  instance. The proof goes by game hops. Let $\tree$ be the tree produced by
  $\tdv$ by rewinding $\adv$. Note that since the tree branches after Round 2,
  the instance $\inp$, commitments
  $\gone{\p{r} (\chi, 1), \p{r} (\chi, y), \p{s} (\chi, y), \p{t} (\chi, y)}$, and challenge
  $y$ are the same. The tree branches after the second round
  of the protocol where the challenge $z$ is presented, thus tree $\tree$ is
  build using different values of $z$.
%
  We consider the following games.

  \ncase{Game 0} In this game the adversary wins if all the transcripts it
  produced are acceptable by the ideal verifier,
  i.e.~$\vereq_{\inp, \zkproof}(X) = 0$, cf.~\cref{eq:ver_eq}, and none of
  commitments
  $\gone{\p{r} (\chi, 1), \p{r} (\chi, y), \p{s} (\chi, y), \p{t} (\chi, y)}$ use
    elements from a simulated proof, and the extractor fails to extract a valid
    witness out of the proof.

    \ncase{Probability that $\adv$ wins Game 0 is negligible} Probability of
    $\adv$ winning this game is $\epsid(\secpar)$ as the protocol $\sonicprot$,
    instantiated with the idealised verification equation, is perfectly
    knowledge sound except with negligible probability of the idealised verifier
    failure $\epsid(\secpar)$. Hence for a valid proof $\zkproof$ for a
    statement $\inp$ there exists a witness $\wit$, such that $\REL(\inp, \wit)$
    holds. Note that since the $\tdv$ produces $(\multconstr + \linconstr + 1)$
    acceptable transcripts for different challenges $z$. As noted in
    \cite{CCS:MBKM19} this assures that the correct witness is encoded in
    $\p{r} (X, Y)$. Hence $\extt$ can recreate polynomials' coefficients by
    interpolation and reveal the witness with probability $1$. Moreover, the
    probability that extraction fails in that case is upper-bounded by
    probability of an idealised verifier failing $\epsid(\secpar)$, which is
    negligible.

    \ncase{Game 1} In this game the adversary additionally wins if it produces a
    transcript in $\tree$ such that $\vereq_{\inp, \zkproof}(\chi) = 0$, but
    $\vereq_{\inp, \zkproof}(X) \neq 0$, and none of commitments
    $\gone{\p{r} (\chi, 1), \p{r} (\chi, y), \p{s} (\chi, y), \p{t} (\chi, y)}$
      use elements from a simulated proof.  The first condition means that the
      ideal verifier does not accept the proof, but the real verifier does.

      \ncase{Game 0 to Game 1} Assume the adversary wins in Game 1, but does not
      win in Game 0. We show that such adversary may be used to break an
      instance of a $\ldlog$ assumption. More precisely, let $\tdv$ be an
      algorithm that for relation $\REL$ and randomly picked
      $\srs \sample \kgen(\REL)$ produces a tree of acceptable transcripts such
      that the winning condition of the game holds. Let $\rdvdlog$ be a
      reduction that gets as input an
      $(\dconst, \dconst)$-ldlog instance
      $\gone{\chi^{-\dconst}, \ldots, \chi^{\dconst}}, \gtwo{\chi^{-\dconst},
        \ldots, \chi^{\dconst}}$ and is tasked to output $\chi$.

      The reduction $\rdvdlog$ proceeds as follows.
  \begin{enumerate}
  \item Build $\sonicprot$'s SRS $\srs$: pick a random $\alpha$ and compute
    $\gone{\alpha \chi^{- \dconst}, \ldots, \alpha \chi^{-1}, \alpha \chi,
      \ldots, \alpha \chi^{\dconst}}$,
    $\gtwo{\alpha \chi^{- \dconst}, \ldots, \alpha \chi^{-1}, \alpha \chi,
      \ldots, \alpha \chi^{\dconst}}$. Compose the SRS.
  \item Let $(1, \tree)$ be the output returned by $\tdv$. Let $\inp$ be a
    relation proven in $\tree$.  Consider a transcript $\zkproof \in \tree$ such
    that $\vereq_{\inp, \zkproof}(X) \neq 0$, but
    $\vereq_{\inp, \zkproof}(\chi) = 0$. Since $\adv$ is algebraic, all group
    elements included in $\tree$ are extended by their representation as a
    combination of the input $\GRP_1$-elements. Hence, all coefficients of the
    verification equation polynomial $\vereq_{\inp, \zkproof}(X)$ are known.
  \item Find $\vereq_{\inp, \zkproof}(X)$ zero points and find $\chi$ among
    them.
  \item Return $\chi$.
  \end{enumerate}
  Hence, the probability that the adversary wins Game 1 is upper-bounded by
  $\epsldlog(\secpar)$.

  \ncase{Game 2} In this game the adversary additionally wins if at least one of
  the commitments $\gone{\p{r} (\chi, 1), \p{r} (\chi, y), \p{s} (\chi, y)}$
  %$\gone{\chi^{-\alpha \dconst}, \ldots, \chi^{\alpha \dconst}} \setminus
 % \smallset{\gone{\chi^{\alpha}}}$
  utilizes a commitment that comes from a simulated proof; for example, $\adv$
  could compute its commitment to $\p{r} (X, 1)$ as follows: it picks a
  polynomial $\p{p} (X, Y)$, computes $\gone{\p{p} (\chi, 1)}$, and outputs
  commitment $\gone{\p{c} (\chi, 1)} = \gone{\p{p} (\chi, 1)} + c$, where $c$ is
  a commitment output by a simulator. In the following, w.l.o.g, we assume that
  $\adv$ uses some simulated element to compute commitment
  $\gone{\p{r} (\chi, 1)}$.

  \ncase{Game 1 to Game 2} Given adversary $\adv$ that wins in Game 2, but not
  in Game 1, we show a reduction $\rdv$ that uses $\adv$ and $\tdv$ to break
  hiding property of the commitment scheme. $\rdv$ proceeds as follows:
  \begin{enumerate}
  \item Given polynomial commitment SRS $\srs_{\PCOMs}$, produce $\sonic$'s SRS
    $\srs$ similarly to Game 1. 
  \item Pick random polynomials
    $\p{p} (X, Y), \p{p'} (X, Y) \in \FF^{< |\dconst|} (X)$, hiding parameter
    $k = 2$ and send them to the polynomial commitment challenger $\cdv$.
  \item From the challenger get the challenge commitment $c$.
  \item Let $S$ be the upper bound on the number of simulator oracles queries
    the adversary can make. 
  \item Guess which simulator's response is going to be used by $\adv$ in its
    proof. Let $s$ be the index of this response.
  \item Guess which of the simulated polynomials in response $s$ will be
    used. Let $i$ be the index of this polynomial.
  \item Let $\tdv'$ be an algorithm that behaves exactly as $\tdv$, except when
    $\adv$ asks for $s$-th simulated proof, $\tdv'$'s internal procedure $\bdv'$
    provides $\adv$ with a simulated proof such that instead of commitment
    $\p{r} (\chi, 1)$ it gives $c$. 
  \item Start $\tdv'(\adv, \srs)$ and get the tree $\tree$.
  % \item If indices $s$ or $i$ have not been guessed correctly, rewind $\adv$ to
  %   the beginning and pick new $s$ and $i$. Since $S = \poly$ probability that
  %   the correct $s$ will be guessed in polynomial time is overwhelming. That is,
  %   the reduction works in expected polynomial time. Similarly, $i$ takes values
  %   from $\range{1}{3}$, hence probability that $\rdv$ guesses $i$ in polynomial
  %   time is overwhelming. 
  \item Since $\tree$ contains $(\multconstr + \linconstr + 1)$ evaluations of
    $\p{t} (X, y)$, the polynomial can be reconstructed.
  \item Since $\adv$ is algebraic, $\rdv$ learns composition of $\p{t} (X, y)$
    in the $\srs$ and simulated elements.
  \item Hence $\rdv$ learns whether $c$ is a commitment to $\p{p} (X, 1)$ or
    $\p{p'} (X, 1)$.
  \item $\rdv$ returns its guessing bit to $\cdv$.
  \end{enumerate}

  \ncase{Game 3} In this game the adversary additionally wins if the commitment
  $\p{t} (\chi, y)$ comes from a simulated proof.

  \ncase{Game 2 to Game 3} Given adversary $\adv$ that wins in Game 3, but not
  in Game 2, we show a reduction $\rdv$ that uses $\adv$ and $\tdv$ to break
  hiding property of the commitment scheme. $\rdv$ proceeds as follows:
  \begin{enumerate}
  \item Guess the simulation query index $s$ the polynomial(s) come from.
  \item Pick random $y, z$ and compute polynomial $\p{t} (X, Y)$ as a simulator
    would compute.
  \item Produce two random polynomials $\p{p_0} (X, y)$ and $\p{p_1} (X, y)$ and
    send them to the challenger $\cdv$. Get commitment $c$.
  \item Let $\tdv'$ be an algorithm that behaves exactly as $\tdv$, except when
    $\adv$ asks for $s$-th simulated proof, $\tdv'$'s internal procedure $\bdv'$
    provides $\adv$ with a simulated proof such that:
    \begin{enumerate}
    \item Start making the simulated proof as a trapdoor-less simulator would.
    \item Before $\gone{\p{t} (z , y)}$ is computed
      get evaluation $p_z = \p{p_b} (z, y)$, i.e.~evaluate the polynomial in
      $c$ at $z$. 
    \item Let $\tilde{t}$ be the evaluation of the simulated $\p{t} (z, y)$.
    \item Pick $r$ such that $p_z + r = \p{t} (z, y)$.
    \item For the commitment of $\p{t} (X, y)$ output $c' = c + \gone{r}$.
    \item Compute the rest of the simulated proof as a simulator would.
    \end{enumerate}
  \item Let $\tdv'$ be an algorithm that behaves exactly as $\tdv$, except when
    $\adv$ asks for $s$-th simulated proof, $\tdv'$'s internal procedure $\bdv'$
    provides $\adv$ with a simulated proof such that instead of a simulated
    $\gone{\p{t} (\chi, y)}$ it gives $c'$.
  \item Start $\tdv'(\adv, \srs)$ and get the tree $\tree$.
  % \item If index $s$ has not been guessed correctly, rewind $\adv$ to
  %   the beginning and pick new $s$. Since $S = \poly$ probability that
  %   the correct $s$ will be guessed in polynomial time is overwhelming. That is,
  %   the reduction works in expected polynomial time. 
  \item Since $\tree$ contains $\multconstr + \linconstr + 1$ evaluations of
    $\p{t} (X, y)$, the polynomial can be reconstructed.
  \item Since $\adv$ is algebraic, $\rdv$ learns composition of $\p{t} (X, y)$ in
    the $\srs$ and simulated elements. 
  \item Hence $\rdv$ learns whether $c$ is a commitment to $\p{p} (X, y)$ or
    $\p{p'} (X, y)$.
  \item $\rdv$ returns its guessing bit to $\cdv$.
  \end{enumerate}
 \end{proof}

\subsection{Honest verifier zero-knowledge}
\begin{lemma}
\label{lem:sonic_hvzk}
$\sonic$ is honest verifier zero-knowledge.
\end{lemma}
\begin{proof}
  The simulator proceeds as follows.
  \begin{enumerate}
  \item Pick randomly vectors $\vec{a}$, $\vec{b}$ and set
    \begin{equation}
      \label{eq:ab_eq_c}
      \vec{c} = \vec{a} \cdot \vec{b}. 
    \end{equation}
  \item Pick randomisers $c_{\multconstr + 1}, \ldots, c_{\multconstr + 4}$,
    honestly compute polynomials $\p{r}(X, Y), \p{r'}(X, Y), \p{s}(X, Y)$ and
    pick randomly challenges $y$, $z$.
  \item Output commitment $\gone{r} \gets \com(\srs, \multconstr, \p{r} (X,
    1))$ and challenge $y$. 
  \item Compute
    \begin{align*}
      & a' = \p{r}(z, 1),\\
      & b' = \p{r}(z, y),\\
      & s' = \p{s}(z, y).
    \end{align*} 
  \item Pick polynomial $\p{t}(X, Y)$ such that
    \begin{align*}
      & \p{t} (X, y) = \p{r} (X, 1) (\p{r}(X, y) + \p{s} (X, y)) - \p{k} (Y)\\
      & \p{t} (0, y) = 0
    \end{align*}
  \item Output commitment $\gone{t} = \com (\srs, \dconst, \p{t} (X, y))$ and
    challenge $z$.
  \item Continue following the protocol.
  \end{enumerate}

  We note that the simulation is perfect. This comes since, except polynomial
  $\p{t} (X, Y)$ all polynomials are computed following the protocol. For
  polynomial $\p{t} (X, Y)$ we observe that in a case of both real and simulated
  proof the verifier only learns commitment $\gone{t} = \p{t} (\chi, y)$ and
  evaluation $t' = \p{t} (z, y)$. Since the simulator picks $\p{t} (X, Y)$ such
  that 
  \begin{align*}
      \p{t} (X, y) = \p{r} (X, 1) (\p{r}(X, y) + \p{s} (X, y)) - \p{k} (Y)
  \end{align*}
  Values of $\gone{t}$ are equal in both proofs.
  Furthermore, the simulator picks its polynomial such that $\p{t}(0, y) = 0$,
  hence it does not need the trapdoor to commit to it. (Note that the proof
  system's SRS does not allow to commit to polynomials which have non-zero
  constant term). \qed
\end{proof}
\begin{remark} 
  As noted in \cite{CCS:MBKM19}, $\sonic$ is statistically subversion-zero
  knowledge (Sub-ZK). As noted in \cite{AC:ABLZ17}, one way to achieve
  subversion zero knowledge is to utilise an extractor that extracts a SRS
  trapdoor from a SRS-generator. Unfortunately, a NIZK made subversion
  zero-knowledge by this approach cannot achieve perfect Sub-ZK as one has to
  count in the probability of extraction failure. However, with the simulation
  presented in \cref{lem:sonic_hvzk}, the trapdoor is not required for the
  simulator as it is able to simulate the execution of the protocol just by
  picking appropriate (honest) verifier's challenges. This result transfers to
  $\sonicprotfs$, where the simulator can program the random oracle to provide
  challenges that fits it.
\end{remark}

\subsection{From forking soundness and unique response property to forking
  simulation extractability of $\sonicprotfs$}
Since \cref{lem:sonicprot_ur,lem:sonicprot_ss} hold, $\sonicprot$ is $\ur{1}$
and forking sound. We now make use
of \cref{thm:se} and show that $\sonicprotfs$ is forking simulation-extractable as defined in \cref{def:simext}.

\begin{corollary}[Forking simulation extractability of $\sonicprotfs$]
  \label{thm:sonicprotfs_se}
  Assume that $\sonicprot$ is $\ur{1}$ with security
  $\epsur(\secpar) = \epsbind(\secpar) + \epsop(\secpar)$ -- where
  $\epsbind (\secpar)$ is polynomial commitment's binding security, $\epsop$ is
  polynomial commitment unique opening security -- and forking-sound with
  security $\epsss(\secpar)$. Let $\ro\colon \bin^* \to \bin^\secpar$ be a
  random oracle. Let $\advse$ be an algebraic adversary that can make up to $q$
  random oracle queries, up to $S$ simulation oracle queries, and outputs an
  acceptable proof for $\sonicprotfs$ with probability at least $\accProb$. Then
  $\sonicprotfs$ is forking simulation-extractable with extraction error
  $\eta = \epsur(\secpar)$. The extraction probability $\extProb$ is at least
\[
		\extProb  \geq \frac{1}{q^{\multconstr + \linconstr}} (\accProb - \epsur(\secpar))^{\multconstr +
		\linconstr + 1} - \eps(\secpar).
	\]
	for some negligible $\eps(\secpar)$, $\multconstr$ and $\linconstr$ being,
  respectively, the number of multiplicative and linear constrains of the system.
\end{corollary}
