\section{Concrete SNARKs Preliminaries}

\ourpar{Bilinear groups.}
A bilinear group generator $\pgen (\secparam)$ returns public parameters $ \pp =
(p, \GRP_1, \GRP_2, \GRP_T, \pair, \gone{1}, \gtwo{1})$, where $\GRP_1$,
$\GRP_2$, and $\GRP_T$ are additive cyclic groups of prime order $p = 2^{\Omega
  (\secpar)}$, $\gone{1}, \gtwo{1}$ are generators of $\GRP_1$, $\GRP_2$, resp.,
and $\pair: \GRP_1 \times \GRP_2 \to \GRP_T$ is a non-degenerate
$\ppt$-computable bilinear pairing. We assume the bilinear pairing to be Type-3,
i.e., that there is no efficient isomorphism from $\GRP_1$ to $\GRP_2$ or from
$\GRP_2$ to $\GRP_1$. We use the by now standard bracket notation, i.e., we
write $\bmap{a}{\gi}$ to denote $a g_{\gi}$ where $g_{\gi}$ is a fixed generator
of $\GRP_{\gi}$. We denote $\pair (\gone{a}, \gtwo{b})$ as $\gone{a} \bullet
\gtwo{b}$. Thus, $\gone{a} \bullet \gtwo{b} = \gtar{a b}$. We freely use the
bracket notation with matrices, e.g., if $\vec{A} \vec{B} = \vec{C}$ then
$\vec{A} \grpgi{\vec{B}} = \grpgi{\vec{C}}$ and $\gone{\vec{A}}\bullet
\gtwo{\vec{B}} = \gtar{\vec{C}}$. Since every algorithm $\adv$ takes as input
the public parameters we skip them when describing $\adv$'s input. Similarly, we
do not explicitly state that each protocol starts with generating these
parameters by $\pgen$.

\subsection{Algebraic Group Model}
The algebraic group model (AGM) introduced in \cite{C:FucKilLos18} lies between the
standard model and generic bilinear group model. In the AGM it is assumed that an
adversary $\adv$ can output a group element $\gnone{y} \in \GRP$ if $\gnone{y}$ has
been computed by applying group operations to group elements given to $\adv$ as
input. It is further assumed, that $\adv$ knows how to ``build'' $\gnone{y}$ from
those elements. More precisely, the AGM requires that whenever $\adv(\gnone{\vec{x}})$
outputs a group element $\gnone{y}$ then it also outputs $\vec{c}$ such that
$\gnone{y} = \vec{c}^\top \cdot \gnone{\vec{x}}$. $\plonk$, $\sonic$ and $\marlin$
have been shown secure using the AGM. An adversary that works in the AGM is called
\emph{algebraic}.

\oursubsub{Idealised Verifier and Verification Equations.} Let
$(\SRScer, \prover, \verifier, \simulator)$ be a proof system.
% or a polynomial commitment
% scheme\hamid{might be unclear as we are defining polynomial commitments as
%   $(\kgen, \com, \open, \verify)$.}.
Observe that the $\SRScer$ algorithms provide an SRS which can be interpreted as a set
of group representation of polynomials evaluated at trapdoor elements. That is, for a
trapdoor $\chi$ the SRS contains $\gone{\p{p_1}(\chi), \ldots, \p{p_k}(\chi)}$, for
some polynomials $\p{p_1}(X), \ldots, \p{p_k}(X) \in \FF_p[X]$. The verifier
$\verifier$ accepts a proof $\zkproof$ for instance $\inp$ if (a set of) verification
equation $\vereq_{\inp, \zkproof}$ (which can also be interpreted as a polynomial in
$\FF_p[X]$ whose coefficients depend on messages sent by the prover) zeroes at
$\chi$. Following \cite{EPRINT:GabWilCio19} we call verifiers who check that
$\vereq_{\inp, \zkproof}(\chi) = 0$ \emph{real verifiers} as opposed to \emph{ideal
  verifiers} who accept only when $\vereq_{\inp, \zkproof}(X) = 0$. That is, while a
real verifier accepts when a polynomial \emph{evaluates} to zero, an ideal verifier
accepts only when the polynomial \emph{is} zero.

Although ideal verifiers are impractical, they are very useful in our
proofs. More precisely, we show that
\begin{compactenum}
\item the idealised verifier accepts an incorrect proof (what ``incorrect''
  means depends on the situation) with at most negligible probability (and in many
  cases---never);
\item when the real verifier accepts, but not the idealised one, then a malicious
  prover can be used to break the underlying security assumption (in our case---a
  variant of $\dlog$.)
\end{compactenum}

Analogously, idealised verifier can be defined for polynomial commitment schemes.

\subsection{Dlog Assumptions in Standard and Updatable Setting}
\label{dlog-upd}
\label{sec:udlog_assumptions}


\label{sec:dlog_assumptions}
\begin{definition}[$(q_1, q_2)\mhyph\dlog$ assumption]\label{def:dlog}
	Let $\adv$ be a $\ppt$ adversary that gets as input
  $\gone{1, \chi, \ldots, \chi^{q_1}}, \gtwo{1, \chi, \ldots, \chi^{q_2}}$, for
  some randomly picked $\chi \in \FF_p$, the assumption requires that $\adv$ cannot compute $\chi$. That is
	\[
		\condprob{\chi = \adv(\gone{1, \chi, \ldots, \chi^{q_1}}, \gtwo{1, \chi,
        \ldots, \chi^{q_2} })}{\chi \sample \FF_p} \leq \negl.
	\]
\end{definition}

 Since all our protocols and security notions are in the updatable setting, it is natural to define the dlog assumptions also in the updatable setting. That is, instead of being given a dlog challenge the adversary $\adv$ is given access to an update oracle as defined in~\cref{fig:upd}. The honestly generated SRS is set to be a dlog challenge and the update algorithm $\upd$ re-randomizing the challenge. We define this assumptions and show a reduction between the assumptions in the updatable and standard setting. 

Note that for clarity we here refer to the SRS by $\Ch$. Further, to avoid cluttering notation, we do not make the update proofs explicit. They are generated in the same manner as the proofs in~\cref{fig:upd-scheme}.
	
%The reduction $\reduction$ proceeds as follows: given the input dlog instance, $\reduction$ answers adversary's queries for the dlog updates and sets the honest update to be the input dlog instance. Once the dlog challenge in the updatable setting is finalized, it runs the adversary and obtains the answer $\chi'$. Let $\chi_1, \ldots, \chi_\ell$ be the partial discrete logarithms of dlog instances corresponding to the adversary's dlog updates. These values can be computed by $\reduction$ by extracting from the update proofs given by the adversary. $\reduction$ now returns  $\chi = \chi' (\chi_1 \chi_2 \ldots \chi_\ell)^{-1}$. The same argument holds for the $(q_1, q_2)\mhyph\ldlog$ assumption, ~\cref{def:ldlog}.

\begin{definition}[$(q_1, q_2)\mhyph\udlog$ assumption]\label{def:udlog}
	Let $\adv$ be a $\ppt$ adversary that gets oracle access to $\initU$ with internal algorithms $(\kgen, \upd, \verifyCRS)$, where $\kgen$ and $\upd$ are defined as follows:
	\begin{itemize}
	\item $\kgen(\secpar)$ samples $\chi \sample \FF_p$ and defines 
		$\Ch:=(\gone{1, \chi, \ldots,
			\chi^{q_1}}, \gtwo{1, \chi, \ldots, \chi^{q_2}
		})$.
	\item $\upd(\Ch, \{\rho_j \}_{j=1}^n)$ 
	parses $\Ch$ as $\left( \gone{\smallset{A_i}_{i = 0}^{q_1}},
	\gtwo{\smallset{B_i}_{i = 0}^{q_2}} \right)$, samples
	$\widetilde{\chi} \sample \FF_p$, and defines
	$\widetilde{\Ch} := 
	\left( \gone{\smallset{\widetilde{\chi}^i A_i}_{i = 0}^{q_1}},
	\gtwo{\smallset{\widetilde{\chi}^i B_i}_{i = 0}^{q_2}} \right)$.
	\end{itemize}
	Then
	\[
	\prob{\bar{\chi} \gets \adv^{\initU}(\secpar)} \leq \negl,
	\]
	where $\left( \gone{\smallset{\bar{\chi}^i}_{i = 0}^{q_1}},
	\gtwo{\smallset{\bar{\chi}^i}_{i = 0}^{q_2}} \right)$ is the finalized challenge.
\end{definition}



\begin{remark}[Single adversarial updates after an honest setup.]\label{rem:upd}
	One can consider a slightly different model of setup, where the adversary is given an initial honestly-generated SRS and is then allowed to perform a malicious update in one-shot fashion.
	Groth
	et al.\ show in~\cite{C:GKMMM18} that the two definitions are equivalent for polynomial commitment based SNARKs. We use this simpler definition in our reductions.
\end{remark}


We show a reduction from $(q_1, q_2)\mhyph\dlog$ assumption to its variant in the updatable setting (with single adversarial update). 
%We omit showing the reduction $(q_1, q_2)\mhyph\ldlog \Rightarrow (q_1, q_2)\mhyph\uldlog$ as it can be done similarly in a straightforward manner.
\begin{lemma}
	$(q_1, q_2)\mhyph\dlog \Rightarrow (q_1, q_2)\mhyph\udlog$.
	\end{lemma}
\begin{proof}
	We construct a reduction algorithm $\reduction$ which uses an adversary $\adv$ on the $(q_1, q_2)\mhyph\udlog$ and construct an adversary on the $(q_1, q_2)\mhyph\dlog$. Specifically, $\reduction$ proceeds as follows: given a dlog instance $\Ch$ as input, it sets $\Ch$ as the initial (honestly generated) challenge. Once the dlog challenge in the updatable setting is finalized, it runs $\adv$ and obtains the answer $\chi'$. Let $\chi_\adv$ be the (possibly) partial discrete logarithm of the dlog instance corresponding to the adversary's update. This value can be computed by $\reduction$ by extracting from the update proof given by $\adv$. $\reduction$ now returns $\chi = \chi' \chi_\adv^{-1}$ as the discrete logarithm of $\Ch$.
	\end{proof}

  \oursubsub{Generalized Forking Lemma}
Although dubbed ``general'', the forking lemma of~\cite{CCS:BelNev06} is not general enough for our purpose as it is useful only for protocols where a witness can be extracted from just two transcripts. To be able to extract a witness from, say, an execution of $\plonkprot$ we need at least $(3 \numberofconstrains + 1)$ valid proofs (where $\numberofconstrains$ is the number of constrains), $(\numberofconstrains+ 1)$ for $\sonicprot$, and $\numberofconstrains + 4$ for $\marlinprot$. Here we use a result by Attema et
al.~\cite{EPRINT:AttFehKlo21}\footnote{An earlier versions had its own forking lemma generalization. Attema et al.\ has a better bound.}  which lower-bounds the probability of generating a tree of accepting transcripts $\tree$.

  \begin{lemma}[Proposition 2~\cite{EPRINT:AttFehKlo21}]\label{lem:attema}
	Let $N = n_1 \cdot \cdots \cdot n_\mu$ and $p = 2^{\Omega(\secpar)}$. Let $\epserr(\secpar) = 1 - \prod_{i=1}^{\mu}\left(1 - \frac{n_i - 1}{p}\right)$.
	Assume adversary $\adv$ that makes up to $q$ random
	oracle queries and outputs an acceptable proof with probability at least
	$\accProb$. There exists a tree building algorithm $\tdv$ for $(n_1, \ldots, n_\mu)$-trees that utilizes the extractor $\zdv_1$ in~\cref{fig:Attema-ext} and succeeds in building a
	tree of accepting transcripts in expected
	running time $N + q (N - 1)$ with probability at least
	\[
	\frac{\accProb - (q + 1) \epserr (\secpar)}{1 - \epserr (\secpar)}.
	\]
	\end{lemma}

\begin{figure}[t]
	\centering
	\fbox{\parbox{\textwidth}{
			\begin{enumerate}
				\item Run $\zdv_{m + 1}$ as follows to obtain $(\vec{\zkproof}, \tzkproof_1, v)$: relay the $q + \mu$ queries to the random oracle and record all query-response pairs. Set 				$h \gets \zkproof[m].\ch $, and let $c_h$ be the response to query $i$. 
				\item If $v = 0$, abort with output $v = 0$. 
				\item Else, repeat
				\begin{itemize}
					\item sample $c'_h \in C \setminus \smallset{c_h}$ (without replacement);
					\item run $\zdv_{m + 1}$ as follows to obtain $(\vec{\zkproof'}, \tzkproof', v')$, aborting right after the initial run of $\adv$ if $\zkproof'[m].\ch  \neq \zkproof[m].\ch$: answer the query to $h$ with $c'_h$, while answering all other queries consistently if the query was performed by $\zdv_{m + 1}$ already on a previous run and with a fresh random value in $C$ otherwise; 
				\end{itemize}
				until either $n_m - 1$ additional challenges $c'_h$ with $v' = 1$ and $\zkproof'[m].\ch  = \zkproof[m]$ have been found or until all challenges $c'_h \in C$ have been tried. 
				\item In the former case, output $\vec{\zkproof}$, the $n_m$ accepting
				$(1, \ldots, 1, n_{m + 1}, \ldots, n_\mu)$-trees $\tzkproof_1, \ldots, \tzkproof_{n_m}$, and
				$v \gets 1$; in the latter case, output $v \gets 0$.
			\end{enumerate}
	}}
	\caption{Extractor $\zdv_m$ from Attema et al.~\cite{EPRINT:AttFehKlo21}. Here $\vec{\zkproof}$ is an index vector that contains all random oracle queries made by the prover for the output proof; that is, for prover's messages $\vec{a} = a_1, \ldots, a_{\mu + 1}$, $\zkproof[1].\ch = (\inp, a_1), \ldots, \zkproof[{\mu}].\ch = (\inp, a_1, \ldots, a_\mu)$.  $\tzkproof$ is a proof transcript that contains both prover's messages and random oracle responses, that is $\tzkproof = (a_1, (\inp, a_1), a_2, (\inp, a_1, a_2), \ldots)$. Finally, $v$ is the verification bit, that is $v = \verifier (\srs, \inp, \tzkproof)$. }
	\label{fig:Attema-ext}
\end{figure} 


\subsection{Opening Uniqueness of Batched Polynomial Commitment Openings}

%We say that $\PCOM$ has the unique opening property if the following holds:
To show the unique response property required by our main theorem we show that the polynomial
commitment schemes employed by concrete proof systems have unique openings in the following sense:
\begin{description}
\item[Opening uniqueness:] Intuitively, opening uniqueness assures that there is only one
  valid opening for the committed polynomial and given evaluation point. This property is
  crucial in showing \COMMENT{forking }simulation-extractability of $\plonk$, $\sonic$ and
  $\marlin$.
  Let $k \in \NN$ be the number of committed polynomials, $l \in \NN$ number of evaluation
  points, $\vec{c} \in \GRP^k$ be the commitments, $\vec{z} \in \FF_p^l$ be the arguments
  the polynomials are evaluated at, $\vec{s} \in \FF_p^k$ the evaluations, and
  $\vec{o}, \vec{o}' \in \FF_p^l$ be the commitment openings. Then for every $\ppt$ adversary $\adv$
	\[
		\condprob{
			\begin{matrix}
				  \verify(\srs, \vec{c}, \vec{z}, \vec{s}, \vec{o}) = 1,  \\ 
				  \verify(\srs, \vec{c}, \vec{z}, \vec{s}, \vec{o'}) = 1, \\
				 \vec{o} \neq \vec{o'}
			\end{matrix}
		}{
			\begin{matrix}
%				& \srs \gets \kgen(\secparam, \maxdeg),\\
				  (\vec{c}, \vec{z}, \vec{s}, \vec{o}, \vec{o'}) \gets \adv^{\initU}(\maxdeg)
			\end{matrix}
		}\leq \negl\,.
	\]
\end{description}
We show
that $\plonk$'s, $\sonic$'s, and $\marlin$'s polynomial commitment schemes satisfy this
requirement in \cref{lem:pcomp_op} and \cref{lem:pcoms_unique_op}
respectively.





\cref{fig:pcomp,fig:pcoms} present variants of KZG~\cite{AC:KatZavGol10} polynomial
commitment schemes used in \plonk{}, \sonic{} and \marlin{}. 
To support batched verification, the inputs to $\com$, $\open$, $\verify$ are vectors, and the algorithms take an additional arbitrary auxiliary string as input. This adversarially chosen string only provides additional context for the computation of challenges. We treat auxiliary input implicitly in the definition.

%
% The key generation algorithm
% $\kgen$ takes as input a security parameter $\secparam$ and a parameter $\maxdeg$ which
% determines the maximal degree of the committed polynomial. 
% We assume that $\maxdeg$ can be
% read from the output SRS. While the figures only describe trusted SRS setup, it is not
% hard to lift the SRS generation into the updatable setting by defining the extra
% algorithms $\upd$, $\verifyCRS$ (see~\cref{def:upd-scheme}) as described in~\cref{fig:upd-scheme}.  

\markulf{30.04}{Is the following important here? Move to where we define or use commitments of knowledge.}
\cite{CCS:MBKM19}
shows, using AGM, that $\PCOMs$ is a commitment of knowledge.  
The same reasoning could be
used to show that property for $\PCOMp$.
 



\hspace*{-3cm}\begin{figure}[t!]
	\centering
	% \small
	\centerline{\fbox{
		\begin{minipage}[t]{1.25\linewidth}
		\begin{pcvstack}
		\begin{pchstack}
			\procedure{$\kgen(\REL)$}{
				\chi \sample \FF_p \\ [\myskip]
				\srs := 
				\left( \gone{\smallset{\chi^i}_{i = 0}^{\dconst}},
				\gtwo{\chi} \right); 
				\rho =  \left(\gone{\chi, \chi}, \gtwo{\chi}\right) \\ [\myskip]
				\pcreturn (\srs, \rho) \\ [\myskip]
			}
		%
		\pchspace
		% 
		\procedure{$\upd(\srs, \{\rho_j \}_{j=1}^n)$}{
			\text{Parse } \srs \text{ as } \left( \gone{\smallset{A_i}_{i = 0}^{\dconst}},
			\gtwo{B} \right) \\ [\myskip]
			\chi' \sample \FF_p  \\ [\myskip]
			\srs' := 
			\left( \gone{\smallset{{\chi'}^i A_i}_{i = 0}^{\dconst}},
			\gtwo{\chi' B} \right); 
			\rho' =	\left( \gone{\chi' A_1, \chi'}, \gtwo{\chi'}\right) \\ [\myskip]
			\pcreturn (\srs', \rho')
		}
		\end{pchstack}
		\pcvspace
		\begin{pchstack}
		%
		\procedure{$\verifyCRS(\srs, \{\rho_j \}_{j=1}^n)$}{
			\text{Parse }  \srs \text{ as } \left( \gone{\smallset{A_i}_{i = 0}^{\dconst}},
			\gtwo{B} \right) \text{and } \{\rho_j \}_{j=1}^n \text{ as } \left\{\left( P_j, \bP_j, \hP_j \right)\right\}_{j=1}^n \\ [\myskip]
			\text{Verify Update proofs: } \\ [\myskip]
			\t \bP_1 = P_1 \\ [\myskip]
			\t P_j \bullet \gtwo{1} = P_{j-1} \bullet \hP_j \quad \forall j \geq 2 \\ [\myskip]
			\t \bP_n \bullet \gtwo{1} = \gone{1} \bullet \hP_n \\ [\myskip]
			\text{Verify SRS structure: } \\ [\myskip]
			\t \gone{A_i} \bullet \gtwo{1} = \gone{A_{i-1}} \bullet \gtwo{B} \text{ for all } 0 < i \leq \dconst %\\ [\myskip]
		}
		%
		\end{pchstack}
		\end{pcvstack}
		%
		\end{minipage}}}
	\caption{Updatable SRS scheme for $\PCOMp$} 
	\label{fig:upd-scheme}
\end{figure}


\begin{figure}
  \small
  \centerline{\fbox{
\begin{minipage}{14.3cm}
\begin{pcvstack}[]
  \begin{pchstack}
			\procedure{$\kgen(\secparam, \maxdeg)$}
			{
			\chi \sample \FF_p \\ [\myskip]
			\pcreturn \srs = \gone{1, \ldots, \chi^{\maxdeg}}, \gtwo{\chi}\\ [\myskip]
      }\\
      
			
			\pchspace
			
			\procedure{$\com(\srs, \vec{\p{f}}(X))$}
			{ 
				\pcreturn \gone{\vec{c}} = \gone{\vec{\p{f}}(\chi)}\\ [\myskip]
        \fbox{$\pcreturn \vec{\p{f}} (X)$}\\
			}

      \pchspace

      \procedure{$\open(\srs, \vec{z}, \vec{s}, \vec{\p{f}}(X), \aux_0)$}
			{
      \vec{\gamma} \gets \ro (g_0( \vec{z}, \vec{s}, \gone{\vec{c}}, \aux_0))\\[\myskip]
			\pcfor i \in \range{1}{\abs{\vec{z}}} \pcdo\\ [\myskip]
      \pcind \p{o}_j(X) \gets \sum_{i \in K_j} \gamma_{j}^{i - 1}
      \frac{\p{f}_{i}(X) - \p{f}_{i}(z_j)}{X - z_j}\\ [\myskip] 
      \pcreturn \vec{o} = \gone{\vec{\p{o}}(\chi)}\\ [\myskip]
      \fbox{$\pcreturn \vec{\p{o}} (X)$}
				% \hphantom{\hspace*{5.5cm}}	
			}

    \end{pchstack}
		 \pcvspace
    
		\begin{pchstack}
			\procedure{$\verifyb(\srs, \gone{\vec{c}}, \vec{z}, \vec{s}, \gone{\p{o}(\chi)}, (\aux_0,\aux_1))$}
			{
        \vec{\gamma} \gets \ro (g_0( \vec{z}, \vec{s}, \gone{\vec{c}}, \aux_0))\\[\myskip]
				r \gets \ro (g_1(\gone{\vec{c}}, \vec{z}, \vec{s}, \gone{\p{o}(\chi)}, \aux_1))\\ [\myskip]
				% \pcfor j \in \range{1}{\abs{\vec{z}}} \pcdo \\ [\myskip]
				(*) \pcif 
          \sum_{j = 1}^{\abs{\vec{z}}} r^{j} \cdot \gone{\sum_{i \in K_j}
          \gamma_j^{i - 1} c_{i} - \sum_{i \in K_j} \gamma_j^{i - 1} s_{i_j}} \bullet \gtwo{1} + \\ [\myskip] 
          \pcind \sum_{j = 1}^{\abs{\vec{z}}} r^{j} z_j o_j
          \bullet \gtwo{1} \neq \gone{\sum_{j = 1}^{\abs{\vec{z}}} r^{j} o_j }
          \bullet \gtwo{\chi} \pcthen  \\
					\pcind \pcreturn 0\\ [\myskip]
          \fbox{
            \begin{minipage}{7cm}
            (**) $\pcif $
              $\sum_{j = 1}^{\abs{\vec{z}}} r^j \cdot (\sum_{i \in K_j}
              \gamma_j^{i - 1} \p{f}_{i} (X) - \sum_{i \in K_j} \gamma_j^{i - 1} s_{i_j}) + $\\ [\myskip] 
              $\pcind \sum_{j = 1}^{\abs{\vec{z}}} r^{j} z_j \p{o}_j (X)
               \neq \sum_{j = 1}^{\abs{\vec{z}}} r^{j} \p{o}_j (X)
              \cdot X \pcthen $ \\
              $\pcind \pcreturn 0$
            \end{minipage}
          }\\[\myskip]
					\pcreturn 1.\\
			}

      \pchspace
      
      \procedure{$\verify(\srs, \gone{\vec{c}}, \vec{z}, \vec{s}, \gone{\p{o}(\chi)},\aux_0)$}
			{
        \vec{\gamma} \gets \ro (g_0( \vec{z}, \vec{s}, \gone{\vec{c}}, \aux_0))\\[\myskip]
				\pcfor j \in \range{1}{\abs{\vec{z}}} \pcdo \\ [\myskip]
				\pcind \pcif 
          \gone{\sum_{i \in K_j}
          \gamma_j^{i - 1} c_{i} - \sum_{i \in K_j} \gamma_j^{i - i} s_{i, j}} \bullet
          \gtwo{1} + \\ [\myskip] \pcind  z_j
          o_j
          \bullet \gtwo{1} \neq \gone{o_j}
          \bullet \gtwo{\chi} \pcthen  \\
					\pcind \pcreturn 0\\ [\myskip]
        \fbox{
          \begin{minipage}{6cm}
          $\pcind \pcif $
          $\sum_{i \in K_j} \gamma_j^{i - 1} \p{f}_{i} (X) - \sum_{i \in K_j} \gamma_j^{i - i} s_{i, j} + $\\ [\myskip] 
          $\pcind  z_j \p{o}_j (X) \neq \p{o}_j (X) X \pcthen \pcreturn 0$
        \end{minipage}
        }\\ [\myskip]
					\pcreturn 1.
			}
    \end{pchstack}
	\end{pcvstack}
\end{minipage}
  }}
	\caption{$\PCOMp$ polynomial commitment scheme. Here $\abs{\vec{z}} = l$ is the number of evaluation points, the number of committed polynomials is $m$, $K_j$ is the set of polynomials that was evaluated at point $z_j$. Functions $g_0$ and $g_1$ are injective and specific to the context in which the polynomial commitment is used. (In our case, functions $g_0$ and $g_1$ are produce partial transcripts of the proof that utilizes the commitment scheme, $\aux$ contains all additional information that is needed by the functions.)
  In the boxes we describe values returned or equality computed in the ideal protocol where the verifier checks equalities on the polynomials instead of their evaluations. For algorithm $\pcalgostyle{Alg}$ we denote its ideal variant by $\pcalgostyle{Alg}'$.
  \michals{29.04}{adjust to $\initU$} \markulf{30.04}{Why not just refer to Fig.5?}
  }
	\label{fig:pcomp}
  \end{figure}

% \begin{figure}[h!]
% \centering
% 	\begin{pcvstack}[center,boxed]
% 		\begin{pchstack}
% 			\procedure{$\kgen(\secparam, \maxdeg)$} {
% 				\alpha, \chi \sample \FF^2_p \\ [\myskip]
% 				\pcreturn \gone{\smallset{\chi^i}_{i = -\multconstr}^{\multconstr},
%           \smallset{\alpha \chi^i}_{i = -\multconstr, i \neq
%             0}^{\multconstr}},\\
%         \pcind \gtwo{\smallset{\chi^i, \alpha \chi^i}_{i =
%             -\multconstr}^{\multconstr}}, \gtar{\alpha}\\
% 				%\markulf{03.11.2020}{} \\
% 			%	\hphantom{\pcind \p{o}_i(X) \gets \sum_{j = 1}^{t_i} \gamma_i^{j - 1} \frac{\p{f}_{i,j}(X) - \p{f}_{i, j}(z_i)}{X - z_i}}
% 				\hphantom{\hspace*{5.5cm}}
% 		}
%
% 			\pchspace
%
% 			\procedure{$\com(\srs, \maxconst, \p{f}(X))$} {
% 				\p{c}(X) \gets \alpha \cdot X^{\dconst - \maxconst} \p{f}(X) \\ [\myskip]
% 				\pcreturn \gone{c} = \gone{\p{c}(\chi)}\\ [\myskip]
% 				\hphantom{\pcind \pcif \sum_{i = 1}^{\abs{\vec{z}}} r_i \cdot
%           \gone{\sum_{j = 1}^{t_j} \gamma_i^{j - 1} c_{i, j} - \sum_{j = 1}^{t_j}
%             s_{i, j}} \bullet \gtwo{1} + } }
% 		\end{pchstack}
% 		% \pcvspace
%
% 		\begin{pchstack}
% 			\procedure{$\open(\srs, z, s, f(X))$}
% 			{
% 				\p{o}(X) \gets \frac{\p{f}(X) - \p{f}(z)}{X - z}\\ [\myskip]
% 				\pcreturn \gone{\p{o}(\chi)}\\ [\myskip]
% 				\hphantom{\hspace*{5.5cm}}
% 			}
%
% 			\pchspace
%
% 			\procedure{$\verify(\srs, \maxconst, \gone{c}, z, s, \gone{\p{o}(\chi)})$}
%       {
%         \pcif \gone{\p{o}(\chi)} \bullet \gtwo{\alpha \chi} + \gone{s - z
%         \p{o}(\chi)} \bullet \gtwo{\alpha} = \\ [\myskip] \pcind \gone{c}
%         \bullet \gtwo{\chi^{- \dconst + \maxconst}} \pcthen  \pcreturn 1\\
%         [\myskip]
%         \rlap{\pcelse \pcreturn 0.} \hphantom{\pcind \pcif \sum_{i =
%             1}^{\abs{\vec{z}}} r_i \cdot \gone{\sum_{j = 1}^{t_j} \gamma_i^{j -
%               1} c_{i, j} - \sum{j = 1}^{t_j} s_{i, j}} \bullet \gtwo{1} + } }
% 		\end{pchstack}
% 	\end{pcvstack}
%
% 	\caption{$\PCOMs$ polynomial commitment scheme.}
% 	\label{fig:pcoms}
% \end{figure}

\subsection{Unique Opening Property of $\PCOMp$}
Now, we show that the batched variant of the KZG polynomial
commitment scheme that is used in \plonk{} and $\marlin{}$, has the unique opening property.
\markulf{30.4}{Changed this to $\PCOMp$, hope that's correct. Could simplfy this, given that the body will be only about Plonk?}

\begin{lemma}
\label{lem:pcomp_op}
Let $\PCOMp = (\kgen, \com, \open, \verifyb)$ be a batched version of a KZG polynomial commitment,
cf.~\cref{fig:pcomp}, that commits to $m$ polynomials of degree up to $\maxdeg$. Let $\vec{z} = (z_0, \ldots, z_{l - 1}) \in \FF_p^l$ be the points the polynomials are  evaluated at, $k_i \in \NN$ be the number of the committed polynomials to be evaluated at $z_i$, and $K_i$ be the set of indices of these polynomials. Let $\vec{s_{K_i}} \in \FF_p^{k_i}$ the evaluations of polynomials at $z_i$, and $\vec{o} = (o_0, \ldots, o_{l - 1}) \in \FF_p^l$ be the commitment openings. We show that the probability an algebraic adversary $\adv$, who can made up to $q$ random oracle queries, opens the same vector of commitments in two different ways is at most $\epsop(\secpar)$, for $\epsop(\secpar) \leq l \cdot  \epsudlog(\secpar) + \infrac{1}{\abs{\FF_p}}$, where $\epsudlog(\secpar)$ is security of the $(\maxdeg, 1)$-$\udlog$ assumption and $\FF_p$ is the field used in $\PCOMp$.
\end{lemma}
\begin{proof}
 
  The proof goes by game hops. In the first game the adversary wins if it presents two acceptable openings of a vector of polynomials. Then, we restrict the winning condition and require that the adversary also makes the idealized batched verifier to accept the proof. In the next game, we abort if the idealized verifier rejects a proof for one of the evaluation point. 

  \ncase{Game 0} In this game the adversary wins if it provides two different openings for a vector of polynomial commitments and their evaluations that are acceptable by $\verifyb$.

  \ncase{Game 1} This game is identical to Game 0 except it is additionally aborted if the commitment opening are not acceptable by $\verifyb'$.

  \ncase{Game 0 to Game 1} %
  Any discrepancy between the idealised verifier rejection and real verifier acceptance allows one to break the (updatable) discrete logarithm problem.  The reduction $\rdvdulog$ proceeds as follows. It answers $\adv$'s queries for SRS updates according to the answers it receives from its udlog update oracle. When $\adv$ finalizes an SRS, $\rdvdulog$ finalizes the corresponding udlog challenge $(\gone{1, \ldots, {\chi'}^{\maxdeg}}, \gtwo{1})$. We consider verification equation $(**)$ as a polynomial in $X$ and the verification equation $(*)$ as it's evaluation at $\chi'$. Consider an opening such that verification equation (**), cf.~\cref{fig:pcomp}, does not hold, i.e.~(**) is not a zero polynomial, but (*) does, i.e.~(**) zeroes at $\chi'$. Since $\adv$ is algebraic, all proof elements are extended by their representation as a combination of the input $\GRP_1$-elements. Therefore, all coefficients of the verification equation polynomial related to (**) are known. Now, $\rdvdulog$ computes the roots of (**), finds $\chi'$ among them, and returns $\chi'$. Hence the probability that the adversary wins in Game 1, but does not win in Game 0 is upper-bounded by $\epsudlog (\secpar)$.

  \ncase{Game 2} This game is identical to Game 1 except it is additionally aborted if one of the opening is not acceptable by an idealised verifier $\verify'$.

  \ncase{Game 1 to Game 2}
  The ideal verifier checks whether the following equality, for $\smallset{\gamma_j}_{j = 1}^{l}, r$
  picked at random, holds:
  \begin{multline}
    \label{eq:ver_eq_poly}
    \sum_{j = 0}^{l - 1} r^{j}\left(\sum_{i \in K_j} \gamma_{j}^{i - 1} \cdot \p{f}_i(X) - \sum_{i \in K_j} \gamma_{j}^{i - 1} \cdot {s_i}_j \right) 
    \equiv \sum_{j = 0}^{l - 1} r^{j} \p{o_{j}}(X)(X - z_j).
  \end{multline}
  Since $r$ has been picked as a random oracle output, probability that
  \cref{eq:ver_eq_poly} holds while for some $j \in \range{0}{l - 1}$
  \[
    r^j \left(\sum_{i \in K_j} \gamma^{i - 1} \cdot \p{f}_i(X) - \sum_{i \in K_j}
    \gamma^{i - 1} \cdot {s_i}_j \right) \not\equiv r^j \p{o_j}(X)(X - z_j)
  \]
  is $\infrac{q}{\abs{\FF_p}}$~cf.~\cite{EPRINT:GabWilCio19}. 
  When \(
    r^j \left(\sum_{i \in K_j} \gamma^{i - 1} \cdot \p{f}_i(X) - \sum_{i \in K_j}
    \gamma^{i - 1} \cdot {s_i}_j \right) = r^j \p{o_j}(X)(X - z_j)
  \)
  holds, polynomial $\p{o_j}(X)$ is uniquely determined from the uniqueness of
  polynomial composition. 

  \ncase{Conclusion} %
  We note that the idealised verifier $\vereq(X)$ does not accept two different openings of a correct evaluation. Hence the probability that the adversary wins Game 2 is $0$ and the probability that the adversary wins in Game 0 is upper-bounded by \(\epsudlog (\secpar) + \frac{q}{\abs{\FF_p}}\).
    \qed
\end{proof}