\section{Concrete SNARKs Preliminaries}

\ourpar{Bilinear groups.}
A bilinear group generator $\pgen (\secparam)$ returns public parameters $ \pp =
(p, \GRP_1, \GRP_2, \GRP_T, \pair, \gone{1}, \gtwo{1})$, where $\GRP_1$,
$\GRP_2$, and $\GRP_T$ are additive cyclic groups of prime order $p = 2^{\Omega
  (\secpar)}$, $\gone{1}, \gtwo{1}$ are generators of $\GRP_1$, $\GRP_2$, resp.,
and $\pair: \GRP_1 \times \GRP_2 \to \GRP_T$ is a non-degenerate
$\ppt$-computable bilinear pairing. We assume the bilinear pairing to be Type-3,
i.e., that there is no efficient isomorphism from $\GRP_1$ to $\GRP_2$ or from
$\GRP_2$ to $\GRP_1$. We use the by now standard bracket notation, i.e., we
write $\bmap{a}{\gi}$ to denote $a g_{\gi}$ where $g_{\gi}$ is a fixed generator
of $\GRP_{\gi}$. We denote $\pair (\gone{a}, \gtwo{b})$ as $\gone{a} \bullet
\gtwo{b}$. Thus, $\gone{a} \bullet \gtwo{b} = \gtar{a b}$. We freely use the
bracket notation with matrices, e.g., if $\vec{A} \vec{B} = \vec{C}$ then
$\vec{A} \grpgi{\vec{B}} = \grpgi{\vec{C}}$ and $\gone{\vec{A}}\bullet
\gtwo{\vec{B}} = \gtar{\vec{C}}$. Since every algorithm $\adv$ takes as input
the public parameters we skip them when describing $\adv$'s input. Similarly, we
do not explicitly state that each protocol starts with generating these
parameters by $\pgen$.

\subsection{Algebraic Group Model}
The algebraic group model (AGM) introduced in \cite{C:FucKilLos18} lies between the
standard model and generic bilinear group model. In the AGM it is assumed that an
adversary $\adv$ can output a group element $\gnone{y} \in \GRP$ if $\gnone{y}$ has
been computed by applying group operations to group elements given to $\adv$ as
input. It is further assumed, that $\adv$ knows how to ``build'' $\gnone{y}$ from
that elements. More precisely, the AGM requires that whenever $\adv(\gnone{\vec{x}})$
outputs a group element $\gnone{y}$ then it also outputs $\vec{c}$ such that
$\gnone{y} = \vec{c}^\top \cdot \gnone{\vec{x}}$. $\plonk$, $\sonic$ and $\marlin$
have been shown secure using the AGM. An adversary that works in the AGM is called
\emph{algebraic}.

\oursubsub{Idealised Verifier and Verification Equations.} Let
$(\kgen, \prover, \verifier, \simulator)$ be a proof system.
% or a polynomial commitment
% scheme\hamid{might be unclear as we are defining polynomial commitments as
%   $(\kgen, \com, \open, \verify)$.}.
Observe that the $\kgen$ algorithm provides an SRS which can be interpreted as a set
of group representation of polynomials evaluated at trapdoor elements. That is, for a
trapdoor $\chi$ the SRS contains $\gone{\p{p_1}(\chi), \ldots, \p{p_k}(\chi)}$, for
some polynomials $\p{p_1}(X), \ldots, \p{p_k}(X) \in \FF_p[X]$. The verifier
$\verifier$ accepts a proof $\zkproof$ for instance $\inp$ if (a set of) verification
equation $\vereq_{\inp, \zkproof}$ (which can also be interpreted as a polynomial in
$\FF_p[X]$ whose coefficients depend on messages sent by the prover) zeroes at
$\chi$. Following \cite{EPRINT:GabWilCio19} we call verifiers who check that
$\vereq_{\inp, \zkproof}(\chi) = 0$ \emph{real verifiers} as opposed to \emph{ideal
  verifiers} who accept only when $\vereq_{\inp, \zkproof}(X) = 0$. That is, while a
real verifier accepts when a polynomial \emph{evaluates} to zero, an ideal verifier
accepts only when the polynomial \emph{is} zero.

Although ideal verifiers are impractical, they are very useful in our
proofs. More precisely, we show that
\begin{compactenum}
\item the idealised verifier accepts an incorrect proof (what ``incorrect''
  means depends on the situation) with at most negligible probability (and in many
  cases---never);
\item when the real verifier accepts, but not the idealised one, then a malicious
  prover can be used to break the underlying security assumption (in our case---a
  variant of $\dlog$.)
\end{compactenum}

Analogously, idealised verifier can be defined for polynomial commitment schemes.

\subsection{Dlog assumptions}
  \markulf{22.04}{Move it to Section 5.}
\label{sec:dlog_assumptions}
\begin{definition}[$(q_1, q_2)\mhyph\dlog$ assumption]\label{def:dlog}
	Let $\adv$ be a $\ppt$ adversary that gets as input
  $\gone{1, \chi, \ldots, \chi^{q_1}}, \gtwo{1, \chi, \ldots, \chi^{q_2}}$, for
  some randomly picked $\chi \in \FF_p$, the assumption requires that $\adv$ cannot compute $\chi$. That is
	\[
		\condprob{\chi = \adv(\gone{1, \chi, \ldots, \chi^{q_1}}, \gtwo{1, \chi,
        \ldots, \chi^{q_2} })}{\chi \sample \FF_p} \leq \negl.
	\]
\end{definition}

\markulf{22.04}{I prefer the notation $Pr[\chi \gets \FF_q; \chi' \gets \adv( ...): \chi=\chi']$ as one can start reading at the left. But I will let that one go and will admit that it's a question of taste and it might be an aquired taste. }

\begin{definition}[$(q_1, q_2)\mhyph\ldlog$ assumption]\label{def:ldlog}
  Let $\adv$ be a $\ppt$ adversary that gets as input
  $\gone{\chi^{-q_1}, \ldots, 1, \ldots, \chi^{q_1}}, \gtwo{\chi^{-q_2},
    \ldots, 1, \ldots, \chi^{q_2}}$, for some randomly picked
  $\chi \in \FF_p$, the assumption requires that $\adv$ cannot compute $\chi$. That is
	\[
    \condprob{\chi = \adv(\gone{\chi^{-q_1}, \ldots, 1, \ldots,
        \chi^{q_1}}, \gtwo{\chi^{-q_2}, \ldots, 1, \ldots, \chi^{q_2}
      })}{\chi \sample \FF_p} \leq \negl.
	\]
\end{definition}


\chb{\paragraph{Dlog assumptions in the updatable setting.}\label{dlog-upd} Since all our protocols and security notions are in the updatable setting, we may require to rely on Dlog assumptions that are defined in the updatable setting. That is, the adversary $\adv$ is not given as input a Dlog challenge, but access to an update oracle as defined in~\cref{fig:upd}, wherein an honestly generated SRS is defined as a Dlog challenge and the update algorithm $\upd$ works similarly as in the updatable schemes by re-randomizing the challenge. Here we define these assumptions and then show a reduction between the assumptions and their variant in the updatable setting. \textcolor{blue}{Note that for ease of clarity, with a slight abuse of notation, we here denote the SRS by $\Ch$. Further, to avoid cluttering notation, we do not make the proofs of correctly generating or updating the Dlog challenges explicit as they can be generated in a similar manner to the proofs in~\cref{fig:upd-scheme}.}
	
%The reduction $\reduction$ proceeds as follows: given the input dlog instance, $\reduction$ answers adversary's queries for the dlog updates and sets the honest update to be the input dlog instance. Once the dlog challenge in the updatable setting is finalized, it runs the adversary and obtains the answer $\chi'$. Let $\chi_1, \ldots, \chi_\ell$ be the partial discrete logarithms of dlog instances corresponding to the adversary's dlog updates. These values can be computed by $\reduction$ by extracting from the update proofs given by the adversary. $\reduction$ now returns  $\chi = \chi' (\chi_1 \chi_2 \ldots \chi_\ell)^{-1}$. The same argument holds for the $(q_1, q_2)\mhyph\ldlog$ assumption, ~\cref{def:ldlog}.

\subsection{Dlog assumptions in the updatable setting}
\label{sec:udlog_assumptions}

\begin{definition}[$(q_1, q_2)\mhyph\udlog$ assumption]\label{def:udlog}
	Let $\adv$ be a $\ppt$ adversary that gets oracle access to $\initU$ with internal algorithms $(\kgen_{\dlog}, \upd_{\dlog}, \verifyCRS)$, where $\kgen_{\dlog}$ and $\upd_{\dlog}$ are defined as follows:
	\begin{itemize}
	\item $\kgen_\dlog(\secpar)$ samples $\chi \sample \FF_p$ and defines 
		$\Ch:=(\gone{1, \chi, \ldots,
			\chi^{q_1}}, \gtwo{1, \chi, \ldots, \chi^{q_2}
		})$.
	\item $\upd_\dlog(\Ch, \{\rho_j \}_{j=1}^n)$ 
	parses $\Ch$ as $\left( \gone{\smallset{A_i}_{i = 0}^{q_1}},
	\gtwo{\smallset{B_i}_{i = 0}^{q_2}} \right)$, samples
	$\widetilde{\chi} \sample \FF_p$, and defines
	$\widetilde{\Ch} := 
	\left( \gone{\smallset{\widetilde{\chi}^i A_i}_{i = 0}^{q_1}},
	\gtwo{\smallset{\widetilde{\chi}^i B_i}_{i = 0}^{q_2}} \right)$.
	\end{itemize}
	Then
	\[
	\prob{\bar{\chi} \gets \adv^{\initU}(\secpar)} \leq \negl,
	\]
	where $\left( \gone{\smallset{\bar{\chi}^i}_{i = 0}^{q_1}},
	\gtwo{\smallset{\bar{\chi}^i}_{i = 0}^{q_2}} \right)$ is the finalized challenge.
\end{definition}

\begin{definition}[$(q_1, q_2)\mhyph\uldlog$ assumption]\label{def:uldlog}
	Let $\adv$ be a $\ppt$ adversary that gets oracle access to $\initU$ with internal algorithms $(\kgen_{\ldlog}, \upd_{\ldlog}, \verifyCRS)$, where $\kgen_{\ldlog}$ and $\upd_{\ldlog}$ are defined as follows:
	\begin{itemize}
		\item $\kgen_\ldlog(\secpar)$ samples $\chi \sample \FF_p$ and defines 
		$\Ch:=(\gone{\chi^{-q_1}, \ldots, 1, \chi, \ldots,
			\chi^{q_1}}, \gtwo{\chi^{-q_2}, \ldots, 1, \chi, \ldots, \chi^{q_2}
		})$.
		\item $\upd_\ldlog(\Ch, \{\rho_j \}_{j=1}^n)$ 
		parses $\Ch$ as $\left( \gone{\smallset{A_i}_{i = -q_1}^{q_1}},
		\gtwo{\smallset{B_i}_{i = -q_2}^{q_2}} \right)$, samples
		$\widetilde{\chi} \sample \FF_p$, and defines
		$\widetilde{\Ch} := 
		\left( \gone{\smallset{\widetilde{\chi}^i A_i}_{i = -q_1}^{q_1}},
		\gtwo{\smallset{\widetilde{\chi}^i B_i}_{i = -q_2}^{q_2}} \right)$.
	\end{itemize}
	Then
	\[
	\prob{\bar{\chi} \gets \adv^{\initU}(\secpar)} \leq \negl,
	\]
	where $\left( \gone{\smallset{\bar{\chi}^i}_{i = -q_1}^{q_1}},
	\gtwo{\smallset{\bar{\chi}^i}_{i = -q_2}^{q_2}} \right)$ is the finalized challenge.
\end{definition}

\chb{\begin{remark}[Single adversarial updates after an honest setup.]\label{rem:upd}
	One can consider a slightly different model of setup, where the adversary is given an initial honestly-generated SRS and is then allowed to perform a malicious update in one-shot fashion.
	As shown by Groth
	et al. in~\cite{C:GKMMM18}, the two definitions are equivalent for the class of SNARKs in this work and thus we use this simpler definition to show our security proofs in the updatable setting.
\end{remark}} \markulf{25.04}{Move this to where we use it in the proof.}

We show a reduction from $(q_1, q_2)\mhyph\dlog$ assumption to its variant in the updatable setting according to the update model in~\cref{rem:upd}. We omit showing the reduction $(q_1, q_2)\mhyph\ldlog \Rightarrow (q_1, q_2)\mhyph\uldlog$ as it can be done similarly in a straightforward manner.
\begin{lemma}
	$(q_1, q_2)\mhyph\dlog \Rightarrow (q_1, q_2)\mhyph\udlog$.
	\end{lemma}
\begin{proof}
	We construct a reduction algorithm $\reduction$ which uses an adversary $\adv$ on the $(q_1, q_2)\mhyph\udlog$ and construct an adversary on the $(q_1, q_2)\mhyph\dlog$. Specifically, $\reduction$ proceeds as follows: given a dlog instance $\Ch$ as input, it sets $\Ch$ as the initial (honestly generated) challenge \sout{and answers adversary's queries for the dlog updates by internally running $\upd_{\dlog}$ in Definition 5.} Once the dlog challenge in the updatable setting is finalized, it runs $\adv$ and obtains the answer $\chi'$. Let \sout{$\chi_1, \ldots, \chi_\ell$} $\chi_\adv$ be the (possibly) partial discrete logarithm of the dlog instance corresponding to the adversary's update. This value can be computed by $\reduction$ by extracting from the update proof given by $\adv$. $\reduction$ now returns  
	\sout{$\chi = \chi' (\chi_1 \chi_2 \ldots \chi_\ell)^{-1}$} $\chi = \chi' \chi_\adv^{-1}$ as the discrete logarithm of $\Ch$. %The same argument holds for the $(q_1, q_2)\mhyph\ldlog$ assumption, ~\cref{def:ldlog}.
	\end{proof}
}
  %\michals{24.03}{I think we should write a formal proof for the reduction}

  \oursubsub{Generalized forking lemma}
Although dubbed ``general'', the forking lemma of~\cite{CCS:BelNev06} is not general
enough for our purpose as it is useful only for protocols where a witness can be
extracted from just two transcripts. To be able to extract a witness from, say, an
execution of $\plonkprot$ we need at least $(3 \numberofconstrains + 1)$ valid proofs
(where $\numberofconstrains$ is the number of constrains),
$(\numberofconstrains+ 1)$ for $\sonicprot$, and $\numberofconstrains + 4$ for $\marlinprot$. Here we use Attema et
al.~\cite{EPRINT:AttFehKlo21} generalization of the forking lemma\footnote{The
	earlier versions of this paper used another generalization of the forking lemma
	provided by the paper authors. Change to Attema's et al.~result was due to better
	extraction success probability bound.}  which shows security of the Fiat--Shamir
transformation for multi-message protocols. The lemma, given probability of producing
an accepting transcript, $\accProb$, lower-bounds the probability of generating a
tree of accepting transcripts $\tree$, which allows to extract a witness.



  \begin{lemma}[Generalized forking lemma~\cite{EPRINT:AttFehKlo21}]\label{lem:attema}
	Let $\varrho = n_1 \cdots n_\mu$. \markulf{26.04}{are the $n_i$ the same as the $k_i$ in the algoithm of Fig.3?}\hamid{29}{Yes, they're inconsistent. I'll fix!} Let $\proofsystem$ be a proof system that is knowledge sound \markulf{22.04}{Requiring knowledge soundness here seems circular.} \chaya{25.04}{do we want to say that $\proofsystem$ is knowledge sound with knowledge error $\epsk$ if there exists a tree buildin algorithm $\tdv$ such that a tree of accepting transcripts is produced with the following probability?}\hamid{29.4}{I think $\epsk$ should not be defined as a general notion of knowledge error here. According to Attema paper, this knowledge error for $(2\mu+1)$-move $(n_1, \ldots, n_\mu)$-out-of-$(N_1, \ldots, N_\mu)$ special sound protocols is defined as:
	$$
Er(n_1, \ldots, n_\mu; N_1, \ldots, N_\mu) := 1 - \prod_{i=1}^{\mu}(1 - \frac{n_i - 1}{N_i})
	$$
In our case, this would be $\epsk = Er(n_1, \ldots, n_\mu; N)$.}
	with knowledge error $\epsk$. Assume adversary $\adv$ that makes up to $q$ random
	oracle queries and outputs an acceptable proof with probability at least
	$\accProb$. There exists a tree building algorithm $\tdv$ for $(n_1, \ldots, n_\mu)$-trees that utilizes the extractor $\zdv_1$ in~\cref{fig:Attema-ext} and succeeds in building a
	tree of accepting transcripts in expected
	running time $\varrho + q (\varrho - 1)$ with probability at least
	\[
	\frac{\accProb - (q + 1) \epsk (\secpar)}{1 - \epsk (\secpar)}.
	\]
	\end{lemma}

\begin{figure}[t]
	\centering
	\fbox{\parbox{\textwidth}{
			\begin{enumerate}
				\item Run $\zdv_{m + 1}$ as follows to obtain $(\vec{I}, \zkproof_1, v)$: relay the
				$q + \mu$ queries to the random oracle and record all query-response pairs. Set
				$i \gets I_m$, and let $c_i$ be the response to query $i$.
				\item If $v = 0$, abort with output $v = 0$. 
				\item Else, repeat
				\begin{itemize}
					\item sample $c'_i \in C \setminus \smallset{c_i}$ (without replacement);
					\item run $\zdv_{m + 1}$ as follows to obtain $(\vec{I'}, \zkproof', v')$, aborting right after the initial run of $\adv$ if $I'_m \neq I_m$: answer the query to $i$ with $c'_i$, while answering all other queries consistently if the query was performed by $\zdv_{m + 1}$ already on a previous run and with a fresh random value in $C$ otherwise; 
				\end{itemize}
				until either $k_m - 1$ additional challenges $c'_i$ with $v' = 1$ and $I'_m = I_m$ have been found or until all challenges $c'_i \in C$ have been tried. 
				\item In the former case, output $\vec{I}$, the $k_m$ accepting
				$(1, \ldots, 1, k_{m + 1}, \ldots, k_\mu)$-trees $\zkproof_1, \ldots, \zkproof_{k_m}$, and
				$v \gets 1$; in the latter case, output $v \gets 0$.
			\end{enumerate}
	}}
	\caption{Extractor $\zdv_m$ from Attema et al.~\cite{EPRINT:AttFehKlo21}. Here $\vec{I}$ is an index vector
		that contains all random oracle queries made by the prover for the output proof;
		that is, for prover's messages $\vec{a} = a_1, \ldots, a_{\mu + 1}$,
		$I_1 = (\inp, a_1), \ldots, I_{\mu} = (\inp, a_1, \ldots, a_\mu)$.  $\zkproof$ is a proof
		transcript that contains both prover's messages and random oracle responses, that is
		$\zkproof = (a_1, (\inp, a_1), a_2, (\inp, a_1, a_2), \ldots)$. Finally, $v$ is the
		verification bit, that is $v = \verifier (\srs, \inp, \zkproof)$. }
	\label{fig:Attema-ext}
\end{figure} 