% !TEX root = main.tex
% !TEX spellcheck = en-US

\section{Non-malleability of $\sonicprotfs$}
\label{sec:sonic}
\subsection{\sonic{} protocol rolled out}
In this section we present $\sonic$'s constraint system and algorithms. Reader
familiar with them may jump directly to the next section.

%\hamid{}{we should put the following figure \ref{fig:pcoms} somewhere in this section.}
 \begin{figure}[h!]
 \centering
 	\begin{pcvstack}[center,boxed]
 		\begin{pchstack}
 			\procedure{$\kgen(\secparam, \maxdeg)$} {
 				\alpha, \chi \sample \FF^2_p \\ [\myskip]
 				\pcreturn \gone{\smallset{\chi^i}_{i = -\multconstr}^{\multconstr},
           \smallset{\alpha \chi^i}_{i = -\multconstr, i \neq
             0}^{\multconstr}},\\
         \pcind \gtwo{\smallset{\chi^i, \alpha \chi^i}_{i =
             -\multconstr}^{\multconstr}}, \gtar{\alpha}\\
 				%\markulf{03.11.2020}{} \\
 			%	\hphantom{\pcind \p{o}_i(X) \gets \sum_{j = 1}^{t_i} \gamma_i^{j - 1} \frac{\p{f}_{i,j}(X) - \p{f}_{i, j}(z_i)}{X - z_i}}
 				\hphantom{\hspace*{5.5cm}}
 		}

 			\pchspace

 			\procedure{$\com(\srs, \maxconst, \p{f}(X))$} {
 				\p{c}(X) \gets \alpha \cdot X^{\dconst - \maxconst} \p{f}(X) \\ [\myskip]
 				\pcreturn \gone{c} = \gone{\p{c}(\chi)}\\ [\myskip]
 				\hphantom{\pcind \pcif \sum_{i = 1}^{\abs{\vec{z}}} r_i \cdot
           \gone{\sum_{j = 1}^{t_j} \gamma_i^{j - 1} c_{i, j} - \sum_{j = 1}^{t_j}
             s_{i, j}} \bullet \gtwo{1} + } }
 		\end{pchstack}
 		% \pcvspace

 		\begin{pchstack}
 			\procedure{$\open(\srs, z, s, f(X))$}
 			{
 				\p{o}(X) \gets \frac{\p{f}(X) - \p{f}(z)}{X - z}\\ [\myskip]
 				\pcreturn \gone{\p{o}(\chi)}\\ [\myskip]
 				\hphantom{\hspace*{5.5cm}}
 			}

 			\pchspace

 			\procedure{$\verify(\srs, \maxconst, \gone{c}, z, s, \gone{\p{o}(\chi)})$}
       {
         \pcif \gone{\p{o}(\chi)} \bullet \gtwo{\alpha \chi} + \gone{s - z
         \p{o}(\chi)} \bullet \gtwo{\alpha} = \\ [\myskip] \pcind \gone{c}
         \bullet \gtwo{\chi^{- \dconst + \maxconst}} \pcthen  \pcreturn 1\\
         [\myskip]
         \rlap{\pcelse \pcreturn 0.} \hphantom{\pcind \pcif \sum_{i =
             1}^{\abs{\vec{z}}} r_i \cdot \gone{\sum_{j = 1}^{t_j} \gamma_i^{j -
               1} c_{i, j} - \sum{j = 1}^{t_j} s_{i, j}} \bullet \gtwo{1} + } }
 		\end{pchstack}
 	\end{pcvstack}

 	\caption{$\PCOMs$ polynomial commitment scheme.}
 	\label{fig:pcoms}
 \end{figure}



\oursubsub{The constraint system}
\label{sec:sonic_constraint_system}
\cref{fig:pcoms} presents a variant of KZG~\cite{AC:KatZavGol10} polynomial commitment schemes
used in \sonic{}. \sonic's system of constraints composes of three $\multconstr$-long vectors
$\va, \vb, \vc$ which corresponds to left and right inputs to multiplication
gates and their outputs. It hence holds $\va \cdot \vb = \vc$.

There is also $\linconstr$ linear constraints of the form
\[
  \va \vec{u_q} + \vb \vec{v_q} + \vc \vec{w_q} = k_q,
\]
where $\vec{u_q}, \vec{v_q}, \vec{w_q}$ are vectors for the $q$-th linear
constraint with instance value $k_q \in \FF_p$. Furthermore define polynomials
\begin{equation}
  \begin{split}
    \p{u_i}(Y) & = \sum_{q = 1}^\linconstr Y^{q + \multconstr} u_{q, i}\,,\\
    \p{v_i}(Y) & = \sum_{q = 1}^\linconstr Y^{q + \multconstr} v_{q, i}\,,\\
  \end{split}
  \qquad
  \begin{split}
    \p{w_i}(Y) & = -Y^i - Y^{-i} + \sum_{q = 1}^\linconstr Y^{q +
      \multconstr} w_{q, i}\,,\\
    \p{k}(Y) & = \sum_{q = 1}^\linconstr Y^{q + \multconstr} k_{q}.
  \end{split}
\end{equation}

$\sonic$ constraint system requires that
\begin{align}
  \label{eq:sonic_constraint}
  \vec{a}^\top \cdot \vec{\p{u}} (Y) + \vec{b}^\top \cdot \vec{\p{v}} (Y) +
  \vec{c}^\top \cdot \vec{\p{w}} (Y) + \sum_{i = 1}^{\multconstr} a_i b_i (Y^i +
  Y^{-i}) - \p{k} (Y) = 0.
\end{align}

In \sonic{} we will use commitments to the following polynomials.
\begin{align*}
  \pr(X, Y) & = \sum_{i = 1}^{\multconstr} \left(a_i X^i Y^i + b_i X^{-i} Y^{-i}
              + c_i X^{-i - \multconstr} Y^{-i - \multconstr}\right) \\
  \p{s}(X, Y) & = \sum_{i = 1}^{\multconstr} \left( u_i (Y) X^{-i} +
                v_i(Y) X^i + w_i(Y) X^{i + \multconstr}\right)\\
  \pt(X, Y) & = \pr(X, 1) (\pr(X, Y) + \p{s}(X, Y)) - \p{k}(Y)\,.
\end{align*}

Polynomials $\p{r} (X, Y), \p{s} (X, Y), \p{t} (X, Y)$ are designed such that
$\p{t} (0, Y) = \vec{a}^\top \cdot \vec{\p{u}} (Y) + \vec{b}^\top \cdot
\vec{\p{v}} (Y) + \vec{c}^\top \cdot \vec{\p{w}} (Y) + \sum_{i =
  1}^{\multconstr} a_i b_i (Y^i + Y^{-i}) - \p{k} (Y) $. That is, the prover is
asked to show that $\p{t} (0, Y) = 0$, cf.~\cref{eq:sonic_constraint}.

Furthermore, the commitment system in $\sonic$ is designed such that it is
infeasible for a $\ppt$ algorithm to commit to a polynomial with non-zero
constant term.

\oursubsub{Algorithms rolled out}
\ourpar{$\sonic$ SRS generation $\kgen(\REL)$.} The SRS generating algorithm picks
randomly $\alpha, \chi \sample \FF_p$ and outputs
	\[
      \srs = \left( \gone{\smallset{\chi^i}_{i = -\dconst}^{\dconst},
          \smallset{\alpha \chi^i}_{i = -\dconst, i \neq 0}^{\dconst}},
        \gtwo{\smallset{\chi^i, \alpha \chi^i}_{i = - \dconst}^{\dconst}},
        \gtar{\alpha} \right)
	\]
\ourpar{$\sonic$ prover $\prover(\srs, \inp, \wit=\va, \vb, \vc)$.}
\begin{description}
\item[Message 1] The prover picks randomly randomisers
  $c_{\multconstr + 1}, c_{\multconstr + 2}, c_{\multconstr + 3}, c_{\multconstr
    + 4} \sample \FF_p$. Sets
  $\pr(X, Y) \gets \pr(X, Y) + \sum_{i = 1}^4 c_{\multconstr + i} X^{- 2
    \multconstr - i}$. Commits to $\pr(X, 1)$ and outputs
  $\gone{r} \gets \com(\srs, \multconstr, \pr(X, 1))$.  Then it computes challenge $y = \ro(\zkproof[0..1])$.
\item[Message 2] $\prover$ commits to $\pt(X, y)$ and outputs
  $\gone{t} \gets \com(\srs, \dconst, \pt(X, y))$. Then it gets a challenge $z = \ro(\zkproof[0..2])$.
\item[Message 3] The prover computes commitment openings. That is, it outputs
  \begin{align*}
    \gone{o_a} & = \open(\srs, z, \pr(z, 1), \pr(X, 1)) \\
    \gone{o_b} & = \open(\srs, yz, \pr(yz, 1), \pr(X, 1)) \\
    \gone{o_t} & = \open(\srs, z, \pt(z, y), \pt(X, y)) 
  \end{align*}
  along with evaluations $a' = \pr(z, 1), b' = \pr(y, z), t' = \pt(z, y)$.  Then it
  engages in the signature of correct computation playing the role of the
  helper, i.e.~it commits to $\p{s}(X, y)$ and sends the commitment $\gone{s}$, commitment opening
  \begin{align*}
    \gone{o_s} & = \open(\srs, z, \p{s}(z, y), \p{s}(X, y)), \\
  \end{align*} and $s'=\p{s}(z, y)$. 
%
  Then
  it obtains a challenge $u = \ro(\zkproof[0..3])$.
\item[Message 4] For the next message the prover computes
  $\gone{c} \gets \com(\srs, \dconst, \p{s}(u, Y))$ and
  computes commitments' openings
  \begin{align*}
    \gone{w} & = \open(\srs, u, \p{s}(u, y), \p{s}(X, y)), \\
    \gone{q_y} & = \open(\srs, y,\p{s}(u, y), \p{s}(u, Y)),
  \end{align*}
  and returns $\gone{w}, \gone{q_y}, s = \p{s}(u, y)$. Eventually the prover gets the last challenge
  $z' = \ro(\zkproof[0..4])$.
\item[Message 5] For the final message, $\prover$ computes opening
  $\gone{q_{z'}} = \open(\srs, z', \p{s}(u, z'), \p{s}(u, X))$ and outputs $\gone{q_{z'}}$.
\end{description}

\ourpar{$\sonic$ verifier $\verifier(\srs, \inp, \zkproof)$.} The verifier
in \sonic{} runs as subroutines the verifier for the polynomial commitment. That
is it sets $t' = a'(b' + s') - \p{k}(y)$ and checks the following:
\begin{equation*}
  \begin{split}
    &\PCOMs.\verifier(\srs, \multconstr, \gone{r}, z, a', \gone{o_a}), \\
    &\PCOMs.\verifier(\srs, \multconstr, \gone{r}, yz, b', \gone{o_b}),\\
    &\PCOMs.\verifier(\srs, \dconst, \gone{t}, z, t', \gone{o_t}),\\
    &\PCOMs.\verifier(\srs, \dconst, \gone{s}, z, s', \gone{o_s}),\\
  \end{split}
  \qquad
  \begin{split}
    &\PCOMs.\verifier(\srs, \dconst, \gone{s}, u, s, \gone{w}),\\
    &\PCOMs.\verifier(\srs, \dconst, \gone{c}, y, s, \gone{q_y}),\\
    &\PCOMs.\verifier(\srs, \dconst, \gone{c}, z', \p{s}(u, z'), \gone{q_{z'}}),
  \end{split}
\end{equation*}
and accepts the proof iff all the checks holds. Note that the value
$\p{s}(u, z')$ that is recomputed by the verifier uses separate challenges $u$
and $z'$. This enables the batching of many proof and outsourcing of this
part of the proof to an untrusted helper.

\subsection{Unique opening property of $\PCOMs$}
\begin{lemma}
\label{lem:pcoms_unique_op}
$\PCOMs$ has the unique opening property in the AGM. 
\end{lemma}
\begin{proof}
Let 
$z \in \FF_p$ be the attribute the polynomial is evaluated at,
$\gone{c} \in \GRP$ be the commitment,  
$s \in \FF_p$ the evaluation value, and 
$o \in \GRP$ be the commitment opening. 
We need to show that for every $\ppt$ adversary $\adv$ probability
\[
  \Pr \left[
    \begin{aligned}
      & \verify(\srs, \gone{c}, z, s, \gone{o}) = 1, \\
      & \verify(\srs, \gone{c}, z, \tilde{s}, \gone{\tilde{o}}) = 1
    \end{aligned}
    \,\left|\, \vphantom{\begin{aligned}
          & \verify(\srs, \gone{c}, z, s, \gone{o}),\\
          & \verify(\srs, \gone{c}, z, s, \gone{\tilde{o}}) \\
          &o \neq \tilde{o})
		\end{aligned}}
      \begin{aligned}
        %& \srs \gets \kgen(\secparam, \maxdeg), \\
        & (\gone{c}, z, s, \gone{o}, \gone{\tilde{o}}) \gets \adv^{\initU}(1^\secpar, \maxdeg)
      \end{aligned}
    \right.\right]
  % \leq \negl.
\]
is at most negligible.

As noted in \cite[Lemma 2.2]{EPRINT:GabWilCio19} it is enough to upper bound the
probability of the adversary succeeding using the idealised verification
equation---which considers equality between polynomials---instead of the real
verification equation---which considers equality of the polynomials' evaluations.

For a polynomial $f$, its degree upper bound $\maxconst$, evaluation point $z$,
evaluation result $s$, and opening $\gone{o(X)}$ the idealised check verifies that
\begin{equation}
  \alpha (X^{\dconst - \maxconst}f(X) \cdot X^{-\dconst + \maxconst} -  s) \equiv \alpha \cdot o(X) (X - z)\,,
\end{equation}
what is equivalent to 
\begin{equation}
	f(X) -  s \equiv o(X) (X - z)\,.
	\label{eq:pcoms_idealised_check}
\end{equation}
Since $o(X)(X - z) \in \FF_p[X]$ then from the uniqueness of polynomial
composition, there is only one $o(X)$ that fulfils the equation above.
\qed
\end{proof}


\subsection{Unique response property}
The unique response property of $\sonicprot$ follows from the unique opening
property of the used polynomial commitment scheme $\PCOMs$.
\begin{lemma}
\label{lem:sonicprot_ur}
If a polynomial commitment scheme $\PCOMs$ is evaluation binding with parameter
$\epsbind (\secpar)$ and has unique openings property with parameter $\epsop(\secpar)$,
$\sonicprotfs$ is $\epss (\secpar)$-sound and $(\dconst, \dconst)$-ldlog problem is
$\epsdlog (\secpar)$-hard, then $\sonicprot$ is $\ur{1}$ with security loss
  \[
    3 \cdot \epsop (\secpar) + 2 \cdot (\epsbind (\secpar) + \epss (\secpar) +
    \epsdlog (\secpar)).
  \]
\end{lemma}

\changedm{
\begin{proof}
  Let $\adv$ be an algebraic adversary tasked to break the $\ur{1}$-ness of
  $\sonicprotfs$. We show that the first prover's message determines, along with
  the verifiers challenges, the rest of it.  This is done by game hops. In the games,
  the adversary outputs two proofs $\zkproof^0$ and $\zkproof^1$ for the same statement.
  To distinguish polynomials and commitments which an honest prover sends in the
  proof from the polynomials and commitments computed by the adversary we write the
  latter using indices $0$ and $1$ (two indices as we have two transcripts), e.g.~to
  describe the quotient polynomial provided by the adversary we write $\p{t}^0$ and
  $\p{t}^1$ instead of $\p{t}$ as in the description of the protocol.

  \ngame{0} In this game, the adversary additionally wins if it provides two transcripts that
  match on all $5$ messages sent by the prover.
  In this game the adversary cannot win.

  \ngame{1} This game is identical to Game $\game{0}$ except that now the
  adversary additionally wins if it provides two transcripts that matches on the first four
  messages of the proof.

  \ncase{Game 0 to Game 1} We show that the probability that $\adv$
  wins in one game but does not in the other is negligible.  Observe that in
  after its $4$-th message, the adversary is given a challenge $z'$ and has to open
  commitment to $\p{s} (u, z')$. Hence, to be able to give two different
  openings in its $5$-th message, $\adv$ has to break the unique opening property of the
  KZG commitment scheme which happens with probability $\epsop (\secpar)$ tops.

  \ngame{2} This game is identical to Game $\game{1}$ except that now the
  adversary additionally wins if it provides two transcripts that matches on the
  first three messages of the proof.

  \ncase{Game 2 to Game 3} In its $4$-th message the adversary computes evaluation
  $s = \p{s} (u, y)$ and the corresponding openings $\gone{w}, \gone{q_y}$. The adversary
  cannot provide two different evaluations for the committed polynomials, since that would
  require breaking the evaluation binding property, which happens (by the union bound)
  with probability at most $2 \cdot \epsbind (\secpar)$. Also, the adversary cannot provide two
  different yet valid opening except probability $2 \cdot \epsop (\secpar)$

  Hence, the probability that adversary wins in one game but does not in the
  other is upper-bounded by $2 \cdot (\epsbind (\secpar) + \epsop (\secpar))$

  \ngame{4} This game is identical to Game $\game{3}$ except that now the
  adversary additionally wins if it provides two transcripts that matches on the
  first two messages of the proof.

  \ncase{Game 3 to Game 4} In its $3$-rd message the adversary computes $4$ polynomial
  evaluations and their openings. It also sends commitment to $\p{s} (X, y)$ which is a
  signature of correct computation.

  Probability that the adversary provides different evaluations or polynomial openings is
  upper bounded by $4 \cdot (\epsop (\secpar) + \epsbind (\secpar))$. Since the polynomial
  commitment scheme is deterministic, if commitment to $\p{s^0} (X, y)$ does not equal
  commitment to $\p{s^1} (X, y)$, then at least one of these values has been computed
  incorrectly. Probability that the adversary outputs an acceptable proof, where signature
  of correct computation has been computed incorrectly is upper-bounded by $\epss
  (\secpar) + \epsdlog (\secpar)$, cf.~\cref{lem:plonkprot_ur}.

  \ncase{Game 5}  This game is identical to Game $\game{4}$ except that now the
  adversary additionally wins if it provides two transcripts that matches on the
  first messages of the proof.

  \ncase{Game 4 to Game 5} In its second message the adversary commits to polynomial
  $\p{t} (X, y)$. Since the commitment scheme is deterministic, probability that adversary
  outputs acceptable proofs where commitment to $\p{t^0} (X, y)$ does not equal commitment
  to $\p{t^1} (X)$ is upper-bounded by $\epss (\secpar) + \epsdlog (\secpar)$, cf.~\cref{lem:plonkprot_ur}.

  \ncase{Conclusion} Taking all the games together, probability that $\adv$ wins
  in Game 5 is upper-bounded by
  \[
    3 \cdot \epsop (\secpar) + 2 \cdot (\epsbind (\secpar) + \epss (\secpar) +
    \epsdlog (\secpar)).
  \]
  \qed
\end{proof}
}

\COMMENT{
  \michals{1.11}{Old proof below}
\begin{proof}
  Let $\adv$ be an adversary that breaks $\ur{1}$-ness of $\sonicprot$.  We
  consider two cases, depending on which message $\adv$ is able to provide at
  least two different outputs such that the resulting transcripts are
  acceptable.  For the first case we show that $\adv$ can be used to break the
  evaluation binding property of $\PCOMs$, while for the second case we show
  that it can be used to break the unique opening property of $\PCOMs$.

  The proof goes similarly to the proof of \cref{lem:plonkprot_ur} thus we
  provide only draft of it here.  For $i$-th message ($i > 1$) the prover
  either commits to some well-defined polynomials (deterministically), evaluates
  these on randomly picked points, or shows that the evaluations were performed
  correctly.  Obviously, for a committed polynomial $\p{p}$ evaluated at point
  $x$ only one value $y = \p{p}(x)$ is correct. If the adversary was able to
  provide two different values $y$ and $\tilde{y}$ that would be accepted as an
  evaluation of $\p{p}$ at $x$ then the $\PCOMs$'s evaluation binding would be
  broken.  Alternatively, if $\adv$ was able to provide two openings $\p{W}$ and
  $\p{\tilde{W}}$ for $y = \p{p}(x)$ then the unique opening property would be
  broken.
%
Hence the probability that $\adv$ breaks $\ur{1}$-property of $\PCOMs$ is
upper-bounded by $\epsbind(\secpar) + \epsop(\secpar)$. 
\qed

\end{proof}
}

\subsection{Computational special soundness}
\begin{lemma}
	\label{lem:sonicprot_ss}
	$\sonicprot$ is $(2, \multconstr + \linconstr + 1)$-computational special sound with security loss $\epss(\secpar)$ against
	algebraic adversaries with
	\[
	\epss(\secpar) \leq \epsid(\secpar) + \epsldlog(\secpar) \,,
	\]
	where $\epsid(\secpar)$ is a soundness error of the idealized verifier, and
	$\epsldlog(\secpar)$ is security of $(\dconst, \dconst)$-$\ldlog$ assumption.
\end{lemma}
\begin{proof}
	Similarly as in the case of $\plonk$, the main idea of the proof is to show that an
  adversary who breaks computational special soundness can be used to break a $\dlog$
  problem instance. The proof goes by game hops. Let $\tree$ be the tree produced by
  $\tdv$ by rewinding $\adv$. Note that since the tree branches after prover's $2$-nd
  message, the instance $\inp$, commitments
  $\gone{\p{r} (\chi, 1), \p{r} (\chi, y), \p{s} (\chi, y), \p{t} (\chi, y)}$, and
  challenge $y$ are the same. The tree branches after the $2$-nd message of the
  prover when the challenge $z$ is presented, thus tree $\tree$ is build using
  different values of $z$.
	%
	We consider the following games.
	
	\ncase{Game 0} In this game the adversary wins if all the transcripts it
	produced are acceptable by the ideal verifier,
	i.e.~$\vereq_{\inp, \zkproof}(X) = 0$, cf.~\cref{eq:ver_eq}, and none of
	commitments
	$\gone{\p{r} (\chi, 1), \p{r} (\chi, y), \p{s} (\chi, y), \p{t} (\chi, y)}$ use
	elements from a simulated proof, and the extractor fails to extract a valid
	witness out of the proof.
	
	\ncase{Probability that $\adv$ wins Game 0 is negligible} Probability of
	$\adv$ winning this game is $\epsid(\secpar)$ as the protocol $\sonicprot$,
	instantiated with the idealised verification equation, is perfectly
	knowledge sound except with negligible probability of the idealised verifier
	failure $\epsid(\secpar)$. Hence for a valid proof $\zkproof$ for a
	statement $\inp$ there exists a witness $\wit$, such that $\REL(\inp, \wit)$
	holds. Note that since the $\tdv$ produces $(\multconstr + \linconstr + 1)$
	acceptable transcripts for different challenges $z$. As noted in
	\cite{CCS:MBKM19} this assures that the correct witness is encoded in
	$\p{r} (X, Y)$. Hence $\extt$ can recreate polynomials' coefficients by
	interpolation and reveal the witness with probability $1$. Moreover, the
	probability that extraction fails in that case is upper-bounded by
	probability of an idealised verifier failing $\epsid(\secpar)$, which is
	negligible.
	
	\ncase{Game 1} In this game the adversary additionally wins if it produces a
	transcript in $\tree$ such that $\vereq_{\inp, \zkproof}(\chi) = 0$, but
	$\vereq_{\inp, \zkproof}(X) \neq 0$, and none of commitments
	$\gone{\p{r} (\chi, 1), \p{r} (\chi, y), \p{s} (\chi, y), \p{t} (\chi, y)}$
	use elements from a simulated proof.  The first condition means that the
	ideal verifier does not accept the proof, but the real verifier does.
	
	\ncase{Game 0 to Game 1} Assume the adversary wins in Game 1, but does not
	win in Game 0. We show that such adversary may be used to break an
	instance of a $\ldlog$ assumption. More precisely, let $\tdv$ be an
	algorithm that for relation $\REL$ and randomly picked
	$\srs \sample \kgen(\REL)$ produces a tree of acceptable transcripts such
	that the winning condition of the game holds. Let $\rdvdlog$ be a
	reduction that gets as input an
	$(\dconst, \dconst)$-ldlog instance
	$\gone{\chi^{-\dconst}, \ldots, \chi^{\dconst}}, \gtwo{\chi^{-\dconst},
		\ldots, \chi^{\dconst}}$ and is tasked to output $\chi$.
	
	The reduction $\rdvdlog$ proceeds as follows.
	\begin{enumerate}
  \item Pick a random $\alpha$ and compute
    $\gone{\alpha \chi^{- \dconst}, \ldots, \alpha \chi^{-1}, \alpha \chi,
      \ldots, \alpha \chi^{\dconst}}$,
    $\gtwo{\alpha \chi^{- \dconst}, \ldots, \alpha \chi^{-1}, \alpha \chi,
      \ldots, \alpha \chi^{\dconst}}$. Set a SRS $\srs$ to be the
    $(\dconst, \dconst)$-ldlog instance and its multiplication with $\alpha$ as
    computed above.
    % \hamid{Is this clear?}
  \item Build $\sonicprot$'s SRS in the updatable setting by answering $\adv$'s
    queries for SRS updates and setting the honest update of the SRS to be
    $\srs$. Let $\srs'$ be the finalised SRS.
		\item Let $(1, \tree)$ be the output returned by $\tdv$. Let $\inp$ be a
		relation proven in $\tree$.  Consider a transcript $\zkproof \in \tree$ such
		that $\vereq_{\inp, \zkproof}(X) \neq 0$, but
		$\vereq_{\inp, \zkproof}(\chi') = 0$. Since $\adv$ is algebraic, all group
		elements included in $\tree$ are extended by their representation as a
		combination of the input $\GRP_1$-elements. Hence, all coefficients of the
		verification equation polynomial $\vereq_{\inp, \zkproof}(X)$ are known.
		\item Find $\vereq_{\inp, \zkproof}(X)$ zero points and find $\chi'$ among
		them.
  \item Let $\chi_1, \ldots, \chi_\ell$ be the partial trapdoors of $\adv$'s SRS
    updates, extracted by the reduction from the update proofs given by $\adv$.
		\item Return  $\chi = \chi' (\chi_1 \chi_2 \ldots \chi_\ell)^{-1}$.
	\end{enumerate}
	Hence, the probability that the adversary wins Game 1 is upper-bounded by
	$\epsldlog(\secpar)$.
\end{proof}

\subsection{Trapdoor-less simulatability of Sonic}
\begin{lemma}
\label{lem:sonic_hvzk}
$\sonic$ is 2-programmable trapdoor-less simulatable.
\end{lemma}
\begin{proof}
  The simulator proceeds as follows.
  \begin{enumerate}
  \item Pick randomly vectors $\vec{a}$, $\vec{b}$ and set
    \begin{equation}
      \label{eq:ab_eq_c}
      \vec{c} = \vec{a} \cdot \vec{b}. 
    \end{equation}
  \item Pick randomisers $c_{\multconstr + 1}, \ldots, c_{\multconstr + 4}$,
    honestly compute polynomials $\p{r}(X, Y), \p{r'}(X, Y), \p{s}(X, Y)$ and
    pick randomly challenges $y$, $z$.
  \item Output commitment $\gone{r} \gets \com(\srs, \multconstr, \p{r} (X,
    1))$ and challenge $y$. 
  \item Compute
    \begin{align*}
      & a' = \p{r}(z, 1),\\
      & b' = \p{r}(z, y),\\
      & s' = \p{s}(z, y).
    \end{align*} 
  \item Pick polynomial $\p{t}(X, Y)$ such that
    \begin{align*}
      & \p{t} (X, y) = \p{r} (X, 1) (\p{r}(X, y) + \p{s} (X, y)) - \p{k} (Y)\\
      & \p{t} (0, y) = 0
    \end{align*}
  \item Output commitment $\gone{t} = \com (\srs, \dconst, \p{t} (X, y))$ and
    challenge $z$.
  \item Continue following the protocol.
  \end{enumerate}

  We note that the simulation is perfect. This comes since, except polynomial
  $\p{t} (X, Y)$ all polynomials are computed following the protocol. For
  polynomial $\p{t} (X, Y)$ we observe that in a case of both real and simulated
  proof the verifier only learns commitment $\gone{t} = \p{t} (\chi, y)$ and
  evaluation $t' = \p{t} (z, y)$. Since the simulator picks $\p{t} (X, Y)$ such
  that 
  \begin{align*}
      \p{t} (X, y) = \p{r} (X, 1) (\p{r}(X, y) + \p{s} (X, y)) - \p{k} (Y)
  \end{align*}
  Values of $\gone{t}$ are equal in both proofs.
  Furthermore, the simulator picks its polynomial such that $\p{t}(0, y) = 0$,
  hence it does not need the trapdoor to commit to it. (Note that the proof
  system's SRS does not allow to commit to polynomials which have non-zero
  constant term). \qed
\end{proof}
\begin{remark} 
  As noted in \cite{CCS:MBKM19}, $\sonic$ is statistically subversion-zero
  knowledge (Sub-ZK). As noted in \cite{AC:ABLZ17}, one way to achieve
  subversion zero knowledge is to utilise an extractor that extracts a SRS
  trapdoor from a SRS-generator. Unfortunately, a NIZK made subversion
  zero-knowledge by this approach cannot achieve perfect Sub-ZK as one has to
  count in the probability of extraction failure. However, with the simulation
  presented in \cref{lem:sonic_hvzk}, the trapdoor is not required for the
  simulator as it is able to simulate the execution of the protocol just by
  picking appropriate (honest) verifier's challenges. This result transfers to
  $\sonicprotfs$, where the simulator can program the random oracle to provide
  challenges that fits it.
\end{remark}

\subsection{From computational special soundness and unique response property to \COMMENT{forking
  }simulation extractability of $\sonicprotfs$}
Since \cref{lem:sonicprot_ur,lem:sonicprot_ss} hold, $\sonicprot$ is $\ur{1}$
and computational special sound. We now make use
of \cref{thm:se} and show that $\sonicprotfs$ is \COMMENT{ forking }simulation-extractable as defined in \cref{def:simext}.

\begin{corollary}[\COMMENT{Forking s}Simulation extractability of $\sonicprotfs$]
  \label{thm:sonicprotfs_se}
  Assume that $\sonicprot$ is $\ur{1}$ with security
  $\epsur(\secpar) = \epsbind(\secpar) + \epsop(\secpar)$ -- where
  $\epsbind (\secpar)$ is polynomial commitment's binding security, $\epsop$ is
  polynomial commitment unique opening security -- and computational special sound with
  security $\epss(\secpar)$. Let $\ro\colon \bin^* \to \bin^\secpar$ be a
  random oracle. Let $\advse$ be an adversary that can make up to $q$
  random oracle queries, and outputs an
  acceptable proof for $\sonicprotfs$ with probability at least $\accProb$. Then
  $\sonicprotfs$ is \COMMENT{forking }simulation-extractable with extraction error
  $\eta = \epsur(\secpar)$. The extraction probability $\extProb$ is at least
\[
		\extProb  \geq \frac{1}{q^{\multconstr + \linconstr}} (\accProb - \epsur(\secpar))^{\multconstr +
		\linconstr + 1} - \eps(\secpar).
	\]
	for some negligible $\eps(\secpar)$, $\multconstr$ and $\linconstr$ being,
  respectively, the number of multiplicative and linear constraints of the system.
\end{corollary}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
