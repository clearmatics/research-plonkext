\section{Concrete SNARKs Preliminaries}

\ourpar{Bilinear groups.}
A bilinear group generator $\pgen (\secparam)$ returns public parameters $ \pp =
(p, \GRP_1, \GRP_2, \GRP_T, \pair, \gone{1}, \gtwo{1})$, where $\GRP_1$,
$\GRP_2$, and $\GRP_T$ are additive cyclic groups of prime order $p = 2^{\Omega
  (\secpar)}$, $\gone{1}, \gtwo{1}$ are generators of $\GRP_1$, $\GRP_2$, resp.,
and $\pair: \GRP_1 \times \GRP_2 \to \GRP_T$ is a non-degenerate
$\ppt$-computable bilinear pairing. We assume the bilinear pairing to be Type-3,
i.e., that there is no efficient isomorphism from $\GRP_1$ to $\GRP_2$ or from
$\GRP_2$ to $\GRP_1$. We use the by now standard bracket notation, i.e., we
write $\bmap{a}{\gi}$ to denote $a \bmap{1}{\gi}$. %where $g_{\gi}$ is a fixed generator of $\GRP_{\gi}$. 
We denote $\pair (\gone{a}, \gtwo{b})$ as $\gone{a} \bullet
\gtwo{b}$. Thus, $\gone{a} \bullet \gtwo{b} = \gtar{a b}$. 
% We freely use the
% bracket notation with matrices, e.g., if $\vec{A} \vec{B} = \vec{C}$ then
% $\vec{A} \grpgi{\vec{B}} = \grpgi{\vec{C}}$ and $\gone{\vec{A}}\bullet
% \gtwo{\vec{B}} = \gtar{\vec{C}}$.\markulf{2.5}{do we use any matrices?} 
Since every algorithm $\adv$ takes as input
the public parameters we skip them when describing $\adv$'s input. Similarly, we
do not explicitly state that each protocol starts by running $\pgen$.

\subsection{Algebraic Group Model}
The algebraic group model (AGM) of Fuchsbauer, Kiltz, and Loss~\cite{C:FucKilLos18} lies somewhat between the
standard and generic bilinear group model. In the AGM it is assumed that an
adversary $\adv$ can output a group element $\gnone{y} \in \GRP$ if $\gnone{y}$ has
been computed by applying group operations to group elements given to $\adv$ as
input. It is further assumed, that $\adv$ knows how to ``build'' $\gnone{y}$ from
those elements. More precisely, the AGM requires that whenever $\adv(\gnone{\vec{x}})$
outputs a group element $\gnone{y}$ then it also outputs $\vec{c}$ such that
$\gnone{y} = \vec{c}^\top \cdot \gnone{\vec{x}}$. $\plonk$, $\sonic$ and $\marlin$
have been shown secure using the AGM. An adversary that works in the AGM is called
\emph{algebraic}.

\oursubsub{Ideal Verifier and Verification Equations.} Let
$(\SRScer, \prover, \verifier, \simulator)$ be a proof system.
% or a polynomial commitment
% scheme\hamid{might be unclear as we are defining polynomial commitments as
%   $(\kgen, \com, \open, \verify)$.}.
Observe that the $\SRScer$ algorithms provide an SRS which can be interpreted as a set
of group representation of polynomials evaluated at trapdoor elements. That is, for a
trapdoor $\chi$ the SRS contains $\gone{\p{p_1}(\chi), \ldots, \p{p_k}(\chi)}$, for
some polynomials $\p{p_1}(X), \ldots, \p{p_k}(X) \in \FF_p[X]$. The verifier
$\verifier$ accepts a proof $\zkproof$ for instance $\inp$ if (a set of) verification
equation $\vereq_{\inp, \zkproof}$ (which can also be interpreted as a polynomial in
$\FF_p[X]$ whose coefficients depend on messages sent by the prover) zeroes at
$\chi$. Following \cite{EPRINT:GabWilCio19} we call verifiers who check that
$\vereq_{\inp, \zkproof}(\chi) = 0$ \emph{real verifiers} as opposed to \emph{ideal
  verifiers} who accept only when $\vereq_{\inp, \zkproof}(X) = 0$. That is, while a
real verifier accepts when a polynomial \emph{evaluates} to zero, an ideal verifier
accepts only when the polynomial \emph{is} zero.

Although ideal verifiers are impractical, they are very useful in our
proofs. More precisely, we show that
%\begin{compactenum}
%\item 
the idealised verifier accepts an incorrect proof (what ``incorrect''
  means depends on the situation) with at most negligible probability (and in many
  cases---never);
%\item 
when the real verifier accepts, but not the idealised one, then a malicious
  prover can be used to break the underlying security assumption (in our case---a
  variant of $\dlog$.)
%\end{compactenum}

Analogously, idealised verifier can be defined for polynomial commitment schemes.

\subsection{Dlog Assumptions in Standard and Updatable Setting}
\label{dlog-upd}
\label{sec:udlog_assumptions}


\label{sec:dlog_assumptions}
\begin{definition}[$(q_1, q_2)\mhyph\dlog$ assumption]\label{def:dlog}
	Let $\adv$ be a $\ppt$ adversary that gets as input
  $\gone{1, \chi, \ldots, \chi^{q_1}}, \gtwo{1, \chi, \ldots, \chi^{q_2}}$, for
  some randomly picked $\chi \in \FF_p$, the assumption requires that $\adv$ cannot compute $\chi$. That is
	\[
		\condprob{\chi = \adv(\gone{1, \chi, \ldots, \chi^{q_1}}, \gtwo{1, \chi,
        \ldots, \chi^{q_2} })}{\chi \sample \FF_p} \leq \negl.
	\]
\end{definition}

 Since all our protocols and security notions are in the updatable setting, it is natural to define the dlog assumptions also in the updatable setting. That is, instead of being given a dlog challenge the adversary $\adv$ is given access to an update oracle as defined in~\cref{fig:upd}. The honestly generated SRS is set to be a dlog challenge and the update algorithm $\upd$ re-randomizing the challenge. We define this assumptions and show a reduction between the assumptions in the updatable and standard setting. 

Note that for clarity we here refer to the SRS by $\Ch$. Further, to avoid cluttering notation, we do not make the update proofs explicit. They are generated in the same manner as the proofs in~\cref{fig:upd-scheme}.
	
%The reduction $\reduction$ proceeds as follows: given the input dlog instance, $\reduction$ answers adversary's queries for the dlog updates and sets the honest update to be the input dlog instance. Once the dlog challenge in the updatable setting is finalized, it runs the adversary and obtains the answer $\chi'$. Let $\chi_1, \ldots, \chi_\ell$ be the partial discrete logarithms of dlog instances corresponding to the adversary's dlog updates. These values can be computed by $\reduction$ by extracting from the update proofs given by the adversary. $\reduction$ now returns  $\chi = \chi' (\chi_1 \chi_2 \ldots \chi_\ell)^{-1}$. The same argument holds for the $(q_1, q_2)\mhyph\ldlog$ assumption, ~\cref{def:ldlog}.

\begin{definition}[$(q_1, q_2)\mhyph\udlog$ assumption]\label{def:udlog}
	Let $\adv$ be a $\ppt$ adversary that gets oracle access to $\initU$ with internal algorithms $(\kgen, \upd, \verifyCRS)$, where $\kgen$ and $\upd$ are defined as follows:
	\begin{itemize}
	\item $\kgen(\secpar)$ samples $\chi \sample \FF_p$ and defines 
		$\Ch:=(\gone{1, \chi, \ldots,
			\chi^{q_1}}, \gtwo{1, \chi, \ldots, \chi^{q_2}
		})$.
	\item $\upd(\Ch, \{\rho_j \}_{j=1}^n)$ 
	parses $\Ch$ as $\left( \gone{\smallset{A_i}_{i = 0}^{q_1}},
	\gtwo{\smallset{B_i}_{i = 0}^{q_2}} \right)$, samples
	$\widetilde{\chi} \sample \FF_p$, and defines
	$\widetilde{\Ch} := 
	\left( \gone{\smallset{\widetilde{\chi}^i A_i}_{i = 0}^{q_1}},
	\gtwo{\smallset{\widetilde{\chi}^i B_i}_{i = 0}^{q_2}} \right)$.
	\end{itemize}
	Then
	$
	\prob{\bar{\chi} \gets \adv^{\initU}(\secpar)} \leq \negl,
	$
	where $\left( \gone{\smallset{\bar{\chi}^i}_{i = 0}^{q_1}},
	\gtwo{\smallset{\bar{\chi}^i}_{i = 0}^{q_2}} \right)$ is the final $\Ch$.
\end{definition}



\begin{remark}[Single adversarial updates after an honest setup.]\label{rem:upd}
	As an alternative to the updatable setting defined in~\cref{fig:upd}, one can consider a slightly different model of setup, where the adversary is given an initial honestly-generated SRS and is then allowed to perform a malicious update in one-shot fashion.
	Groth
	et al.\ show in~\cite{C:GKMMM18} that the two definitions are equivalent for polynomial commitment based SNARKs. We use this simpler definition in our reductions.
\end{remark}


We show a reduction from $(q_1, q_2)\mhyph\dlog$ assumption to its variant in the updatable setting (with single adversarial update). 
%We omit showing the reduction $(q_1, q_2)\mhyph\ldlog \Rightarrow (q_1, q_2)\mhyph\uldlog$ as it can be done similarly in a straightforward manner.
\begin{lemma}
	$(q_1, q_2)\mhyph\dlog \Rightarrow (q_1, q_2)\mhyph\udlog$.
	\end{lemma}
\begin{proof}
	We show a reduction $\reduction$ that uses an adversary $\adv$ that breaks $(q_1, q_2)\mhyph\udlog$ to break $(q_1, q_2)\mhyph\dlog$. Specifically, $\reduction$ proceeds as follows: given a dlog instance $\Ch$ as input, it sets $\Ch$ to be the initial (honestly generated) challenge and runs $\adv$. After $\adv$ performs its update and finalizes the dlog challenge it returns the answer $\chi'$. Let $\chi_\adv$ be the trapdoor contribution of adversary $\adv$ in its update. Reduction $\reduction$ can extract this value from the update proof of $\adv$. $\reduction$ now returns $\chi = \chi' \chi_\adv^{-1}$ as the discrete logarithm of the original challenge $\Ch$.\qed
	\end{proof}

	% \markulf{2.5}{Old numbers: To be able to extract a witness from, say, an execution of $\plonkprot$ we need at least $(3 \numberofconstrains + 1)$ valid proofs (where $\numberofconstrains$ is the number of constrains), $(\numberofconstrains+ 1)$ for $\sonicprot$, and $\numberofconstrains + 4$ for $\marlinprot$.}
	% \michals{2.5}{Should be $\plonkprot$ we need at least $(3 \numberofconstrains + 6)$ valid proofs (where $\numberofconstrains$ is the number of constrains), $(\numberofconstrains + 1)$ for $\sonicprot$ (if we count ), and $\numberofconstrains + 4$ for $\marlinprot$}

  \oursubsub{Generalized Forking Lemma}
Although dubbed ``general'', the forking lemma of~\cite{CCS:BelNev06} is not general enough for our purpose as it is useful only for protocols where a witness can be extracted from just two transcripts. To be able to extract a witness from, say, an execution of $\plonkprot$ we need at least $(3 \numberofconstrains + 6)$ valid proofs (where $\numberofconstrains$ is the number of constrains), $(\numberofconstrains + 1)$ for $\sonicprot$, and $2 \numberofconstrains + 3$ for $\marlinprot$.
% \hamid{2.5}{Numbers are incorrect! Maybe $(3 \numberofconstrains + 6)$ for Plonk, $(\numberofconstrains + \linconstr+ 1)$ for Sonic and $(\numberofconstrains+ 3)$ for Marlin? }
% \michals{2.5}{$\multconstr + \linconstr = \noofc$}
 Here we use a result by Attema et
al.~\cite{EPRINT:AttFehKlo21short}\footnote{An earlier versions had its own forking lemma generalization. Attema et al.\ has a better bound.}  which lower-bounds the probability of generating a tree of accepting transcripts $\tree$. We restate their Proposition 2 in our notation:

  \begin{lemma}[Run Time and Success Probability]\label{lem:attema}
	Let $N = n_1 \cdot \cdots \cdot n_\mu$ and $p = 2^{\Omega(\secpar)}$. Let $\epserr(\secpar) = 1 - \prod_{i=1}^{\mu}\left(1 - \frac{n_i - 1}{p}\right)$.
	Assume adversary $\adv$ that makes up to $q$ random
	oracle queries and outputs an acceptable proof with probability at least
	$\accProb$. There exists a tree building algorithm $\tdv$ for $(n_1, \ldots, n_\mu)$-trees that %utilizes the extractor $\zdv_1$ in~\cref{3 \noofc + 5ema-ext} and 
	succeeds in building a
	tree of accepting transcripts in expected
	running time $N + q (N - 1)$ with probability at least
	\[
	\frac{\accProb - (q + 1) \epserr (\secpar)}{1 - \epserr (\secpar)}.
	\]
	\end{lemma}

	\iffalse
\begin{figure}[t]
	\centering
	\fbox{\parbox{\textwidth}{
			\begin{enumerate}
				\item Run $\zdv_{m + 1}$ as follows to obtain $(\vec{\zkproof}, \tzkproof_1, v)$: relay the $q + \mu$ queries to the random oracle and record all query-response pairs. Set 				$h \gets \zkproof[m].\ch $, and let $c_h$ be the response to query $i$. 
				\item If $v = 0$, abort with output $v = 0$. 
				\item Else, repeat
				\begin{itemize}
					\item sample $c'_h \in C \setminus \smallset{c_h}$ (without replacement);
					\item run $\zdv_{m + 1}$ as follows to obtain $(\vec{\zkproof'}, \tzkproof', v')$, aborting right after the initial run of $\adv$ if $\zkproof'[m].\ch  \neq \zkproof[m].\ch$: answer the query to $h$ with $c'_h$, while answering all other queries consistently if the query was performed by $\zdv_{m + 1}$ already on a previous run and with a fresh random value in $C$ otherwise; 
				\end{itemize}
				until either $n_m - 1$ additional challenges $c'_h$ with $v' = 1$ and $\zkproof'[m].\ch  = \zkproof[m]$ have been found or until all challenges $c'_h \in C$ have been tried. 
				\item In the former case, output $\vec{\zkproof}$, the $n_m$ accepting
				$(1, \ldots, 1, n_{m + 1}, \ldots, n_\mu)$-trees $\tzkproof_1, \ldots, \tzkproof_{n_m}$, and
				$v \gets 1$; in the latter case, output $v \gets 0$.
			\end{enumerate}
	}}
	\caption{Extractor $\zdv_m$ from Attema et al.~\cite{EPRINT:AttFehKlo21short}. Here $\vec{\zkproof}$ is an index vector that contains all random oracle queries made by the prover for the output proof; that is, for prover's messages $\vec{a} = a_1, \ldots, a_{\mu + 1}$, $\zkproof[1].\ch = (\inp, a_1), \ldots, \zkproof[{\mu}].\ch = (\inp, a_1, \ldots, a_\mu)$.  $\tzkproof$ is a proof transcript that contains both prover's messages and random oracle responses, that is $\tzkproof = (a_1, (\inp, a_1), a_2, (\inp, a_1, a_2), \ldots)$. Finally, $v$ is the verification bit, that is $v = \verifier (\srs, \inp, \tzkproof)$. }
	\label{fig:Attema-ext}
\end{figure} 
\fi

\oursubsub{Opening Uniqueness of Batched Polynomial Commitment Openings}
%We say that $\PCOM$ has the unique opening property if the following holds:
To show the unique response property required by our main theorem we show that the polynomial commitment schemes employed by concrete proof systems have unique openings, which, intuitively, assures that there is only one
valid opening for a given committed polynomial and evaluation point:

\begin{definition}[Unique opening property]
	Let $m \in \NN$ be the number of committed polynomials, $l \in \NN$ number of evaluation points, $\vec{c} \in \GRP^m$ be the commitments, $\vec{z} \in \FF_p^l$ be the arguments the polynomials are evaluated at, $K_j$ set of indices of polynomials which are evaluated at $z_j$, $\vec{s_{i}}$ vector of evaluations of $\p{f_i}$,, and $\vec{o_j}, \vec{o'_j} \in \FF_p^{K_j}$ be the commitment openings. Then for every $\ppt$ adversary $\adv$
	  \[
		  \condprob{
			  \begin{matrix}
					\verify(\srs, \vec{c}, \vec{z}, \vec{s}, \vec{o}) = 1,  \\ 
					\verify(\srs, \vec{c}, \vec{z}, \vec{s}, \vec{o'}) = 1, \\
				   \vec{o} \neq \vec{o'}
			  \end{matrix}
		  }{
			  \begin{matrix}
  %				& \srs \gets \kgen(\secparam, \maxdeg),\\
					(\vec{c}, \vec{z}, \vec{s}, \vec{o}, \vec{o'}) \gets \adv^{\initU}(\maxdeg)
			  \end{matrix}
		  }\leq \negl\,.
	  \]
\end{definition}

We show that the polynomial commitment schemes of $\plonk$, $\sonic$, and $\marlin$ satisfy this requirement in \cref{sec:uop}.

\begin{remark}
\cref{fig:pcomp}, cf.~\cref{sec:uop}, presents efficient variants of KZG~\cite{AC:KatZavGol10} polynomial commitment schemes used in \plonk{}, \sonic{} and \marlin{} that support batched verification. Algorithms $\com$, $\open$, $\verify$ take vectors as input and receive an additional arbitrary auxiliary string. This adversarially chosen string only provides additional context for the computation of challenges and allows reconstruction of proof transcripts $\tzkproof[0..i]$ for batch challenge computations. We treat auxiliary input implicitly in the definition above.
\end{remark}