% !TEX root = main.tex
% !TEX spellcheck = en-US


\section{Non-Malleability of Plonk} 
\label{sec:plonk}
In this section, we show that $\plonkprotfs$ is \COMMENT{forking }simulation-extractable. Towards this end, we first use the unique opening property to show that
$\plonkprot$ has the $\ur{2}$ property,
cf.~\cref{lem:plonkprot_ur}.
Next, we show that $\plonkprot$ is computational special sound. That is, given a
number of accepting transcripts whose messages match on the first $5$ messages of the
protocol, we can either extract a witness for the proven statement or use
one of the transcripts to break the $\dlog$ assumption. This result is shown in
the AGM, cf.~\cref{lem:plonkprot_ss}. We then show that $\plonkprot$ is trapdoor-less simulatable ZK in the AGM, cf.~\cref{lem:plonk_hvzk}.

Given computational special soundness, $\ur{2}$ and trapdoor-less simulatability of $\plonkprot$, we invoke \cref{thm:se} and conclude that $\plonkprot_\fs$ is \COMMENT{forking }simulation-extractable.
%\hamid{19.1}{To conclude USE of Plonk, I think we should rely on TLS property too!}
%Due to page limit, we omit description of \plonk{} here and refer to
%\cref{sec:plonk_explained}.
%Unfortunately, we also have to Message some of the
% proofs to the Supplementary Materials as well, cf.~\cref{sec:plonk_supp_mat}

\newcommand{\vql}{\vec{q_{L}}}
\newcommand{\vqr}{\vec{q_{R}}}
\newcommand{\vqm}{\vec{q_{M}}}
\newcommand{\vqo}{\vec{q_{O}}}
\newcommand{\vx}{\vec{x}}
\newcommand{\vqc}{\vec{q_{C}}}

\subsection{Plonk protocol description}
\label{sec:plonk_explained}
\oursubsub{The constraint system}
Assume $\CRKT$ is a fan-in two arithmetic circuit,
which fan-out is unlimited and has $\numberofconstrains$ gates and $\noofw$ wires
($\numberofconstrains \leq \noofw \leq 2\numberofconstrains$). \plonk's constraint
system is defined as follows:
\begin{itemize}
\item Let $\vec{V} = (\va, \vb, \vc)$, where $\va, \vb, \vc
  \in \range{1}{\noofw}^\numberofconstrains$. Entries $\va_i, \vb_i, \vc_i$ represent indices of left,
  right and output wires of circuits $i$-th gate.
\item Vectors $\vec{Q} = (\vql, \vqr, \vqo, \vqm, \vqc) \in
  (\FF^\numberofconstrains)^5$ are called \emph{selector vectors}:
  \begin{itemize}
  \item If the $i$-th gate is a multiplicative gate then $\vql_i = \vqr_i = 0$,
    $\vqm_i = 1$, and $\vqo_i = -1$. 
  \item If the $i$-th gate is an addition gate then $\vql_i = \vqr_i  = 1$, $\vqm_i =
    0$, and $\vqo_i = -1$. 
  \item $\vqc_i = 0$ always. 
  \end{itemize}
\end{itemize}

We say that vector $\vx \in \FF^\noofw$ satisfies constraint system if for all $i
\in \range{1}{\numberofconstrains}$
\[
  \vql_i \cdot \vx_{\va_i} + \vqr_i \cdot \vx_{\vb_i} + \vqo \cdot \vx_{\vc_i} +
  \vqm_i \cdot (\vx_{\va_i} \vx_{\vb_i}) + \vqc_i = 0. 
\]

\oursubsub{Algorithms rolled out}
\label{sec:plonk_explained}
\plonk{} argument system is universal. That is, it allows to verify computation
of any arithmetic circuit which has no more than $\numberofconstrains$
gates using a single SRS. However, to make computation efficient, for each
circuit there is allowed a preprocessing phase which extends the SRS with
circuit-related polynomial evaluations.

For the sake of simplicity of the security reductions presented in this paper, we
include in the SRS only these elements that cannot be computed without knowing
the secret trapdoor $\chi$. The rest of the SRS---the preprocessed input---can
be computed using these SRS elements thus we leave them to be computed by the
prover, verifier, and simulator.

\ourpar{$\plonk$ SRS generating algorithm $\kgen(\REL)$:}
The SRS generating algorithm picks at random $\chi \sample \FF_p$, computes
and outputs
\[
	\srs = \left(\gone{\smallset{\chi^i}_{i = 0}^{\numberofconstrains + 2}},
	\gtwo{\chi} \right).
\]

\ourpar{Preprocessing:}
Let $H = \smallset{\omega^i}_{i = 1}^{\numberofconstrains }$ be a
(multiplicative) $\numberofconstrains$-element subgroup of a field $\FF$
compound of $\numberofconstrains$-th roots of unity in $\FF$. Let $\lag_i(X)$ be
the $i$-th element of an $\numberofconstrains$-elements Lagrange basis. During
the preprocessing phase polynomials $\p{S_{id j}}, \p{S_{\sigma j}}$, for
$\p{j} \in \range{1}{3}$, are computed:
\begin{equation*}
  \begin{aligned}
    \p{S_{id 1}}(X) & = X,\vphantom{\sum_{i = 1}^{\noofc} \sigma(i) \lag_i(X),}\\
    \p{S_{id 2}}(X) & = k_1 \cdot X,\vphantom{\sum_{i = 1}^{\noofc} \sigma(i) \lag_i(X),}\\
    \p{S_{id 3}}(X) & = k_2 \cdot X,\vphantom{\sum_{i = 1}^{\noofc} \sigma(i) \lag_i(X),}
  \end{aligned}
  \qquad
\begin{aligned}
  \p{S_{\sigma 1}}(X) & = \sum_{i = 1}^{\noofc} \sigma(i) \lag_i(X),\\
  \p{S_{\sigma 2}}(X) & = \sum_{i = 1}^{\noofc}
  \sigma(\noofc + i) \lag_i(X),\\
  \p{S_{\sigma 3}}(X) & =\sum_{i = 1}^{\noofc} \sigma(2 \noofc + i) \lag_i(X).
\end{aligned}
\end{equation*}
Coefficients $k_1$, $k_2$ are such that $H, k_1 \cdot H, k_2 \cdot H$ are
different cosets of $\FF^*$, thus they define $3 \cdot \noofc$
different elements. \cite{EPRINT:GabWilCio19} notes that it is enough to set
$k_1$ to a quadratic residue and $k_2$ to a quadratic non-residue.

Furthermore, we define polynomials $\p{q_L}, \p{q_R}, \p{q_O}, \p{q_M}, \p{q_C}$
such that
\begin{equation*}
  \begin{aligned}
  \p{q_L}(X) & = \sum_{i = 1}^{\noofc} \vql_i \lag_i(X), \\
  \p{q_R}(X) & = \sum_{i = 1}^{\noofc} \vqr_i \lag_i(X), \\
  \p{q_M}(X) & = \sum_{i = 1}^{\noofc} \vqm_i \lag_i(X),
\end{aligned}
\qquad
\begin{aligned}
  \p{q_O}(X) & = \sum_{i = 1}^{\noofc} \vqo_i \lag_i(X), \\
  \p{q_C}(X) & = \sum_{i = 1}^{\noofc} \vqc_i \lag_i(X). \\
  \vphantom{\p{q_M}(X)  = \sum_{i = 1}^{\noofc} \vqm_i \lag_i(X),}
\end{aligned}
\end{equation*}

\ourpar{Proving statements in $\plonkprotfs$} We show how prover's algorithm
$\prover(\srs, \inp, \wit = (\wit_i)_{i \in \range{1}{3 \cdot \noofc}})$ operates for
the Fiat--Shamir transformed version of Plonk.
\begin{description}
\item[Message 1] Sample $b_1, \ldots, b_9 \sample \FF_p$; compute
  $\p{a}(X), \p{b}(X), \p{c}(X)$ as
	\begin{align*}
		\p{a}(X) &= (b_1 X + b_2)\p{Z_H}(X) + \sum_{i = 1}^{\noofc} \wit_i \lag_i(X) \\
		\p{b}(X) &= (b_3 X + b_4)\p{Z_H}(X) + \sum_{i = 1}^{\noofc} \wit_{\noofc + i} \lag_i(X) \\
		\p{c}(X) &= (b_5 X + b_6)\p{Z_H}(X) + \sum_{i = 1}^{\noofc} \wit_{2 \cdot \noofc + i} \lag_i(X) 
	\end{align*}
	Output polynomial commitments $\gone{\p{a}(\chi), \p{b}(\chi), \p{c}(\chi)}$.  
	
\item[Message 2] Compute challenges $\beta, \gamma \in \FF_p$ by querying random oracle
  on partial proof, that is,
	\[
		\beta = \ro(\zkproof[0..1], 0)\,, \qquad \gamma = \ro(\zkproof[0..1], 1)\,.
	\]
  
	Compute permutation polynomial $\p{z}(X)$
	\begin{multline*}
		\p{z}(X) = (b_7 X^2 + b_8 X + b_9)\p{Z_H}(X) + \lag_1(X) + \\
    + \sum_{i = 1}^{\noofc - 1} \left(\lag_{i + 1} (X) \prod_{j = 1}^{i} \frac{
        (\wit_j +\beta \omega^{j - 1} + \gamma)(\wit_{\noofc + j} + \beta k_1
        \omega^{j - 1} + \gamma)(\wit_{2 \noofc + j} +\beta k_2 \omega^{j- 1} +
        \gamma)} {(\wit_j+\sigma(j) \beta + \gamma)(\wit_{\noofc + j} + \sigma(\noofc
        + j)\beta + \gamma)(\wit_{2 \noofc + j} + \sigma(2 \noofc + j)\beta +
        \gamma)}\right)
	\end{multline*}
	Output polynomial commitment $\gone{\p{z}(\chi)}$
		
\item[Message 3] Compute the challenge $\alpha = \ro(\zkproof[0..2])$, compute the quotient
  polynomial
	\begin{align*}
    & \p{t}(X)  = \\
    & (\p{a}(X) \p{b}(X) \selmulti(X) + \p{a}(X) \selleft(X) + 
      \p{b}(X)\selright(X) + \p{c}(X)\seloutput(X) + \pubinppoly(X) + \selconst(X)) 
      \frac{1}{\p{Z_H}(X)} +\\
    & + ((\p{a}(X) + \beta X + \gamma) (\p{b}(X) + \beta k_1 X + \gamma)(\p{c}(X) 
      + \beta k_2 X + \gamma)\p{z}(X)) \frac{\alpha}{\p{Z_H}(X)} \\
    & - (\p{a}(X) + \beta \p{S_{\sigma 1}}(X) + \gamma)(\p{b}(X) + \beta 
      \p{S_{\sigma 2}}(X) + \gamma)(\p{c}(X) + \beta \p{S_{\sigma 3}}(X) + 
      \gamma)\p{z}(X \omega))  \frac{\alpha}{\p{Z_H}(X)} \\
    & + (\p{z}(X) - 1) \lag_1(X) \frac{\alpha^2}{\p{Z_H}(X)}
	\end{align*}
	Split $\p{t}(X)$ into degree less then $\noofc$ polynomials
  $\p{t_{lo}}(X), \p{t_{mid}}(X), \p{t_{hi}}(X)$, such that
	\[
		\p{t}(X) = \p{t_{lo}}(X) + X^{\noofc} \p{t_{mid}}(X) + X^{2 \noofc}
    \p{t_{hi}}(X)\,.
	\]
	Output $\gone{\p{t_{lo}}(\chi), \p{t_{mid}}(\chi), \p{t_{hi}}(\chi)}$.
	
\item[Message 4] Get the challenge $\chz \in \FF_p$, $\chz = \ro(\zkproof[0..3])$.
  Compute opening evaluations
	\begin{align*}
    \p{a}(\chz), \p{b}(\chz), \p{c}(\chz), \p{S_{\sigma 1}}(\chz), \p{S_{\sigma 2}}(\chz), \p{t}(\chz), \p{z}(\chz \omega),
	\end{align*}
	Compute the linearisation polynomial
	\[
		\p{r}(X) =
		\begin{aligned}
      & \p{a}(\chz) \p{b}(\chz) \selmulti(X) + \p{a}(\chz) \selleft(X) + \p{b}(\chz) \selright(X) + \p{c}(\chz) \seloutput(X) + \selconst(X) \\
      & + \alpha \cdot \left( (\p{a}(\chz) + \beta \chz + \gamma) (\p{b}(\chz) + \beta k_1 \chz + \gamma)(\p{c}(\chz) + \beta k_2 \chz + \gamma) \cdot \p{z}(X)\right) \\
      & - \alpha \cdot \left( (\p{a}(\chz) + \beta \p{S_{\sigma 1}}(\chz) + \gamma) (\p{b}(\chz) + \beta \p{S_{\sigma 2}}(\chz) + \gamma)\beta \p{z}(\chz\omega) \cdot \p{S_{\sigma 3}}(X)\right) \\
      & + \alpha^2 \cdot \lag_1(\chz) \cdot \p{z}(X)
		\end{aligned}
	\]
	Output
  $\p{a}(\chz), \p{b}(\chz), \p{c}(\chz), \p{S_{\sigma 1}}(\chz), \p{S_{\sigma
      2}}(\chz), \p{t}(\chz), \p{z}(\chz \omega), \p{r}(\chz).$
	
\item[Message 5] Compute the opening challenge $v \in \FF_p$,
  $v = \ro(\zkproof[0..4])$.  Compute the openings for the polynomial commitment
  scheme
	\begin{align*}
	& \p{W_\chz}(X) = \frac{1}{X - \chz} \left(
   \begin{aligned}
     & \p{t_{lo}}(X) + \chz^\noofc \p{t_{mid}}(X) + \chz^{2 \noofc} \p{t_{hi}}(X) - \p{t}(\chz)\\
     & + v(\p{r}(X) - \p{r}(\chz)) \\
     & + v^2 (\p{a}(X) - \p{a}(\chz))\\
     & + v^3 (\p{b}(X) - \p{b}(\chz))\\
     & + v^4 (\p{c}(X) - \p{c}(\chz))\\
     & + v^5 (\p{S_{\sigma 1}}(X) - \p{S_{\sigma 1}}(\chz))\\
     & + v^6 (\p{S_{\sigma 2}}(X) - \p{S_{\sigma 2}}(\chz))
   \end{aligned}
       \right)\\
    & \p{W_{\chz \omega}}(X) = \frac{\p{z}(X) - \p{z}(\chz \omega)}{X - \chz \omega}
  \end{align*}
	Output $\gone{\p{W_{\chz}}(\chi), \p{W_{\chz \omega}}(\chi)}$.
\end{description}

\ncase{$\plonk$ verifier $\verifier(\srs, \inp, \zkproof)$}\ \newline
The \plonk{} verifier works as follows
\begin{enumerate}
	\item Validate all obtained group elements.
	\item Validate all obtained field elements.
	\item Validate the instance
      $\inp = \smallset{\wit_i}_{i = 1}^\instsize$.
	\item Compute challenges $\beta, \gamma, \alpha, \chz, v,
      u$ from the transcript.
	\item Compute zero polynomial evaluation
      $\p{Z_H} (\chz) =\chz^\noofc - 1$.
	\item Compute Lagrange polynomial evaluation
      $\lag_1 (\chz) = \frac{\chz^\noofc -1}{\noofc (\chz - 1)}$.
	\item Compute public input polynomial evaluation
      $\pubinppoly (\chz) = \sum_{i \in \range{1}{\instsize}} \wit_i
      \lag_i(\chz)$.
	\item Compute quotient polynomials evaluations
	\begin{multline*}
    \p{t} (\chz) = \frac{1}{\p{Z_H}(\chz)} \Big(
    \p{r} (\chz) + \pubinppoly(\chz) - (\p{a}(\chz) + \beta \p{S_{\sigma 1}}(\chz) + \gamma) (\p{b}(\chz) + \beta \p{S_{\sigma 2}}(\chz) + \gamma) \\
    (\p{c}(\chz) + \gamma)\p{z}(\chz \omega) \alpha - \lag_1 (\chz) \alpha^2
    \Big) \,.
	\end{multline*}
	\item Compute batched polynomial commitment
	$\gone{D} = v \gone{r} + u \gone {z}$ that is
	\begin{align*}
		\gone{D} & = v
		\left(
		\begin{aligned}
          & \p{a}(\chz)\p{b}(\chz) \cdot \gone{\selmulti} + \p{a}(\chz)  \gone{\selleft} + \p{b}  \gone{\selright} + \p{c}  \gone{\seloutput} + \\
          & + (	(\p{a}(\chz) + \beta \chz + \gamma) (\p{b}(\chz) + \beta k_1 \chz + \gamma) (\p{c} + \beta k_2 \chz + \gamma) \alpha  + \lag_1(\chz) \alpha^2)  + \\
			% &   \\
          & - (\p{a}(\chz) + \beta \p{S_{\sigma 1}}(\chz) + \gamma) (\p{b}(\chz)
          + \beta \p{S_{\sigma 2}}(\chz) + \gamma) \alpha \beta \p{z}(\chz
          \omega) \gone{\p{S_{\sigma 3}}(\chi)})
		\end{aligned}
		\right) + \\
		& + u \gone{\p{z}(\chi)}\,.
	\end{align*}
	\item Computes full batched polynomial commitment $\gone{F}$:
	\begin{align*}
      \gone{F} & = \left(\gone{\p{t_{lo}}(\chi)} + \chz^\noofc \gone{\p{t_{mid}}(\chi)} + \chz^{2 \noofc} \gone{\p{t_{hi}}(\chi)}\right) + u \gone{\p{z}(\chi)} + \\
               & + v
                 \left(
		\begin{aligned}
			& \p{a}(\chz)\p{b}(\chz) \cdot \gone{\selmulti} + \p{a}(\chz)  \gone{\selleft} + \p{b}(\chz)   \gone{\selright} + \p{c}(\chz)  \gone{\seloutput} + \\
			& + (	(\p{a}(\chz) + \beta \chz + \gamma) (\p{b}(\chz) + \beta k_1 \chz + \gamma) (\p{c}(\chz)  + \beta k_2 \chz + \gamma) \alpha  + \lag_1(\chz) \alpha^2)  + \\
			% &   \\
			& - (\p{a}(\chz) + \beta \p{S_{\sigma 1}}(\chz) + \gamma) (\p{b}(\chz) + \beta \p{S_{\sigma 2}}(\chz) + \gamma) \alpha  \beta \p{z}(\chz \omega) \gone{\p{S_{\sigma 3}}(\chi)})
		\end{aligned}
		\right) \\
		& + v^2 \gone{\p{a}(\chi)} + v^3 \gone{\p{b}(\chi)} + v^4 \gone{\p{c}(\chi)} + v^5 \gone{\p{S_{\sigma 1}(\chi)}} + v^6 \gone{\p{S_{\sigma 2}}(\chi)}\,.
	\end{align*}
	\item Compute group-encoded batch evaluation $\gone{E}$
	\begin{align*}
		\gone{E}  = \frac{1}{\p{Z_H}(\chz)} & \gone{
		\begin{aligned}
			& \p{r}(\chz) + \pubinppoly(\chz) +  \alpha^2  \lag_1 (\chz) + \\
			& - \alpha \left( (\p{a}(\chz) + \beta \p{S_{\sigma 1}} (\chz) + \gamma) (\p{b}(\chz) + \beta \p{S_{\sigma 2}} (\chz) + \gamma) (\p{c}(\chz) + \gamma) \p{z}(\chz \omega) \right)
		\end{aligned}
           }\\
      + & \gone{v \p{r}(\chz) + v^2 \p{a}(\chz) + v^3 \p{b}(\chz) + v^4 \p{c}(\chz) + v^5 \p{S_{\sigma 1}}(\chz) + v^6 \p{S_{\sigma 2}}(\chz) + u \p{z}(\chz \omega) }\,.
	\end{align*}
\item Check whether the verification
 % $\vereq_\zkproof(\chi)$
  equation holds
	\begin{multline}
		\label{eq:ver_eq}
		\left( \gone{\p{W_{\chz}}(\chi)} + u \cdot \gone{\p{W_{\chz
                \omega}}(\chi)} \right) \bullet
		\gtwo{\chi} - %\\
		\left( \chz \cdot \gone{\p{W_{\chz}}(\chi)} + u \chz \omega \cdot
          \gone{\p{W_{\chz \omega}}(\chi)} + \gone{F} - \gone{E} \right) \bullet
        \gtwo{1} = 0\,.
	\end{multline}
  The verification equation is a batched version of the verification equation
  from \cite{AC:KatZavGol10} which allows the verifier to check openings of
  multiple polynomials in two points (instead of checking an opening of a single
  polynomial at one point).
\end{enumerate}

\ncase{$\plonk$ simulator $\simulator_\chi(\srs, \td= \chi, \inp)$}\ \newline
The \plonk{} simulator proceeds as an honest prover would, except:
\begin{enumerate}
  \item In the first message, it sets $\wit = (\wit_i)_{i \in \range{1}{3 \noofc}}
    = \vec{0}$, and at random picks $b_1, \ldots, b_9$. Then it proceeds with
    that all-zero witness.
  \item In prover's $3$-rd message, it computes polynomial $\pt(X)$ honestly, however uses
    trapdoor $\chi$ to compute commitments
    $\p{t_{lo}}(\chi), \p{t_{mid}}(\chi), \p{t_{hi}}(\chi)$.
  \end{enumerate}

\hamid{24.3}{The following proof is for the non-batched version of Plonk. Maybe we should say this explicitly somewhere!}
 
\subsection{Unique response property}
\begin{lemma}
	\label{lem:plonkprot_ur}
	Let $\PCOMp$ be a polynomial commitment that is $\epsbind(\secpar)$-binding and has unique opening
	property with loss $\epsop(\secpar)$, let $\plonkprotfs$ be $\epss$-sound and
		$(\noofc + 2, 1)$-$\udlog$ problem be $\epsdlog (\secpar)$ hard. Then $\plonkprotfs$ is $\ur{2}$ against algebraic adversaries with security loss $\epsdlog(\secpar) + \epss (\secpar) + 11 \cdot \epsbind (\secpar) + 9 \cdot \epsop(\secpar)$.
\end{lemma}

\begin{proof}
	Let $\adv$ be an algebraic adversary tasked to break the $\ur{2}$-ness of
	$\plonkprotfs$. We show that the first 2 prover's messages determine, along with
	the verifiers challenges, the rest of it.  This is done by game hops. In the games,
	the adversary outputs two proofs $\zkproof^0$ and $\zkproof^1$ for the same statement.
	To distinguish polynomials and commitments which an honest prover sends in the
	proof from the polynomials and commitments computed by the adversary we write the
	latter using indices $0$ and $1$ (two indices as we have two transcripts), e.g.~to
	describe the quotient polynomial provided by the adversary we write $\p{t}^0$ and
	$\p{t}^1$ instead of $\p{t}$ as in the description of the protocol.

\ngame{0} In this game, the adversary wins if it provides two different transcripts that match on the first two messages of the proof.

\ngame{1} In this game, the adversary additionally wins if it provides two different transcripts that match on the first three messages of the proof.

\ncase{Game 0 to Game 1} In its $3$-rd message the adversary computes the
quotient polynomial $\pt(X)$ and outputs its commitment that compounds of three separate commitments $\gone{\p{t_{lo}}(\chi), \p{t_{mid}}(\chi), \p{t_{hi}}(\chi)}$. Let $\gone{\p{t^0_{lo}}(\chi), \p{t^0_{mid}}(\chi), \p{t^0_{hi}}(\chi)}$ be the commitments output by the adversary in one transcript, and $\gone{\p{t^1_{lo}}(\chi), \p{t^1_{mid}}(\chi), \p{t^1_{hi}}(\chi)}$ the commitments output in the other.
%
Since the commitment scheme is deterministic, the adversary cannot come up with two different valid commitments for the same polynomial except probability $\epsbind (\secpar)$. Without loss of generality, let $\gone{\p{t^0_{lo}}(\chi), \p{t^0_{mid}}(\chi), \p{t^0_{hi}}(\chi)}$ be the invalid commitments to incorrect polynomials (i.e., different from split polynomials of $\pt(X)$) provided by the adversary.  If the adversary can later open any of these commitments $\gone{\p{t^0_{\star}}(\chi)}$ as if $\p{t^0_{\star}} = \p{t_{\star}}$ for any $\star \in \{\p{lo, mid, hi}\}$, it can break the evaluation binding property, which by assumption is upper-bounded by $\epsbind(\secpar)$.

If the adversary picks two different polynomials: $\p{t^0}(X)$, which commitment is $\gone{\p{t^0_{lo}}(\chi), \p{t^0_{mid}}(\chi), \p{t^0_{hi}}(\chi)}$, and $\p{t^1}(X)$ which commitment is $\gone{\p{t^1_{lo}}(\chi), \p{t^1_{mid}}(\chi), \p{t^1_{hi}}(\chi)}$, then one of them has to be computed incorrectly or the adversary can be used to break the udlog assumption if $\gone{\p{t^0_{lo}}(\chi), \p{t^0_{mid}}(\chi), \p{t^0_{hi}}(\chi)} = \gone{\p{t^1_{lo}}(\chi), \p{t^1_{mid}}(\chi), \p{t^1_{hi}}(\chi)}$.

More precisely, assume that the adversary is able to output a pair of commitments as above with probability $\eps$. We show that there exists a reduction $\rdv$ that takes as input $\udlog$ challenge $\Ch$ and breaks it with probability at least $\eps$ as well. To that end, the reduction runs $\adv$ internally simulating its access to random and update oracles. For any query $x$ that $\adv$ sends to the random oracle, $\rdv$ responds with $\ro(x)$. Similarly, update oracle responses are also computed honestly. Since the adversary is algebraic, the reduction learns coefficients $t^{b}_{i, \star}$, such that $\p{t}^{b}_{\star} (X) = \sum_{i = 0}^{\numberofconstrains} X^{i} t^{b}_{i, \star}$ for $\star \in \smallset{\p{lo}, \p{med}, \p{hi}}$. Hence, $\rdv$ can compute polynomials $\p{t}^{0} (X)$ and $\p{t}^{1} (X)$. Since these are not equal, yet their evaluations on $\chi$ are the same, $\rdv$ can compute $\chi$ by finding roots of $\p{t}^{0} (X) - \p{t}^{1} (X)$.

Importantly, polynomial $\p{t}(X)$ assures that the constraints of the system
hold. Hence, the probability that one of $\p{t^0}(X)$, $\p{t^1}(X)$ is computed
incorrectly, the adversary gives and opens acceptably a commitment to it, and
the proof is acceptable, is upper bounded by the soundness of the proof system
$\epss (\secpar)$. Probability of $\adv$ winning in one game but not in the
other is thus upper bounded by $3 \cdot \epsbind(\secpar) + \epsdlog (\secpar) + \epss (\secpar)$.

\ngame{2} In this game, the adversary additionally wins if it provides two different transcripts that
match on the first four messages of the proof.

\ncase{Game 1 to Game 2} In its $4$-th message the adversary
has to provide evaluations
$a_\chz = \p{a}(\chz), b_\chz = \p{b}(\chz), c_\chz = \p{c}(\chz), t_\chz =
\p{t}(\chz), S_{1, \chz} = \p{S_{\sigma 1}}(\chz), s_{2, \chz} = \p{S_{\sigma
		2}}(\chz), z_\chz = \p{z}(\chz \omega)$ of previously committed
polynomials, and compute and evaluate a linearization polynomial $\p{r}$.

As before, the adversary cannot provide two different evaluations for the
committed polynomials, since that would require breaking the evaluation
binding property, which happens (by the union bound) with probability at most
$7 \cdot \epsbind (\secpar)$. 

The adversary cannot also provide two different linearization polynomials
$\p{r^0}$ and $\p{r^1}$ evaluations $r^0_\chz$ and $r^1_\chz$ as the
linearization polynomial is determined by values known to the verifier who
also can compute a commitment to $\p{r}(X)$ by its
own. The evaluation of $\p{r}$ provided by the adversary is later checked, as
$\adv$ opens the commitment in its $5$-th message. Hence, the probability that the
adversary manages to build two convincing proofs that differ in evaluations
$r^0_\chz$ and $r^1_\chz$ is at most $\epsbind (\secpar)$.

Hence, the probability that adversary wins in one game but does not in the
other is upper-bounded by $\abs{\prob{\game{1}} - \prob{\game{2}}} \leq  8 \cdot \epsbind (\secpar)$

\ngame{3} In this game, the adversary additionally wins if it provides two different transcripts that
match on all $5$ messages sent by the prover.

\ncase{Game 2 to Game 3} We show that the probability that $\adv$
wins in one game but does not in the other is negligible.  Observe that in
after its $4$-th message, the adversary is given a challenge $v$ and has to open
the previously computed commitments. Since the transcripts match up to $\adv$'s 
$4$-th message, the challenge is the same in both. Hence, to be able to give two different
openings in its $5$-th message, $\adv$ has to break the unique opening property of the
KZG commitment scheme which happens with probability $9 \cdot \epsop$ tops (as $9$
polynomials are evaluated).

\ncase{Conclusion} Taking all the games together, probability that $\adv$ wins
is upper-bounded by
\[
\epsdlog (\secpar) + \epss (\secpar) + 8 \cdot \epsbind (\secpar) + 9 \cdot \epsop (\secpar).
\]
\qed
	\end{proof}

\subsection{Updatable computational special soundness}
\begin{lemma}
	\label{lem:plonkprot_ss}
  $\plonkprot$ is $(3, 3 \noofc + 1)$-updatable computational special sound with security loss $(\epst(\accProb, \secpar), \epss(\secpar))$ against algebraic adversary $\adv^{\ro, \initU} (\secparam)$ where
  \[
    \epst(\secpar) \leq \frac{\accProb - (q + 1) \epsid (\secpar)}{1 - \epsid (\secpar)}\,,
  \]
  and
	\[
	  \epss(\secpar) \leq \epsid(\secpar) + \epsldlog(\secpar) \,.
	\]
	Here $\accProb$ is a probability that the adversary outputs an acceptable proof, $q$ is the upper bound for a number of random oracle queries the adversary makes, $\epsid(\secpar)$ is a soundness error of the idealized verifier, and $\epsldlog(\secpar)$ is security of $(\numberofconstrains + 2, 1)$-$\uldlog$ \hamid{18.4}{$(\dconst, \dconst)$-$\uldlog$?}\michals{18.04}{Corrected} assumption.
\end{lemma}

%\hamid{17.4}{Should we not make $\epst$ explicit here as $\epst = (\accProb - (q + 1) \epsk)/(1 - \epsk)$? If yes, then we should also change the statement of lemma as follows:
%\begin{lemma}
%	\label{lem:plonkprot_ss}
%	\chb{Let $\plonkprot$ be knowledge sound with knowledge error $\epsk$.} 
%	Let $\plonkprot$'s idealized verifier fails with probability $\epsid (\secpar)$, and
%	$(\noofc + 2, 1)$-$\udlog$ problem be $\epsdlog (\secpar)$ hard. Then $\plonkprot$ is
%	$(3, 3 \noofc + 1)$-computational special sound with security loss $(\epst, \epss)$ \chb{with $\epst = (\accProb - (q + 1) \epsk)/(1 - \epsk)$ and $\epss = \epsid (\secpar) + \epsdlog (\secpar)$} against algebraic adversary $\adv^{\ro, \initU} (\secparam)$ who makes at most $q$ queries to the random oracle $\ro$ \chb{and outputs an acceptable proof with probability
%	at least $\accProb$}.
%\end{lemma}
%}
\begin{proof}
	Let $\adv^{\ro, \initU}(\secparam)$ be the adversary who outputs $(\inp, \zkproof)$ such that $\plonkprotfs.\verifier$ accepts the proof. Let $\tdv$ be a tree-building algorithm that runs $\zdv_1$ from \cref{fig:Attema-ext} and outputs a tree $\tree$, and let $\extt$ be an extractor that given the tree output by $\tdv$ reveals the witness for $\inp$. The main idea of the proof is to show that an adversary who breaks updatable computational special soundness can be used to break a $\udlog$ problem instance. The proof goes by game hops. Note that since the tree branches after $\adv$'s $3$-rd message, the instance $\inp$, commitments $\gone{\p{a} (\chi), \p{b} (\chi), \p{c} (\chi), \p{z} (\chi), \p{t_{lo}} (\chi), \p{t_{mid}} (\chi), \p{t_{hi}} (\chi)}$, and challenges $\alpha, \beta, \gamma$ are the same in all the transcripts. The tree branches after the third adversary's message where the challenge $\chz$ is presented, thus tree $\tree$ is built using different values of $\chz$. 
	%
	We consider the following games.
  \hamid{17.4}{I am happy with the current version of the proof, but I think it might be more readable if we have the explanation in Game 0 not as a game, but as a separate argument that specify $\epst$. Then we define only two games (currently as Game 1 and Game 2) by which we upper-bound $\epss$.}
  \michals{18.04}{I think it makes more sense to have everything written as a game. I believe that this adds structure to the proof and makes it easier to underestand.}

  \ncase{Game 0} %
  In this game the adversary wins if it outputs a valid instance--proof pair $(\inp, \zkproof)$, and the extractor $\extt$ does not manage to output a witness $\wit$ such that $\REL (\inp, \wit)$ holds.

  \ncase{Game 1} %
  In this game the environment aborts the game if the tree building algorithm $\tdv$ fails in building a tree of acceptable transcripts $\tree$. 

  \ncase{Game 0 to Game 1} %
  By \cref{lem:attema} probability that Game 1 is aborted, while Game 0 is not, is at most 
  \[
    \frac{\accProb - (q + 1) \epsid (\secpar)} {1 - \epsid (\secpar)} \,.
  \]

  \ncase{Game 2} %
  In this game the environment additionally aborts if at least one of its proofs in $\tree$ is not acceptable by an idealised verifier.

  \ncase{Game 1 to Game 2} % 
  We show a reduction that breaks an instance of a $\udlog$ assumption when Game 2 is aborted, while Game 1 is not.

  Let $\rdvudlog$ be a reduction that gets as input an $(\noofc + 2, 1)$-$\udlog$ instance $\gone{1, \ldots, \chi^{\noofc+2}}, \gtwo{\chi}$. Then it can update the instance to another one $\gone{1, \ldots, {\chi'}^{\noofc+2}}, \gtwo{\chi'}$. Eventually, the reduction has to ouput $\chi'$.
	%
	The reduction $\rdvudlog$ proceeds as follows.
	\begin{enumerate}
			\item Builds $\adv$'s SRS $\srs$ using the input $\udlog$ instance. Then it processes the adversary's update query by passing it to its own update oracle getting instance $\gone{1, \ldots, {\chi'}^{\noofc+2}}, \gtwo{\chi'}$. The updated SRS $\srs'$ is then built and given to $\adv$. The reduction then starts $\tdv(\adv, \srs')$;
			\item Let $(1, \tree)$ be the output returned by $\tdv$. Let $\inp$ be a relation proven in $\tree$.  Consider a transcript $\zkproof \in \tree$ such that $\vereq_{\inp, \zkproof}(X) \neq 0$, but $\vereq_{\inp, \zkproof}(\chi') = 0$. Since $\adv$ is algebraic, all group
			elements included in $\tree$ are extended by their representation as a combination of the input $\GRP_1$-elements. Hence, all coefficients of the verification equation polynomial $\vereq_{\inp, \zkproof}(X)$ are known. 
			\item Find $\vereq_{\inp, \zkproof}(X)$ zero points and find $\chi'$ among
			them.
			\item Return  $\chi'$.
      \end{enumerate}
    
    Hence, the probability that the adversary wins in Game 2 but does not win in Game 1 is upperbounded by $\epsudlog (\secpar)$.

  \ncase{Conclusion}
  Note that the adversary can win in Game 2 only if $\tdv$ manages to produce a tree of acceptable transcript $\tree$, such that each of the transcripts in $\tree$ is acceptable by an idealised verifier. Note that since $\tdv$ produces $(3 \noofc + 1)$ acceptable transcripts for different challenges $\chz$, it obtains the same number of different evaluations of polynomials $\p{a} (X), \p{b} (X), \p{c} (X), \p{z} (X), \p{t} (X)$. Since the transcripts are acceptable by an idealised verifier, the equality between polynomial $\p{t} (X)$ and combination of polynomials $\p{a} (X), \p{b} (X), \p{c} (X), \p{z} (X)$ defined in prover's $3$-rd message description holds. Hence, $\p{a} (X), \p{b} (X), \p{c} (X)$ encodes the valid witness for the proven statement. Since $\p{a} (X), \p{b} (X), \p{c} (X)$ are of degree at most $(\noofc + 2)$ and there is more than $(\noofc + 2)$ their evaluations known, $\extt$ can recreate polynomials' coefficients by interpolation and reveal the witness with probability $1$. Hence, the probability that extraction fails in that case is upper-bounded by probability of an idealised verifier failing $\epsid(\secpar)$ 

  Probability that the adversary wins in Game 2 but not in Game 1 is 
  \[
  \frac{\accProb + (q + 1) \epsid (\secpar)}{1 - \epsid (\secpar)} + \epsudlog(\secpar)  + \epsid (\secpar). 
  \]
  

\subsection{Trapdoor-less simulatability of Plonk}
\begin{lemma}
  \label{lem:plonk_hvzk}
  Let $\plonkprot$ be zero knowledge with security $\epszk(\secpar)$. Let
  $(\pR, \pS, \pT, \pf, 1)$-uber assumption for $\pR, \pS, \pT, \pf$ as defined in
  \cref{eq:uber} hold with security $\epsuber(\secpar)$. Then $\plonkprot$
  is 2-programmable trapdoor-less simulatable zero knowledge 
  %with simulator $\simulator$ that does not require a SRS trapdoor 
  with security
  $\epszk(\secpar) + \epsuber(\secpar)$ \chb{against algebraic adversaries}.~\footnote{The simulator works as a simulator
    for proofs that are zero-knowledge in the standard model. However, we do not say
    that $\plonk$ is HVZK in the standard model as proof of that \emph{requires} the
    SRS simulator.}
\end{lemma}

%Due to page limit, the proof has been moved to \cref{sec:plonk-tls-proof}
\begin{proof}
  As noted in \cref{def:upd-scheme}, subvertible zero knowledge implies updatable zero
  knowledge. Hence, here we show that Plonk is TLS even against algebraic adversaries who picks
  the SRS on its own.
  
  The proof goes by game-hopping. The environment that controls the games
  starts the adversary who sets a SRS $\srs$, then the adversary outputs an
  instance--witness pair $(\inp, \wit)$ and, depending on the game, is provided
  with either real or simulated proof for it. In the end of the game the
  adversary outputs either $0$ if it believes that the proof it saw was provided
  by the simulator and $1$ in the other case.

  \ngame{0} In this game $\adv(\secparam)$ picks an SRS $\srs$ and instance--witness pair
  $(\inp, \wit)$ and gets a real proof $\zkproof$ for it.

  \ngame{1} In this game for $\adv(\secparam)$ picks an SRS $\srs$ and an instance--witness pair
  $(\inp, \wit)$ and gets a proof $\zkproof$ that is simulated by a simulator
  $\simulator_\chi$ which utilises for the simulation the SRS trapdoor and
  proceeds as described in \cref{sec:plonk_explained}.

  \ncase{Game 0 to Game 1} Since $\plonk$ is (subvertible) zero-knowledge,
  probability that $\adv$ outputs a different bit in both games is negligible.
  Hence
  \(
	\abs{\prob{\game{0}} - \prob{\game{1}}} \leq \epszk(\secpar).
\)

\ngame{2} In this game $\adv(\secparam)$ picks an SRS $\srs$ and instance--witness pair
$(\inp, \wit)$ and gets a proof $\zkproof$ simulated by the simulator
$\simulator$ which proceeds as follows.

For its $1$-st message the simulator  picks randomly both the randomisers $b_1, \ldots, b_6$ and
sets $\wit_i = 0$ for $i \in \range{1}{3\noofc}$. Then $\simulator$
outputs $\gone{\p{a}(\chi), \p{b}(\chi), \p{c}(\chi)}$. For the first
challenge, the simulator picks permutation argument challenges $\beta, \gamma$
randomly.

For its $2$-nd message, the simulator computes $\p{z}(X)$ from
the newly picked randomisers $b_7, b_8, b_9$ and coefficients of polynomials
$\p{a}(X), \p{b}(X), \p{c}(X)$. Then it evaluates $\p{z}(X)$ honestly and outputs
$\gone{\p{z}(\chi)}$. Challenge $\alpha$ that should be sent by the verifier
after the simulator's $2$ message is picked by the simulator at random.

In its $3$-rd message the simulator starts by picking at random a challenge $\chz$, which
in the real proof comes as a challenge from the verifier sent \emph{after} the prover
sends its $3$-rd message. Then $\simulator$ computes evaluations
\(\p{a}(\chz), \p{b}(\chz), \p{c}(\chz), \p{S_{\sigma 1}}(\chz), \p{S_{\sigma
    2}}(\chz), \pubinppoly(\chz), \lag_1(\chz), \p{Z_H}(\chz),\allowbreak
\p{z}(\chz\omega)\) and computes $\p{t}(X)$ honestly. Since for a random
$\p{a}(X), \p{b}(X), \p{c}(X), \p{z}(X)$ the constraint system is (with
overwhelming probability) not satisfied and the constraints-related polynomials
are not divisible by $\p{Z_H}(X)$, hence $\p{t}(X)$ is a rational function
rather than a polynomial. Then, the simulator evaluates $\p{t}(X)$ at $\chz$ and
picks randomly a degree-$(3 \noofc - 1)$ polynomial $\p{\tilde{t}}(X)$ such that
$\p{t}(\chz) = \p{\tilde{t}}(\chz)$ and publishes a commitment
$\gone{\p{\tilde{t}_{lo}}(\chi), \p{\tilde{t}_{mid}}(\chi),
  \p{\tilde{t}_{hi}}(\chi)}$. After that the simulator outputs $\chz$ as a
challenge.

For the next message, the simulator computes polynomial $\p{r}(X)$ as an honest
prover would, cf.~\cref{sec:plonk_explained} and evaluates $\p{r}(X)$ at $\chz$.

The rest of the evaluations are already computed, thus $\simulator$ simply outputs
\( \p{a}(\chz), \p{b}(\chz), \p{c}(\chz), \p{S_{\sigma 1}}(\chz), \p{S_{\sigma
    2}}(\chz), \p{t}(\chz), \p{z}(\chz \omega)\,.  \) After that it picks randomly
the challenge $v$, and prepares the the last message as an honest prover
would. Eventually, $\simulator$ and outputs the final challenge, $u$, by picking it
at random as well.

\ncase{Game 1 to Game 2} We now describe the reduction $\rdv$ which
relies on the $(\pR, \pS, \pT, \pF, 1)$-uber assumption, cf.~\cref{sec:uber_assumption}
where $\pR, \pS, \pT, \pF$ are polynomials over variables
$\vB = B_1, \ldots, B_9$ and are defined as follows. Let
$E = \smallset{\smallset{2}, \smallset{3, 4}, \smallset{5, 6}, \smallset{7, 8,
    9}}$ and $E' = E \setminus \smallset{2}$. Let
\begin{align}
\label{eq:uber}
\pF(\vB) & = \smallset{B_1} \cup \smallset{B_1B_i \mid i \in A,\ A \in E'} \cup
             \smallset{B_1B_iB_j \mid i \in A, j \in B,\ A, B \in E', B
             \neq A} \cup \notag\\
           & \smallset{B_1B_iB_jB_k \mid i \in A, j \in
             B, k \in C,\ A, B, C \in E', A \neq B \neq C \neq A}\notag\,,\\
  \pR(\vB) & = \smallset{B_i \mid i \in A,\ A \in E} \cup \smallset{B_i B_j \mid i \in
             A, j \in B,\ A \neq B, A, B \in E} \cup \\ 
           & \smallset{B_i B_j B_k \mid i \in A,\ j \in
             B,\ k \in C,\
             A, B, C \text{ all different and in } E} \cup \notag \\
           & \smallset{B_i B_j B_k B_l \mid i \in A,\ j \in B,\ k \in C,\ l \in D,\
             A, B, C, D \text{ all different and in } E} \notag \\
           & \setminus \pF(\vB)\,,\notag \\
  \pS(\vB) & = \emptyset, \qquad \pT(\vB) = \emptyset.
\end{align}
That is, the elements of $\pR$ are all singletons, pairs, triplets and
quadruplets of $B_i$ variables that occur in polynomial $\pt(\vB)$ except the
challenge element $\pf(\vB)$ which are all elements that depend on a variable
$B_1$. Variables $\vB$ are evaluated to randomly picked
$\vb = b_1, \ldots, b_9$.

The reduction $\rdv$ learns $\gone{\pR}$ and challenge
$\gone{\vec{w}} = \gone{w_1, \ldots, w_{12}}$ where $\vec{w}$ is either a vector
of evaluations $\pF(\vb)$ or a sequence of random values $y_1, \ldots, y_{12}$,
for the sake of concreteness we state $w_1 = b_1$ or $w_1 = y_1$ (depending on
the chosen random bit).

Then it starts $\adv$ and learns $\srs$, since $\adv$ is algebraic, the reduction also learns trapdoor $\chi$. Then $\rdv$ picks $\chz$. Elements $b_i$ are interpreted as polynomials in $X$ that are
evaluated at $\chi$, i.e. $b_i = b_i(\chi)$. Next, $\rdv$ sets for
$\xi_i, \zeta_i \sample \FF_p$
\(
  \gone{\p{\tb}_1(X)} =
(X - \chz)(X - \ochz) \gone{w_1}(X) + \xi_i (X - \chz) \gone{1} +
\zeta_i (X - \ochz) \gone{1}, % \text{ for } i \in % \range{1}{9}, u_1
\),
and
\(
  \gone{\p{\tb}_i(X)} =
(X - \chz)(X - \ochz) \gone{b_i}(X) + \xi_i (X - \chz) \gone{1} +
\zeta_i (X - \ochz) \gone{1}, % \text{ for } i \in % \range{1}{9}, u_1
\) 
for $i \in \range{2}{9}$.

Denote by $\tb_i$ evaluations of $\p{\tb}_i$ at $\chi$.  The reduction computes
all
$\gone{\tb_i \tb_j}, \gone{\tb_i \tb_j \tb_k}, \gone{\tb_i \tb_j \tb_k \tb_l}$
such that $\gone{B_i B_j, B_i B_j B_k, B_i B_j B_k B_l} \in \pR$.  This is
possible since $\rdv$ knows all singletons $\gone{w_1, b_2, \ldots, b_9}$ and pairs
$\gone{b_i b_j} \in \pR$ which can be used to compute all required pairs
$\gone{\tb_i \tb_j}$:
\begin{align*}
\gone{\tb_i \tb_j} 
& = ((\chi - \chz)(\chi - \ochz)\gone{b_i} + \xi_i (\chi - \chz)\gone{1} +
\zeta_i (\chi - \ochz) \gone{1}) 
\cdot \\
 & ((\chi - \chz)(\chi - \ochz)\gone{b_j} + \xi_j (\chi - \chz)\gone{1} +
\zeta_j (\chi - \ochz) \gone{1}) = \\
 & ((\chi - \chz)(\chi - \ochz))^2 \gone{b_i b_j} +  ((\chi - \chz)(\chi -
 \ochz)\gone{b_i} (\xi_j (\chi - \chz) \gone{1} + \zeta_j (\chi - \ochz)
 \gone{1}) + \\
 & ((\chi - \chz)(\chi -
 \ochz)\gone{b_j} (\xi_i (\chi - \chz) \gone{1} + \zeta_i (\chi - \ochz)
 \gone{1}) + \psi,
\end{align*}
where $\psi$ compounds of $\xi_i, \xi_j, \zeta_i, \zeta_j, \chz, \ochz, \chi$ which
are all known by $\rdv$ and no $b_i$ nor $b_j$.
Analogously for the triplets and quadruplets and elements dependent on~$\vec{w}$. 

Next the reduction obtains from $\adv$ an instance--witness pair $(\inp, \wit)$.  $\rdv$ now
prepares a simulated proof as follows:
\begin{compactdesc} 
\item[Message 1] $\rdv$ computes $\gone{\pa(\chi)}$ using as
randomisers $\gone{\tb_1}, \gone{\tb_2}$ and setting $\wit_i = 0$, for $i
\in \range{1}{3 \noofc}$. Similarly it computes
$\gone{\pb(\chi)}, \gone{\pc(\chi)}$.  $\rdv$ publishes the obtained values
and picks the first challenge $\beta, \gamma$ at random.  Note that regardless
$w_1 = b_1$ or a random element, $\gone{a(\chi)}$ is random. Thus $\rdv$'s
output has the same distribution as output of a real prover.  
\item[Message 2]
$\rdv$ computes $\gone{\pz(\chi)}$ using $\tb_7, \tb_8, \tb_9$ and publishes
it. Then it picks randomly the challenge $\alpha$. This message is
independent on $b_1$ thus $\rdv$'s output is indistinguishable from the prover's. 
\item[Message 3] The reduction computes
  $\p{t_{lo}}(\chi), \p{t_{mid}}(\chi), \p{t_{hi}}(\chi)$, which all depend on
  $b_1$. To that end $\gone{\tb_1}$ is used. Note that if $\vec{w}$ is a vector
  of $\pF(b_1, \ldots, b_9)$ evaluations then
  $\gone{\p{t_{lo}}(\chi), \p{t_{mid}}(\chi), \p{t_{hi}}(\chi)}$ is the same as
  the real prover's. Alternatively, if $\vec{w}$ is a vector of random values,
  then $\p{t_{lo}}(\chi), \p{t_{mid}}(\chi), \p{t_{hi}}(\chi)$ are all random
  polynomials which evaluates at $\chz$ to the same value as the polynomials
  computed by the real prover. That is, in that case
  $\p{t_{lo}}(\chi), \p{t_{mid}}(\chi), \p{t_{hi}}(\chi)$ are as the simulator
  $\simulator$ would compute. Eventually, $\rdv$ outputs $\chz$.
\item[Message 4] The reduction outputs
  $\pa(\chz), \pb(\chz), \pc(\chz), \p{S_{\sigma 1}}(\chz), \p{S_{\sigma 2} (\chz)},
  \pt(\chz), \pz(\ochz)$.  For the sake of concreteness, denote by
  $S = \smallset{\pa, \pb, \pc, \pt, \pz}$. Although for a polynomial $\p{p} \in S$,
  reduction $\rdv$ does not know $\p{p}(\chi)$ or even do not know all the
  coefficients of $\p{p}$, the polynomials in $S$ was computed such that the
  reduction always knows their evaluation at $\chz$ and $\ochz$.
\item[Message 5] $\rdv$ computes the openings of the polynomial commitments assuring
  that evaluations at $\chz$ it provided were computed honestly.
\end{compactdesc}

If the adversary $\adv$'s output distribution differ in Game $\game{1}$ and
$\game{2}$ then the reduction uses it to distinguish between
$\vec{w} = \pF(b_1, \ldots, b_9)$ and $\vec{w}$ being random, thus
\( \abs{\prob{\game{1}} - \prob{\game{2}}} \leq \epsuber(\secpar).  \)

\ncase{Conclusion} Probability that the adversary's outputs differ in Game 0 and Game
2 is upper-bounded by $ \epszk(\secpar) + \epsuber(\secpar)$. \qed
\end{proof}

% \begin{lemma}[Simulation for false statement]
%   Let $\simulator = (\simulator_1, \simulator_2)$ be a trapdoor-less simulator from
%   Game 2 above, define $\simulator' = (\simulator_1, \simulator'_2)$ such that
%   $\simulator'_2$ behaves as $\simulator_2$ except it produces simulated proofs for
%   statements outside the language as well. Then for every $\inp \not\in \LANG_\REL$
%   holds
%   \[
%     \Pr \left[ \verifier (\srs, \inp, \zkproof) = 1 \left|\, \srs \gets \adv
%         (\secparam), \zkproof \gets \simulator (\srs, \inp) \right.  \right] \geq
%     1 - \eps (\secpar),
%   \]
%   for some negligible $\eps (\secpar)$.\michals{15.10}{Could we have just ``$= 1$''
%     here?}
% \end{lemma}

\subsection{Simulation extractability of~$\plonkprotfs$}
Since \cref{lem:plonkprot_ur,lem:plonkprot_ss,lem:plonk_hvzk} hold, $\plonkprot$ is $\ur{2}$,
computational special sound and trapdoor-less simulatable. We now make use of \cref{thm:se} and show that
$\plonkprot_\fs$ is simulation-extractable as defined in \cref{def:updsimext}.

\begin{corollary}[Simulation extractability of $\plonkprot_\fs$]
\label{thm:plonkprotfs_se}
Assume an idealised $\plonkprot$ verifier fails at most with probability
$\epsid(\secpar)$, the discrete logarithm advantage is bounded by $\epsdlog(\secpar)$ and
the $\PCOMp$ is a commitment of knowledge with security $\epsk(\secpar)$, binding security
$\epsbind(\secpar)$ and has unique opening property with security $\epsop(\secpar)$. Let
$\ro\colon \bin^* \to \bin^\secpar$ be a random oracle. Let $\advse$ be an adversary that
can make up to $q$ random oracle queries, and outputs an acceptable proof for
$\plonkprotfs$ with probability at least $\accProb$. Then $\plonkprotfs$ is
\COMMENT{forking }simulation-extractable with extraction error \textcolor{red}{$\eta =
\epsur(\secpar)$}. The extraction probability $\extProb$ is at least
\[
	\extProb \geq \frac{1}{q^{3 \noofc}} (\accProb - \epsk(\secpar) - 2\cdot\epsbind(\secpar) -
  \epsop(\secpar))^{3\noofc + 1} -\eps(\secpar)\,,
\]
for some negligible $\eps(\secpar)$ and $\noofc$ being the number of
constraints in the proven circuit.
\end{corollary}
 
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
